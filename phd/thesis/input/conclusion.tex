\chapter{Conclusion et perspectives}
\label{chap:main-conclusion}
  \smallchaptercite{
    [\dots] the task is far from being solved [\dots]
  }{
    \newcite{hasan2014state_of_the_art}
  }

  \section{Rappel}
  \label{sec:main-conclusion-rappel}
    Dans cette thèse, nous nous sommes intéressé à la tâche d'indexation par
    termes-clés en domaines de spécialités. Étant donné un document textuel,
    cette tâche consiste à lui attribuer les unités textuelles qui décrivent son
    contenu. Ces unités textuelles, les termes-clés, permettent de le résumé, de
    le catégoriser et, surtout, de l'indexer pour la recherche d'information.
    Les termes-clés peuvent être attribués par les auteurs, des lecteurs ou des
    indexeurs professionnels, mais seuls ces derniers réalisent un travail
    impartial, homogène et conforme pour une indexation de qualité en domaines
    de spécialités. Notre objectif était de proposer une alternative automatique
    aux indexeurs professionnels pour une indexation par termes-clés de
    documents numérique en domaines de spécialités. Tout d'abord, nous avons
    fait le choix de traiter ce problème dans sa généralité, puis nous nous
    sommes ensuite concentré sur les documents en domaines de spécialités et sur
    leur indexation particulière effectuée par des indexeurs professionnels.

    Dans la littérature, de nombreuses méthodes sont proposées pour l'indexation
    automatique par termes-clés. Elles sont réparties en deux catégories~:
    l'extraction et l'assignement de termes-clés. La première catégorie de
    méthode extrait les termes-clés depuis le contenu du document et la seconde
    depuis un vocabulaire contrôlé représentatif du langage documentaire de
    rigueur pour l'indexation. L'extraction est la catégorie d'indexation par
    termes-clés la plus étudiée. Elle est plus simple à mettre en \oe{}uvre, car
    elle traite les unités textuelles du document. Cependant, ces unités
    textuelles ne sont pas toujours sous une forme appropriée pour une
    indexation à la manière des indexeurs professionnels. Au contraire,
    l'assignement fournit des termes-clés contrôlés par un vocabulaire
    spécifique assurant une indexation de meilleure qualité. Cependant, elle est
    plus difficile à mettre en \oe{}uvre, car les entrées du vocabulaire
    contrôlé ne sont pas nécessairement présentent dans le document. Par
    ailleurs, elle n'est pas capable d'identifier des termes-clés très
    spécifiques au document, ni même des nouveaux concepts, si ceux-ci ne sont
    pas dans le vocabulaire contrôlé. Pour traiter le problème d'indexation par
    termes-clés dans sa généralité, nous avons travaillé sur l'extraction de
    termes-clés. Pour l'indexation en domaines de spécialités, nous avons
    proposé une extension de ce travail afin d'y intégrer la capacité à réaliser
    l'assignement.

  \section{Contributions}
  \label{sec:main-conclusion-contributions}
    Nos travaux ont fait l'objet de trois contributions~: deux contributions
    pour l'extraction de termes-clés et une contributions pour l'indexation par
    termes-clés en domaines de spécialités. Nous avons aussi proposé un
    protocole d'évaluation pour une campagne d'évaluation manuelle de nos
    travaux.

    Notre première contribution à l'extraction de termes-clés concerne l'étape
    préliminaire de sélection des termes-clés candidats, qui consiste à
    identifier les unités textuelles du document susceptibles d'être des
    termes-clés. Dans la littérature, cette étape est très souvent réalisée à
    l'aide de règles simples qui ont parfois tendance à sélectionner beaucoup de
    candidats. Or, nous émettons l'hypothèse que l'indexation par termes-clés
    est influencée par la qualité de l'ensemble des candidats sélectionnés et
    que cette qualité est en partie due au nombre de candidats. Selon nous, plus
    l'ensemble de candidats est de petite taille et plus il contient de
    termes-clés corrects, alors meilleure est sa qualité et meilleure sera
    l'indexation.
    %
    En nous fondant sur une analyse des propriétés linguistiques des termes-clés
    de référence et de leurs adjectifs, nous avons d'abord proposé une méthode
    qui limite le nombre de candidats sélectionnés en ciblant les séquences de
    noms modifiés, ou non, par un adjectif utile (non superflu). Un adjectif
    utile se distingue par sa catégorie (relationnel ou composé complexe) et son
    usage fréquent dans le document~; un adjectif superflu est un adjectif
    qualificatif qui modifie un nom utilisé plus fréquemment en autonomie.
    %
    Nous avons ensuite vérifié notre hypothèse en évaluant la qualité de
    l'ensemble de candidats sélectionnés par notre méthode, ainsi que son impact
    sur deux méthodes d'extraction de
    termes-clés~:\textsc{Tf-Idf}~\cite{jones1972tfidf} et
    \textsc{Kea}~\cite{witten1999kea}. Les résultats ont montré que notre
    méthode est effectivement capable de réduire le nombre de candidats
    sélectionnés sans éliminer un nombre significatif de termes-clés corrects.
    Ils montrent aussi qu'elle à un meilleure impact sur les méthodes
    d'extractions employées. Elle sélectionne donc des candidats de meilleure
    qualité et notre hypothèse est vérifiée.

    Notre seconde contribution à l'extraction de termes-clés s'intéresse aux
    méthodes qui ordonnent les termes-clés candidats par importance, puis
    extraient les $k$ plus importants en tant que termes-clés. Selon nous, ce ne
    sont pas les termes-clés candidats qui doivent être ordonnés par importance,
    mais ce qu'ils représentent~: leur sujet. De plus, si plusieurs unités
    textuelles représentent le même sujet, alors elles doivent être considérées
    comme une entité unique. Nous avons donc proposé, TopicRank, une méthode à
    base de graphe qui commence par grouper les termes-clés candidats en sujets,
    ordonne ces sujets à l'aide d'un graphe, puis extrait un, et un seul,
    terme-clé candidat pour chacun des $k$ meilleurs sujets. Nos expériences
    ont montrées que TopicRank améliore les méthodes à base de graphe
    TextRank~\cite{mihalcea2004textrank} et SingleRank~\cite{wan2008expandrank},
    vérifiant ainsi notre hypothèse. Au travers d'évaluations manuelles, nous
    avons aussi pu montrer que TopicRank extrait des termes-clés non redondants,
    lui permettant de mieux couvrir les sujets du document que les méthodes
    ordonnant les termes-clés candidats.

    Notre troisième contribution s'intéresse à l'indexation par termes-clés en
    domaines de spécialités telle qu'elle est effectuée par un indexeur
    professionnel. Ces indexeurs mélangent extraction et assignement, avec une
    préférence pour l'assignement. L'assignement permet de d'obtenir un
    indexation homogène de tous les documents d'un même domaine, une indexation
    conforme au vocabulaire de ce domaine et une généralisation du contenu de
    chaque document afin de le situer dans son domaine. L'extraction, quant à
    elle, permet d'améliorer l'exhaustivité de l'indexation en ajoutant des
    termes-clés très spécifiques au document, voir même de nouveaux concepts.
    Nous faisons donc l'hypothèse qu'extraction et assignement doivent être
    réalisés conjointement grâce à une recontextualisation du contenu du
    document dans son domaine. Cette recontextualisation doit (1) permettre de
    déterminer l'importance des sujets en tenant aussi compte de la place qu'ils
    occupent dans le domaine et (2) permettre l'assignement en déterminant les
    termes-clés du domaines importants vis-à-vis du document.
    %
    Pour cela, nous avons étendu notre seconde contribution en ajoutant un
    graphe du domaine, représenté par son vocabulaire contrôlé (ses
    termes-clés). Notre nouvelle méthode, TopicCoRank, représente le domaine du
    document avec un graphe des termes-clés de référence attribués à des
    documents du même domaine, le connecte au graphe de sujets et ordonne
    conjointement sujets et termes-clés de référence. Les termes-clés obtenus à
    partir du graphe de sujets sont extraits et les termes-clés obtenus à partir
    du graphe du domaine sont assignés. En domaine de spécialité, TopicCoRank
    obtient des résultats supérieurs à l'état de l'art. À notre connaissance, il
    s'agit aussi de la première méthode capable de réaliser simultanément
    extraction et assignement.

    Enfin, nous avons participé à la mise en place d'une campagne d'évaluation
    manuelle en domaines de spécialités. Nous avons proposé, en collaboration
    avec les indexeurs professionnels de l'Inist, un protocole permettant
    d'évaluer deux aspects de l'indexation~: la pertinence (validité) et le
    silence (perte d'information). Le premier aspect est celui qui est aussi
    évalué par l'évaluation automatique. Les résultats obtenus lors de la
    campagnes ont tout de même montré que l'humain est plus adapté pour
    déterminer la validité d'un terme-clé, car il est capable de comprendre son
    sens et n'a donc pas besoin de le comparer avec des termes-clés de
    référence. Le second aspect est nouveau pour l'évaluation de méthodes
    d'indexation par termes-clés. Il est purement sémantique et permet de
    déterminer si, au delà de fournir un grand nombre de termes-clés corrects,
    la méthode capture les informations les plus importantes du document. Toutes
    les étapes de cette campagne d'évaluation seront rendus disponible afin de
    permettre l'étude de nouvelle techniques d'évaluation automatique, notamment
    vérifier leur corrélation avec le jugement humain.

  \section{Perspectives}
  \label{sec:main-conclusion-contributions}
    Nos contributions ont montrées des améliorations en matière de sélection de
    termes-clés, d'extraction de termes-clés et d'indexation par termes-clés en
    domaines de spécialités. Elles ont toutefois des limites et il reste encore
    plusieurs perspectives de travail.

    Nous identifions trois limites de notre travail s'intéressant à la sélection
    des termes-clés candidats pour l'extraction de termes-clés. Premièrement,
    notre étude linguistique des termes-clés s'est limitées aux adjectifs
    composés complexes et aux adjectifs relationnels, alors qu'il existe
    d'autres catégories d'adjectifs. Les adjectifs relationnel, qui sont des
    dénominaux, ont montrés leur utilité au sein des termes-clés, alors n'en
    est-il pas de même pour les autres adjectifs dénominaux~? N'est-ce pas parce
    qu'ils sont dérivé du nom, élément central du terme-clé, qu'ils sont si
    utiles~? Qu'en est-il pour les autres adjectifs dérivés~? Ces questions sont
    intéressantes et mérites d'être soulevées. Ensuite, nous avons mis de côté
    les prépositions et les déterminants en français, alors qu'ils sont
    fréquemment employés au sein de termes-clés. Ils méritent aussi d'être
    étudiés afin de distinguer dans quels cas ils servent de frontière entre
    deux candidats (\TODO{exemple}) et dans quels cas ils doivent être
    sélectionnés au sein d'eux (\TODO{exemple}). Enfin, lors de notre analyse de
    TopicRank selon les différentes méthodes de sélection des termes-clés
    candidats, nous avons évoqué la possibilité que certaines méthodes (comme
    TopicRank) soient moins sensibles à la variation de qualité des candidats
    que d'autres. Il serait intéressant d'étudier les méthodes de sélection de
    candidats sur un plus large panel de méthodes, de vérifier cette hypothèse
    et d'identifier quels sont les facteurs en cause d'une sensibilité plus ou
    moins forte.

    Notre travail sur TopicRank possède aussi quelques limitations. Tout
    d'abord, le groupement en sujets que nous avons proposé est naïf. Il ne
    tient pas compte du lien de synonymie des mots, ni même de leur sens dans
    leurs contextes (problème d'ambiguïté). Nous avons proposé ce groupement car
    il permet à TopicRank d'être applicable dans toutes les situation, sans
    nécessiter de ressources particulières. Lorsque les données mises à
    dispositions le permettent, il serait tout de même intéressant d'envisager
    d'autres méthodes de groupement. Nous pourrions analyser la sémantique
    latente au sein d'une collection donné, comme l'ont fait
    \newcite{liu2010topicalpagerank}, \newcite{ding2011binaryintegerprogramming}
    et \newcite{zhang2013wordtopicmultirank} avec
    \textsc{Lda}~\cite{blei2003lda}. À la manière de
    \newcite{daille2014synonymdetection}, nous pourrions aussi nous appuyer sur
    le contexte des termes-clés candidats et de leurs mots pour déterminer
    lesquels sont synonymes. En effet, \newcite{daille2014synonymdetection}
    proposent une approche qui se fonde sur le constat qu'un mot se reconnait
    par ses fréquentations (cooccurrences) pour déterminer les expressions
    synonymes lorsque leurs têtes sont identiques et leurs queues sémantiquement
    similaires d'après les mots avec lesquels ils cooccurrent, ou inversement
    lorsque leurs queues sont identiques et leurs têtes sémantiquement
    similaires d'après les mots avec lesquels elles cooccurrent. Une autre
    limite de notre travail est le choix non optimal du terme-clé candidat à
    extraire pour un sujet. Bien que la stratégie que nous employons donne des
    résultats satisfaisants, nous avons établi que la stratégie optimale
    permettrait d'atteindre des performances deux fois supérieures dans certains
    cas. Une première solution serait d'utiliser une collection d'entraînement
    pour apprendre à reconnaître le terme-clé au sein d'un sujet. Certains
    traits utilisés par les méthodes supervisés pourraient servir (position de
    la première occurrence, nombre de mots, etc.), ainsi que de nouveaux traits
    liés à la relation qu'entretient le candidat avec les autre candidats du
    sujet (degré de similarité avec tous les autres, catégorie grammaticale des
    mots en communs avec les autres, etc.). Une autre solution serait
    d'appliquer des méthodes de titrage automatique, telles que celle de
    \newcite{lau2011topiclabeling}. L'avantage d'une méthode telle que celle de
    \newcite{lau2011topiclabeling} est qu'elle permet de générer des unités
    textuelles à partir d'un sujet. Dans notre cas, elles permettent donc de
    proposer des termes-clés qui n'occurrent pas nécessairement dans le
    document. Correctement paramétrée avec un vocabulaire contrôlé, une méthode
    de titrage automatique générative peut donc être une alternative à
    TopicCoRank pour réaliser extraction et assignement.

    TopicCoRank, qui permet de réaliser simultanément extraction et assignement
    de termes-clés possède encore quelques défauts. Premièrement, bien que
    l'ordonnancement conjoint des sujets du document et des termes-clés du
    domaine améliore l'ordonnancement, nous avons observé que TopicCoRank est
    plus performant en domaines de spécialités lorsqu'il ne réalise que
    l'assignement. Cela signifie que les termes-clés du domaine sont
    correctement identifiés parmi tous les termes-clés de celui-ci, mais que
    leur importance est trop faible comparée à celle qui est attribuée aux
    sujets du document. Ce problème peut être résolu de deux manières. Il existe
    peut être un schéma de pondération des arêtes et d'unification des deux
    graphes plus performant que celui que nous proposons. Pour unifier les deux
    graphes, nous pourrions par exemple nous intéresser au contenu des documents
    de référence. Ainsi, un terme-clé du domaine pourrait est connecté à un
    sujet lorsqu'il est le terme-clé d'un document dans lequel le sujet
    apparaît. Une autre manière de résoudre ce problème serait aussi de faire
    varier l'influence de la recommandation interne (paramètre $\lambda$)
    différemment pour les sujets et les termes-clés de référence. En augmentant
    plus fortement l'impact de la recommandation issue des sujets
    (recommandation externe) en utilisant une faible valeur pour $\lambda$,
    l'importance des termes-clés du domaine devrait augmenter, leur permettant
    de rivaliser avec les sujets au classement par importance. Le paramétrage de
    $\lambda$ peut aussi résoudre un autre problème de TopicCoRank. En effet,
    nous avons aussi observé que TopicCoRank fonctionne moins bien hors domaines
    de spécialités, il est difficilement généralisable. Utiliser un paramètre
    $\lambda$ différent pour calculer l'importance des sujets et l'importance
    des termes-clés peut aussi résoudre ce problème. Ce paramètre $\lambda$ peut
    être paramétré empiriquement avec les données d'entraînement, mais nous
    aimerions aussi chercher à le prédire. En effet, nous avons expliqué que le
    problème de généralisation de TopicCoRank est dû au fait que les données
    d'entraînement des collections que nous avons utilisé hors domaines de
    spécialités ne sont pas adaptées. Il serait donc intéressant de voir si nous
    pouvons évaluer avec quel degré les données sont adaptées et de voir s'il
    existe une corrélation entre celui-ci et le paramétrage de $\lambda$.

