\chapter{Extraction de termes-clés indépendante du domaine}
\label{chap:main-domain_independent_keyphrase_extraction}
  \smallchaptercite{
    [\dots] there is still room for improvement over the task.
  }{
    \newcite{kim2010semeval}
  }

  %-----------------------------------------------------------------------------

  \section{Introduction}
  \label{sec:main:domain_independent_keyphrase_extraction-introduction}
    Dans ce chapitre, nous nous intéressons à la tâche d'extraction automatique
    de termes-clés. Cette tâche consiste à identifier dans un document ses mots
    et expressions qui permettent le mieux d'en caractériser le contenu. Cette
    tâche de l'indexation par termes-clés est celle la plus étudiée de nos
    jours. Elle peut être réalisée de manière non supervisée ou supervisée,
    grâce à la mise en \oe{}uvre d'algorithmes d'ordonnancement par importance
    des mots du document ou grâce à l'entraînement de classifieurs capables de
    déterminer si une unité textuelle est un terme-clé ou non.

    Nous proposons deux contributions à l'extraction automatique de termes-clés.
    Tout d'abord, nous nous intéressons à l'étape préliminaire de sélection des
    termes-clés candidats, puis nous nous intéressons à leur ordonnancement par
    importance. Les méthodes proposées sont non supervisées, aucun biais
    induisant une quelconque dépendance à une langue ou à un domaine n'est
    introduit.

    \TODO{pas très complet}

  %-----------------------------------------------------------------------------

  \section{Sélection des termes-clés candidats}
  \label{sec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection}
    La sélection des termes-clés candidats établit la liste des termes-clés
    potentiels pour un document donné. Bien qu'étudiée en surface, ou de manière
    ad-hoc à une méthode particulière d'extraction de termes-clés, cette étape
    est critique pour l'extraction de termes-clés. Si elle ne sélectionne pas
    suffisamment de candidats, alors la performance maximale pouvant être
    atteinte pour l'extraction de termes-clés est faible et, au contraire, si
    elle sélectionne un nombre important de candidats, alors elle augmente le
    risque de sélectionner de mauvais candidats pouvant dégrader la performance
    d'une méthode d'extraction de termes-clés~\cite{hasan2014state_of_the_art}.
    De nombreux travaux semblent montrer que les groupes nominaux, souvent
    approximés par les séquences de noms et d'adjectifs, forment de bons
    termes-clés candidats et sont très proches des termes-clés de
    référence~\cite{barker2000nounphrasehead,hulth2003keywordextraction,wan2008expandrank}.

    Dans notre travail, nous remettons en question la sélection systématique
    d'un adjectif apposé à un nom. En nous appuyant sur une analyse linguistique
    des termes-clés de trois collections de données, nous proposons une méthode
    qui juge si un adjectif apporte du sens bénéfique à la caractérisation du
    contenu du document, auquel cas il est sélectionné avec le nom qu'il
    modifie, ou non, auquel cas seul le nom est sélectionné comme terme-clé
    candidat. Le bien fondé de cette méthode est montré au travers de deux
    évaluations~: l'une intrinsèque, l'autre extrinsèque. L'évaluation
    intrinsèque compare la qualité de l'ensemble de termes-clés candidats
    sélectionnés par notre méthode à ceux sélectionnés par les méthodes les plus
    utilisées ($\{1..3\}$-grammes, \textit{NP-chunks} et \texttt{/(N|A)+/})~;
    l'évaluation extrinsèque compare l'impact de notre méthode de sélection sur
    deux méthodes d'extraction de termes-clés à celui des méthodes de sélection
    les plus utilisées.

    \subsection{Analyse des propriétés linguistiques des termes-clés}
    \label{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-analysis_of_keyphrase_properties}
      Afin de sélectionner plus finement les termes-clés candidats, nous
      extrayons et analysons des statistiques concernant les termes-clés~: leur
      taille (en nombre de mots) et la catégorie grammaticale des mots qui les
      composent. Cela nous permet de confirmer les observations faites dans les
      travaux précédents et d'en faire de nouvelles, centrées sur la catégorie
      grammaticale des mots des termes-clés.

      Notre analyse couvre les deux langues de nos ressources (français et
      anglais). Elle se porte sur les collections \textsc{De}ft, \textsc{Duc} et
      SemEval. Dans le but de ne pas biaiser les résultats des évaluations de ce
      travail, l'analyse est effectuée sur un sous-ensemble de ces collections.
      Pour permettre des comparaisons avec des travaux futures, les évaluations
      sont réalisées sur les ensembles de test de nos collections et l'analyse
      est donc réalisée sur les ensembles normalement destinés à
      l'apprentissage. \textsc{Duc} n'étant pas répartie en plusieurs
      sous-ensembles, nous utilisons 208 documents pour l'analyse et 100 pour
      les évaluations.

      ~\\Le tableau~\ref{tab:candidate_selection-train_stats} montre la
      proportion de termes-clés uni-grammes, bi-grammes et tri-grammes, ainsi
      que la proportion de termes-clés multi-mots contenant au moins un mot de
      l'une des sept catégories grammaticales que nous observons en leur
      sein\footnote{ Nous nous focalisons sur les expressions (termes-clés
      multi-mots), car nous avons observé que \TODO{\dots}~\% des termes-clés
      qui sont des mots simples sont des noms. }~: nom commun, nom propre,
      adjectif, verbe, adverbe, préposition et déterminant. Pour obtenir ces
      informations, les termes-clés ont été automatiquement segmentés en mots et
      étiquetés grammaticalement à l'aide des outils utilisés pour prétraiter
      les collections de données (cf
      section~\ref{sec:main-data_description-preprocessing}
      page~\pageref{sec:main-data_description-preprocessing}), puis manuellement
      corrigés.
      \begin{table}[!h]
        \centering
        \begin{tabular}{ll|ccc}
          \toprule
          & & \textbf{\textsc{Duc}} & \textbf{SemEval} & \textbf{\textsc{Deft}}\\
          \hline
          \multicolumn{2}{l|}{\textbf{Taux (en \%) de termes-clés~:}}\\
          & Uni-grammes & 17,1 & 20,2 & 60,2\\
          & Bi-grammes & 60,8 & 53,4 & 24,5\\
          & Tri-grammes & 17,8 & 21,3 & 8,8\\
          \hline
          \multicolumn{2}{l|}{\textbf{Taux (en \%) de termes-clés}} & & &\\
          \multicolumn{2}{l|}{\textbf{contenant au moins un(e)~:}} & & &\\
          & Nom commun & 94,5 & 98,7 & 93,1\\
          & Nom propre & 17,1 & $~~$4,3 & $~~$6,9\\
          & Adjectif & 50,0 & 50,2 & 65,5\\
          & Verbe & $~~$1,0 & $~~$4,0 & $~~$1,0\\
          & Adverbe & $~~$1,6 & $~~$0,7 & $~~$1,3\\
          & Préposition & $~~$0,3 & $~~$1,5 & 31,2\\
          & Déterminant & $~~$0,0 & $~~$0,0 & 20,4\\
          \bottomrule
        \end{tabular}
        \caption{Statistiques concernant les termes-clés de référence des
                 collections \textsc{Deft}, SemEval et \textsc{Duc}
                 \label{tab:candidate_selection-train_stats}}
      \end{table}

      Concernant la taille des termes-clés de référence, ceux composés de un à
      trois mots couvrent plus de 90~\% des termes-clés de références. En
      français, ce sont les uni-grammes qui sont les plus présents, suivis par
      les bi-grammes, tandis qu'en anglais, ce sont les bi-grammes qui sont les
      plus présents, avec des proportions équivalentes d'uni-grammes et de
      tri-grammes. Ces premières observations font écho à celles que nous
      trouvons dans la littérature, nous pouvons en conclure qu'il s'agit de
      propriétés stables des termes-clés. Une approche raisonable peut donc se
      restreindre aux $\{1..3\}$-grammes, à l'instar de celle de
      \newcite{witten1999kea}.

      Concernant les catégories des mots que contiennent les termes-clés de
      référence, nous observons que la quasi-totalité des termes-clés
      contiennent un nom, que ce sont majoritairement des groupes nominaux et
      que la moitié d'entre eux est modifiée par un adjectif. Les autres
      catégories de mots, comme le verbe et l'adverbe sont très peu utilisées.
      L'usage de ces dernières au sein de termes-clés semble être exceptionnel.
      Les déterminants et prépositions ont un usage presque exclusivement
      français. En anglais, les formes composés (par exemple,
      \textit{\og{}nature conservation\fg{}} -- \og{}conservation de la
      nature\fg{}) sont préférées aux formes syntagmatiques (par exemple~:
      \textit{\og{}conservation of nature\fg{}} -- \og{}conservation de la
      nature\fg{}).

      ~\\L'adjectif étant utilisé à plus forte proportion que les catégories
      grammaticales autres que le nom et le nom propre, nous analysons plus
      finement leur nature~: relationnel, composé ou autre (principalement
      qualificatif).
      
      Un adjectif relationnel est un adjectif
      dénominal~\cite{bally1944linguistiquegeneraleetlinguistiquefrancaise}. Il
      est dérivé d'un nom (par exemple~: l'adjectif relationnel
      \og{}culturel\fg{} est dérivé du nom \og{}culture\fg{}) pour lequel il
      établit une relation équivalente à celle exprimée par le complément du nom
      (par exemple~: \og{}héritage culturel\fg{} équivaut à \og{}héritage de la
      culture\fg{}). Caractéristique du discours du
      spécialiste~\cite{maniez2009denominaladjectives}, l'adjectif relationnel
      sert de modificateur pour les noms de catégories, telles que celles de
      Wikipedia (par exemple \og{}héritage culturel\fg{}), catégories qui
      constituent de bons termes-clés
      candidats~\cite{medelyan2008smalltrainingset,eichler2010keywe}.
      
      Un adjectif composé est un adjectif constitué de plusieurs mots (par
      exemple, \og{}socio-culturel\fg{}). Généralement marqué par la présence
      d'un trait d'union, l'adjectif composé indique avec précision la place
      hiérarchique qu'occupe le nom qu'il modifie (par exemple, \og{}évênement
      socio-culturel\fg{} est un hyponyme de \og{}évênement\fg{}).
      
      Pour détecter les adjectifs composés, nous nous limitons à la présence du
      trait d'union, marque de composition en français et en anglais. Pour
      détecter les adjectifs relationnels, nous utilisons une technique simple,
      adaptée (ou adaptable) à plusieurs langues, et ne requérant pas
      nécessairement de données riches. Notre approche se fonde sur les
      assertions suivantes~:
      \begin{enumerate}
        \item{L'adjectif relationnel est dénominal, c'est-à-dire
              \textbf{dérivé d'un
              nom}~\cite{bally1944linguistiquegeneraleetlinguistiquefrancaise}.}
        \item{L'adjectif relationnel est dérivé du nom par
              \textbf{suffixation}~\cite{dubois1999derivation}.}
      \end{enumerate}

      Dans un premier temps, les adjectifs relationnels sont détectés avec une
      base de données lexicale. Si l'adjectif d'un candidat présélectionné est
      marqué comme dérivé d'un nom, alors nous le considérons comme
      relationnel. Pour le français, nous utilisons la base
      WoNeF~\cite{pradet2013wonef} dont la propriété \texttt{[DERIVED]}
      indique que l'adjectif est dérivé d'un nom. Pour l'anglais, nous
      utilisons la base  WordNet~\cite{miller1995wordnet} dont la propriété
      \texttt{[PERTAINYM]} indique que l'adjectif est relationnel.

      Dans un second temps, les adjectifs relationnels qui ne sont pas présents
      dans la base de données lexicale sont détectés à l'aide de leur suffixe.
      Une liste des suffixes les plus productifs pour les adjectifs relationnels
      est utilisée pour identifier les adjectifs relationnels potentiels. En
      français, les suffixes les plus productifs sont \textit{-ain},
      \textit{-aire}, \textit{-al}, \textit{-el}, \textit{-esque},
      \textit{-estre}, \textit{-eux}, \textit{-ien}, \textit{-ier},
      \textit{-if}, \textit{-il}, \textit{-in}, \textit{-ique}, \textit{-ois},
      et \textit{-é}~\cite{guyon1993adjectifsrelationnels}~; en anglais, les
      suffixes utilisés sont \textit{al}, \textit{ant}, \textit{ary},
      \textit{ic}, \textit{ous} et
      \textit{ive}~\cite{grabar2006terminologystructuring}.

      La détection des adjectifs relationnels telle que réalisée dans ce
      travail, n'est pas exacte. En effet, les adjectifs qualificatifs se
      terminant par un suffixe d'adjectif relationnel sont détectés comme
      relationnels, et les adjectifs à usage qualificatif ou relationnel selon
      le contexte~\cite{maniez2009denominaladjectives} sont toujours détectés
      comme relationnels. Les précédentes approches pour identifier les
      adjectifs relationnels (dans le cadre de l'extraction terminologique)
      reposent sur une analyse en
      corpus~\cite{daille2001relationaladjectives,maniez2005automaticrelationaladjectiveidentification,harastani2013relationaladjectivetranslation},
      où il s'agit notamment de trouver des paraphrases avec un complément de
      nom. Dans le contexte de l'extraction de termes-clés, où de larges
      corpus ne sont pas toujours disponibles, les paraphrases ne sont pas
      toujours présentes.

      ~\\Le tableau~\ref{tab:candidate_selection-adjective_categories}montre le
      taux d'adjectifs des termes-clés de référence par catégorie.
      \begin{table}[!ht]
        \centering
          \begin{tabular}{l|ccc}
            \toprule
            & \textbf{\textsc{Duc}} & \textbf{SemEval} & \textbf{\textsc{Deft}}\\
            \hline
            Adjectifs relationnels \hfill(\%) & 53,1 & 43,6 & 87,1\\
            Adjectifs composés \hfill(\%) & 10,6 & 16,4 & $~~$3,3\\
            Autres adjectifs qualificatifs \hfill(\%) & 36,3 & 40,0 & $~~$9,6\\
            \bottomrule
        \end{tabular}
        \caption{Taux d'adjectifs (de termes-clés) par catégorie (relationnel,
                 composé ou qualificatif)}
        \label{tab:candidate_selection-adjective_categories}
      \end{table}
      
      \TODO{revoir}
      Nous observons que la majorité des adjectifs présents au sein des
      termes-clés de référence sont des adjectifs relationnels. Nos propos se
      confirment dans le tableau~\ref{tab:candidate_selection-best_patterns},
      qui montre les patrons grammaticaux les plus fréquents pour les
      termes-clés de référence.
      
      \TODO{revoir}
      Les adjectifs composés sont la réunion de mots équivalents à un adjectif,
      nous parlons aussi de locutions adjectifs (par exemple~:
      \og{}socio-culturel\fg{}). Bien qu'ils ne représentent qu'une faible
      quantité des adjectifs présents au sein des termes-clés de référence, nous
      trouvons les adjectifs composés pertinents en tant que modificateurs de
      termes-clés.
      
      \TODO{revoir}
      Ceux-ci sont présents en nombre non négligeable au sein
      des termes-clés de référence. Cependant, la catégorie des adjectifs
      qualificatifs regroupe un grand nombre d'adjectifs qui ne sont
      intuitivement pas tous pertinent en tant que modificateur au sein d'un
      terme-clés (\TODO{exemple}). \TODO{renforcer l'argumentation en comparant
      la proportion d'adjectifs qualificatis avec la proportion d'adjectifs
      relationnels dans les documents.}

      \begin{table}[!h]
        \centering
        \begin{tabular}{r@{~}|@{~}l@{~}l@{~}l@{~}llr}
          \toprule
          \multicolumn{1}{r@{~}|@{~}}{} & \multicolumn{4}{@{}l}{\textbf{Pattern}} & \textbf{Example} & \textbf{\%}\\
          \hline
          \multirow{5}{*}{\begin{sideways}\textbf{Français}\end{sideways}}
          & \texttt{Nc} & \texttt{rA} & & & \TODO{exemple} & 46,4\\
          & \texttt{NC} & \texttt{Sp} & \texttt{D} & \texttt{Nc} & \TODO{exemple} & 12,5\\
          & \texttt{Nc} & \texttt{Sp} & \texttt{Nc} & & \TODO{exemple} & $~~$8,2\\
          & \texttt{Nc} & \texttt{A} & & & \TODO{exemple} & $~~$4,3\\
          & \texttt{Np} & \texttt{Np} & & & \TODO{exemple} & $~~$3,0\\
          \hline
          \multirow{5}{*}{\begin{sideways}\textbf{Anglais}\end{sideways}}
          & \texttt{Nc} & \texttt{Nc} & & & \TODO{exemple} & 32,5\\
          & \texttt{rA} & \texttt{Nc} & & & \TODO{exemple} & 15,1\\
          & \texttt{A} & \texttt{Nc} & & & \TODO{exemple} & $~~$9,5\\
          & \texttt{Nc} & \texttt{Nc} & \texttt{Nc} & & \TODO{exemple} & $~~$5,3\\
          & \texttt{cA} & \texttt{Nc} & & & \TODO{exemple} & $~~$4,9\\
          \bottomrule
        \end{tabular}
        \caption[
          Patrons grammaticaux les plus fréquents parmi les termes-clés
          français et anglais
        ]{
          Patrons grammaticaux les plus fréquents parmi les termes-clés
          français et anglais. Les classes grammaticales sont exprimées au
          format Multext~\cite{ide1994multext}, sauf \texttt{rA} et \texttt{cA}
          qui représentent, respectivement, un adjectif relationnel et un
          adjectif composé.
          \label{tab:candidate_selection-best_patterns}
        }
      \end{table}

    \subsection{Sélection fine des termes-clés candidats}
    \label{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-modifiers_filtering}
      Pour sélectionner les termes-clés candidats, nous proposons une méthode
      qui se fonde sur les observations ci-avant. Cette méthode commence par
      présélectionner les termes-clés candidats à l'aide d'un patron
      grammatical, puis elle filtre les adjectifs jugés non pertinents.

      \subsubsection{Présélection des termes-clés candidats}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-modifiers_filtering-candidate_pre_selection}
        L'étape de présélection des candidats utilise un patron grammatical
        défini sous la forme d'une expression rationnelle. Celui-ci est appliqué
        aux catégories grammaticales des séquences de mots adjacents dans le
        document et sélectionne celles-ci qui le respectent. Ce patron est
        gourmand, c'est-à-dire qu'il capture les plus longues séquences
        possibles. Ainsi, il n'y a pas de surproduction de candidats qui se
        recouvrent (comme c'est le cas avec les n-grammes) et augmentent le
        risque d'extraire des termes-clés
        redondants~\cite{hasan2014state_of_the_art}.

        D'après les observations de la
        section~\ref{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-analysis_of_keyphrase_properties},
        seuls les noms, les adjectifs, les prépositions et les déterminants sont
        utiles pour sélectionner des candidats permettant une performance
        maximale quasi-optimale. Dans le cas de l'anglais, les prépositions et
        les déterminants sont en proportions très faibles et peuvent être
        ignorés. Dans le cas du français, les prépositions et les déterminant
        couvrent plus de 30~\% des termes-clés de référence, cependant leur
        nombre est tellement important au sein d'un document \TODO{donner les
        chiffres} qu'il est préférable de les ignorés afin d'éviter d'ajouter un
        grand nombre de candidats erronés pouvant dégrader la performance des
        méthodes d'extraction de termes-clés.
        
        Pour le français, nous définissons le patron \texttt{/N+ A?/}, qui
        accepte une séquence de noms (ou noms propres) se terminant
        optionnellement par un adjectif. En français, l'adjectif peut être soit
        antéposé, soit postposé. Le patron que nous avons défini n'accepte que
        les adjectifs postposés pour deux raisons. La première raison est que
        les adjectifs relationnels, que nous jugeons les plus pertinents en tant
        que modificateurs au sein des termes-clés, se trouvent toujours en
        postposition. La seconde raison est que l'antéposition et la
        postposition des adjectifs marquent deux aspects différents du
        discours~: la subjectivité et l'objectivité,
        respectivement~\cite{eskenazi2005adjectifavantapres}. Nous supposons,
        avec l'appui des patrons grammaticaux les plus fréquents présentés dans
        le tableau~\ref{tab:candidate_selection-best_patterns}, que la
        subjectivité n'a pas ça place au sein d'un terme-clé.
        
        Pour l'anglais, nous définissons le parton \texttt{/A? N+/}, qui
        accepte une séquence de noms (ou noms propres) modifié par un adjectifs
        antéposé. En anglais, tous les adjectifs sont antéposés. Ce patron ne
        filtre donc aucun adjectif à cette étape de présélection.

      \subsubsection{Filtrage des adjectifs non pertinents}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-modifiers_filtering-adjective_filtering}
        L'orsqu'un candidat contient un adjectif, notre méthode juge sa
        pertinence en tant que modificateur d'un terme-clé, autrement dit s'il
        apporte au sens du terme-clé. Si l'adjectif n'est pas jugé pertinent,
        alors il est enlevé du terme-clé candidats.

        Toujours d'après les observations et hypothèses de la
        section~\ref{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-analysis_of_keyphrase_properties},
        les adjectifs relationnels et composés sont systématiquement jugés
        pertinents. Dans le cas des adjectifs qualificatifs (autres que
        composés), c'est l'usage des candidats présélectionnés dans le document
        qui détermine leur pertinence. Tout adjectif qualificatif modifiant une
        même séquence de nom plus souvent que cette dernière apparaît de manière
        autonome est jugé pertinent et est conservé en tant que modificateur de
        cette séquence.

        \paragraph{}
        L'algorithme~\ref{algo:candidate_pruning} résume le
        fonctionnement de notre méthode de sélection des termes-clés candidats.
        Les lignes \ref{algo:line:start_preselection} à
        \ref{algo:line:end_preselection} concernent la présélection des
        candidats et les lignes \ref{algo:line:start_filtering} à
        \ref{algo:line:end_filtering} identifient et filtrent les adjectifs
        qualificatifs non pertinent (\TODO{exemple}).
        \begin{algorithm}[h!]
          \SetKwInOut{kwInput}{Entrée}
          \SetKwInOut{kwOutput}{Sortie}
          \SetKwFor{For}{Pour chaque}{faire}{}
          \SetKwIF{If}{ElseIf}{Else}{Si}{alors}{Sinon si}{Sinon}{}
          \SetKw{KwRet}{Retourner}
          \DontPrintSemicolon{}

          \kwInput{document}
          \kwOutput{candidats}
          \BlankLine

          patron $\leftarrow$ Nil\;\label{algo:line:start_preselection}
          \If{\textnormal{document.langue = "francais"}}{
            patron $\leftarrow$ \texttt{/N+ A?/}\;
          }\Else{
            \If{\textnormal{document.langue = "anglais"}}{
              patron $\leftarrow$ \texttt{/A? N+/}\;
            }
          }

          candidats $\leftarrow$ \{\}\;
          candidats\_preliminaires $\leftarrow$ preselection(document, patron)\;\label{algo:line:end_preselection}

          \For{\textnormal{cdt} $\in$ \textnormal{candidats\_preliminaires}}{\label{algo:line:start_filtering}
            \If{$\exists{}\textnormal{mot} \in$ \textnormal{cdt},
            \textnormal{est\_adjectif(mot)} $\wedge$ $\overline{\textnormal{est\_relationnel(mot)}}$ $\wedge$ $\overline{\textnormal{est\_compose(mot)}}$}{
              tete\_cdt $\leftarrow$ cdt $-$ mot\;
              freq\_cdt $\leftarrow$ \textnormal{document.conter(cdt)}\;
              freq\_tete\_cdt $\leftarrow$ \textnormal{document.conter(tete\_cdt)} $-$ freq\_cdt\;
              \If{\textnormal{freq\_cdt} $>$ \textnormal{freq\_tete\_cdt}}{
                candidats $\leftarrow$ candidats $\cup$ \{cdt\}\;
              }\Else{
                candidats $\leftarrow$ candidats $\cup$ \{tete\_cdt\}\;
              }
            }\Else{
              candidats $\leftarrow$ candidats $\cup$ \{cdt\}\;
            }
          }\label{algo:line:end_filtering}

          \Return{\textnormal{candidats}}

          \caption{Sélection fine des termes-clés candidats
                   \label{algo:candidate_pruning}}
        \end{algorithm}

    \subsection{Évaluation}
    \label{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation}
      Afin de montrer la validité de notre méthode de sélection de candidats,
      nous réalisons deux expériences~: l'une intrinsèque, où les ensembles de
      termes-clés candidats de différentes méthodes de sélections sont comparés
      qualitativement, l'autre extrinsèque, où les différentes méthodes de
      sélections sont comparés d'après les performances de deux méthodes
      d'extraction de termes-clés.

      \subsubsection{Méthodes de référence}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-baselines}
        Nous comparons notre méthode de sélection de termes-clés candidats a
        trois autres méthodes utilisées dans les travaux précédents en
        extraction automatique de termes-clés~:
        \begin{itemize}
          \item{sélection des n-grammes ($1 \leq n \leq 3$)~;}
          \item{sélection des plus longues séquences de noms et d'adjectifs~:
                \texttt{/(N|A)+/}~;}
          \item{sélection des \textit{NP-chunks}~:}
          \begin{itemize}
            \item{\texttt{/Np+|(A? Nc A+)|(A Nc)|Nc+/} en français~;}
            \item{\texttt{/Np+|(A+ Nc)|Nc+/} en anglais.}
          \end{itemize}
        \end{itemize}

        Pour l'évaluation extrinsèque, nous utilisons deux méthodes d'extraction
        automatique de termes-clés très utilisées~: la méthode non supervisée
        \textsc{Tf-Idf} et la méthode supervisée \textsc{Kea}. Bien que des
        méthodes plus récentes donnent de meilleures performances que
        \textsc{Tf-Idf} et \textsc{Kea}~\cite{kim2010semeval}, ces dernières
        sont reproductibles et présentent l'avantage d'être robustes.

      \subsubsection{Collections de données}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-evaluation_data}
        Pour évaluer ce travail, nous utilisons les ensembles de test des
        collections \textsc{Deft}, SemEval et \textsc{Duc}, dont les ensembles
        d'entraînement sont utilisées pour l'analyse proposée dans la
        section~\ref{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-analysis_of_keyphrase_properties}.
      
      \subsubsection{Mesures d'évaluation}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-evaluation_measures}
        Pour évaluer la qualité des ensembles de termes-clés candidats
        sélectionnés, nous comparons leur nombre de candidats (Cand./Soc.), le
        rappel maximum (R$_\textnormal{max}$) pouvant être atteint et un ratio
        exprimant le compromis en ces deux critères (QR)~:
        \begin{align}
          \textnormal{QR} &= \frac{\textnormal{R}_{\textnormal{max}}}{\textnormal{Cand./Doc.}} \times 100
        \end{align}
        Plus QR est élevé, meilleure est la qualité de l'ensemble des
        termes-clés candidats sélectionnés.

        Les performances des méthodes d'extraction de termes-clés sont exprimées
        en termes de précision (P), rappel (R) et f-mesure (f1-mesure, F). En
        accord avec l'évaluation menée dans les travaux précédents, nous
        considérons correcte l'extraction d'une variante flexionnelle d'un
        terme-clé de référence~\cite{kim2010semeval}. Les opérations de
        comparaison entre les termes-clés de référence et les termes-clés
        extraits sont donc effectuées à partir de la racine des mots qui les
        composent, d'après la méthode de \newcite{porter1980suffixstripping}.

      \subsubsection{Évaluation intrinsèque}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-intrinsic_evaluation}
        L'évaluation intrinsèque a pour objectif d'évaluer la qualité de
        l'ensemble des termes-clés candidats sélectionnés par notre méthode
        (LR-NP, pour \textsc{Linguistically-Refined Noun Phrases}) et
        de la comparer à celle des ensembles de termes-clés sélectionnés par les
        méthodes de référence. Nous faisons l'hypothèse que plus une
        méthode de sélection de candidats permet un rappel maximum élevé
        (quasi-optimal) tout en limitant la quantité de termes-clés candidats
        sélectionnés, alors plus elle fournit un ensemble de candidats de bonne
        qualité.

        Le tableau~\ref{tab:candidate_extraction_statistics} présente les
        résultats de l'évaluation intrinsèque. Le nombre de candidats
        sélectionnés par chaque méthode, le rappel maximum pouvant être atteint
        avec ceux-ci et la mesure QR sont reportés pour chacune des
        trois collections de données utilisées pour cette évaluation.
        \begin{table}[!h]
          \centering
          \resizebox{\linewidth}{!}{
            \begin{tabular}{r|ccc|ccc|ccc}
              \toprule
              \multirow{2}{*}[-2pt]{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{DUC}} & \multicolumn{3}{c|}{\textbf{SemEval}} & \multicolumn{3}{c}{\textbf{DEFT}}\\
              \cline{2-10}
              & Cand./Doc. & R$_{\text{max}}$ & QR & Cand./Doc. & R$_{\text{max}}$ & QR & Cand./Doc. & R$_{\text{max}}$ & QR\\
              \hline
              n-grammes & $~~~$596.2 & \textbf{90.8} & 15.2 & 2580.5 & \textbf{72.2} & $~~$2.8 & 4070.2 & \textbf{74.1} & $~~~$1.8\\
              \texttt{/(N|A)+/} & $~~~$155.6 & 88.7 & 57.0 & $~~~$646.5 & 62.4 & $~~$9.7 & $~~~$914.5 & 61.1 & $~~$6.7\\
              \textit{NP-chunks} & $~~~$149.9 & 76.0 & 50.7 & $~~~$598.4 & 56.6 & $~~$9.5 & $~~~$812.3 & 63.0 & $~~$7.8\\
              LR-NP & \textbf{$~~~$143.8} & 85.3 & \textbf{59.3} & \textbf{$~~~$538.2} & 59.4 & \textbf{11.0} & \textbf{$~~~$738.2} & 60.1 & \textbf{$~~$8.1}\\
              \bottomrule
            \end{tabular}
          }
          \caption{Résultats de l'évaluation intrinsèque des méthodes de
                   sélection des termes-clés candidats
                   \label{tab:candidate_extraction_statistics}}
        \end{table}
        
        Globalement, nous remarquons que notre méthode sélectionne le moins de
        candidats sans nécessairement induire le moins bon rappel maximum
        (obtenu avec les \textit{NP-chunks}).
        C'est, sans surprise, la sélections des n-grammes qui induit le meilleur
        rappel maximum. Celui-ci est très proche du rappel maximum optimal, mais
        au prix d'un nombre de candidats 4 à 5 fois supérieur à celui des autres
        méthodes. Comme le montre la mesure de compromis entre nombre de
        candidats sélectionnés et rappel maximum (QR), notre méthode
        est de meilleure qualité que les autres, suivit par la méthode de
        sélection des \texttt{/(N|A)+/}, par la méthode de sélection des
        \textit{NP-chunks} et, de loin, par la méthode de sélection des
        n-grammes.

      \subsubsection{Évaluation extrinsèque}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-extrinsic_evaluation}
        L'évaluation extrinsèque a pour objectif d'évaluer l'efficacité de notre
        méthode de sélection de termes-clés en situation réelle d'extraction de
        termes-clés et de la comparer à celle des méthodes de référence.
        Il s'agit aussi de valider notre hypothèse par laquelle plus une méthode
        de sélection de candidats permet un rappel maximum élevé tout en
        limitant la quantité de termes-clés candidats sélectionnés, alors plus
        elle fournit un ensemble de candidats de bonne qualité.

        Le tableau~\ref{tab:keyphrase_extraction_results_with_filtering}
        présente les résultats de l'évaluation extrinsèque. La performance, en
        termes de précision, rappel et f-mesure, des méthodes \textsc{Tf-Idf} et
        \textsc{Kea} est reportée pour chacune des trois collections de données
        utilisées pour cette évaluation.
        \begin{table}[h!]
          \centering
          \resizebox{\linewidth}{!}{
            \begin{tabular}{r@{~}|c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c}
              \toprule
              \multirow{2}{*}[-2pt]{\textbf{Method}} & \multicolumn{6}{c@{~}|@{~}}{\textbf{DUC}} & \multicolumn{6}{c@{~}|@{~}}{\textbf{SemEval}} & \multicolumn{6}{c}{\textbf{DEFT}}\\
              \cline{2-19}
              & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c@{~}|@{~}}{KEA} & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c@{~}|@{~}}{KEA} & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c}{KEA}\\
              \cline{2-19}
              & P & R & F & P & R & F & P & R & F & P & R & F & P & R & F & P & R & F\\
              \hline
              n-grammes & 14.3 & 19.0 & 16.1$~~$ & 12.0 & 16.6 & 13.7$~~$ & $~~$9.0 & $~~$6.6 & $~~$7.2$~~$ & 19.4 & 13.7 & 15.9 & $~~$6.7 & 12.5 & $~~$8.6 & 13.4 & 25.3 & 17.3\\
              \texttt{/(N|A)+/} & 24.2 & 31.7 & 27.0$~~$ & \textbf{14.5} & 19.9 & 16.5$~~$ & 11.7 & $~~$7.9 & $~~$9.3$~~$ & 19.6 & 13.7 & 16.0 & $~~$9.5 & 17.6 & 12.1 & 14.1 & 26.3  &18.1\\
              \textit{NP-chunks} & 21.1 & 28.1 & 23.8$~~$ & 13.5 & 18.6 & 15.4$~~$ & 11.9 & $~~$8.0 & $~~$9.5$~~$ & 19.5 & 13.7 & 16.0 & $~~$9.6 & 17.9 & 12.3 & 14.3 & 26.8 & 18.4\\
              LR-NP & \textbf{24.3} & \textbf{32.0} & \textbf{27.2$^\dagger$} & \textbf{14.5} & \textbf{20.0} & \textbf{16.6$^\ddagger$} & \textbf{12.4} & \textbf{$~~$8.4} & \textbf{$~~$9.9$^\ddagger$} & \textbf{20.4} & \textbf{14.4} & \textbf{16.7}& \textbf{10.1} & \textbf{18.5} & \textbf{12.9} & \textbf{14.4} & \textbf{27.0} & \textbf{18.6}\\
              \bottomrule
            \end{tabular}
          }
          \caption[
            Résultats de \textsc{Tf-Idf} et \textsc{Kea} selon la
            méthode de sélection des termes-clés candidats utilisée
          ]{
            Résultats de \textsc{Tf-Idf} et \textsc{Kea} d'après la
            méthode de sélection des termes-clés candidats utilisée.
            $\ddagger$ indique une amélioration significative par rapport à
            toutes les autres méthodes de sélection de candidats et $\dagger$
            indique une amélioration significative par rapport à toutes les
            méthodes sauf celle qui extrait les \texttt{/(N|A)+/}, à 0.001 pour
            le t-test de Student.
           \label{tab:keyphrase_extraction_results_with_filtering}}
        \end{table}

        Globalement, la performance des méthodes d'extraction de termes-clés est
        corrélée à la qualité de l'ensemble des termes-clés candidats
        sélectionnés. Les candidats sélectionnés avec notre méthode induisent
        les meilleures performances dans les six cas de figure étudiés et, dans
        la moitié des cas, l'amélioration vis-à-vis des méthodes de référence
        est significative. Au delà de montrer la pertinence de filtrer certains
        adjectifs lors de la sélection des termes-clés candidats, les résultats
        montrent la validité de notre hypothèse par laquelle plus une méthode de
        sélection de candidats permet un rappel maximum élevé tout en limitant
        la quantité de termes-clés candidats sélectionnés, alors plus
        elle fournit un ensemble de candidats de bonne qualité et plus aisée
        sera l'extraction de termes-clés.

    \subsection{Bilan}
    \label{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-conclusion}
      Avec ce travail, nous proposons une méthode de sélection des termes-clés
      candidats d'un document. Développée à l'issue d'une analyse des propriétés
      linguistiques des termes-clés de référence de trois collections de
      données, notre méthode préselectionne des termes-clés candidats composés
      uniquement de noms et d'au plus un adjectif, puis détermine si l'adjectif
      des candidats apporte du sens selon sa catégorie (relationnel, composé ou
      qualificatif) et son usage dans le document. Vis-à-vis des méthodes de
      sélection de termes-clés candidats les plus utilisées, celle-ci présente
      l'avantage de sélectionner moins de candidats sans réduire
      significativement le nombre de candidats positifs qui s'y trouvent. La
      qualité de l'ensemble de candidats proposés est donc supérieure et permet
      de réduire aussi bien le temps de traitement pour l'extraction de
      termes-clés que les risques d'erreurs.

  %-----------------------------------------------------------------------------

  \section{Extraction automatique non supervisée de termes-clés}
  \label{sec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction}
    Dans cet section, nous présentons TopicRank, une méthode non supervisée à
    base de graphe pour l'extraction automatique de termes-clés. Ce travail se
    fonde sur celui de \newcite{mihalcea2004textrank}, qui ont proposé TextRank.
    Notre objectif est de résoudre les faiblesses de l'approche à base de
    graphe, que nous identifions dans le
    \ANNOTATE{chapitre~\ref{chap:main-state_of_the_art}
    (page~\pageref{chap:main-state_of_the_art})}{état de l'art}.

    \TODO{enlever le paragraphe precedent et intégrer celui-ci}
    L'ordonnancement des unités textuelles du document, afin de déterminer
    lesquelles sont les plus importantes vis-à-vis de son contenu, est
    principalement réalisé avec des approches non supervisées. Parmi elles, nous
    nous intéressons à l'approche à base de graphe. Celle-ci consiste à
    représenter le document sous la forme d'un graphe de cooccurrences de mots
    et à appliquer à ce graphe un algorithme pour identifier les n\oe{}uds
    (mots) les plus centraux dans le graphe. Dans notre travail, nous remettons
    en question l'ordonnancement des mots alors que les termes-clés peuvent être
    des expressions multi-mots. Nous groupons les termes-clés candidats qui
    expriment le même sujet et proposons d'ordonner ces sujets plutôt que les
    mots.

    Les méthodes à base de graphe actuelles déterminent l'importance des mots du
    document, puis utilisent cette importance soit pour générer les
    termes-clés~\cite{mihalcea2004textrank}, soit pour déterminer l'importance
    des termes-clés candidats en faisant la somme du score d'importance de leurs
    mots~\cite{wan2008expandrank}. Nous jugeons qu'il est plus pertinent
    d'utiliser l'algorithme d'ordonnancement à base de graphe pour ordonner
    directement les termes-clés candidats et ainsi éviter les problèmes de
    redondance que nous évoquons dans le
    \ANNOTATE{chapitre~\ref{chap:main-state_of_the_art}
    (page~\pageref{chap:main-state_of_the_art})}{état de l'art} et que nous montrons dans
    l'exemple \TODO{ref vers l'exemple à mettre dans l'état de l'art}
    (\TODO{page ???}).
    
    En plus de cela, les méthodes actuelles ne tiennent pas compte du phénomène
    de variation lexicale, qui consiste à utiliser des unités textuelles
    différentes d'un point de vue lexicale mais équivalentes d'un point de vue
    sémantique afin d'éviter les répétitions dans le texte. Ne pas tenir compte
    de ce phénomène engendre une dispersion, dans le graphe, d'informations
    relatives à un même sujet.
    
    Enfin, les expériences réalisées dans le travail de
    \newcite{mihalcea2004textrank} et dans celui de \newcite{wan2008expandrank}
    montrent un comportement marginal des différentes approches à base de graphe
    vis-à-vis de la valeur de la fenêtre de cooccurrence. Les performances
    relevées dans les expériences de \newcite{mihalcea2004textrank} montrent que
    plus la fenêtre de cooccurrence est élevée, moins l'extraction de
    termes-clés est performante, alors que celles relevées par
    \newcite{wan2008expandrank} montrent le comportement inverse. \TODO{mettre
    les courbes de Mihalcea et celles de Wan}

    Avec TopicRank, nous proposons une solution pour résoudre les trois
    problèmes énoncés ci-dessus. Dans la suite, nous présentons TopicRank, nous
    l'évaluons, nous le comparons à l'existant, puis nous en analysons les
    erreurs.

    \subsection{TopicRank}
    \label{subsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank}
      TopicRank est une méthode à base de graph pour extraire des termes-clés
      représentant chacun un sujet important dans le document.
      % Quel en est le fonctionnement général ?
      Elle repose sur les quatre étapes suivantes, qui sont détaillées dans
      la suite~: identification des sujets, construction d'un graphe de sujets,
      ordonnancement des sujets et sélection du terme-clé candidat le plus
      représentatif de chaque sujet.

      \subsubsection{Identification des sujets}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-topic_identification}
        Dans ce travail, un sujet représente un thème du document qui est
        véhiculé par une ou plusieurs unités textuelles partageant le même
        sens. Il s'agit d'un groupe de termes-clés candidats qui partagent le
        plus d'unités de sens, de mots.

        % Que nous faut-il pour identifier les sujets ?
        La première étape de l'identification des sujets consiste à sélectionner
        les termes-clés candidats.
        % Quels candidats composent les sujets ?
        Pour ce travail, nous suivons \newcite{wan2008expandrank} et
        sélectionnons les plus longues séquences de noms, de noms propres et
        d'adjectifs à partir du patron grammatical suivant~:\texttt{/(N|A)+}.
        Celui-ci présente l'avantage d'être simple et adapté à plusieurs
        langues, telles que les langues latines (anglais, français, etc.),
        lorsque les outils d'étiquetage grammatical sont disponibles pour la
        langue concernée. De plus, ce patron est gourmand, c'est-à-dire qu'il
        capture les séquences les plus longues qui le respectent, et il est donc
        adapté pour le groupement que nous effectuons ensuite.

        % Comment détectons nous deux candidats appartenant au même sujet ?
        La seconde étape de l'identification des sujets consiste à grouper les
        termes-clés candidats lorsqu'ils appartiennent au même sujet. Afin de
        proposer une méthode qui n'utilise pas de données
        supplémentaires, nous optons pour un groupement naïf des
        candidats. Deux candidats $c_1$ et $c_2$ sont groupés selon leur degré
        de similarité de Jaccard. Ils sont considérés comme des sacs de
        mots tronqués par la méthode de racinisation\footnote{Cette
        racinisation a pour effet de grouper les candidats qui varient
        uniquement en termes de flexion ou de dérivation.} de
        \newcite{porter1980suffixstripping} et leur degré de similarité est
        d'autant plus élevé qu'ils partagent de mots racinisés~:
        \begin{align}
          \text{sim}(c_1, c_2) &= \frac{|\textnormal{Porter}(c_1)\ \cap\ \textnormal{Porter}(c_2)|}{|\textnormal{Porter}(c_1)\ \cup\ \textnormal{Porter}(c_2)|} \label{equa:jaccard}
        \end{align}
        Cette mesure est naïve, car l'ordre des mots, leur ambiguïté
        et leur synonymie ne sont pas pris en compte. À cela s'ajoute
        aussi des erreurs introduites par l'usage de la méthode de
        \newcite{porter1980suffixstripping} (par exemple les mots
        \og{}empire\fg{} et \og{}empirique\fg{} partagent le même radical
        \og{}empir\fg{}).

        % Comment groupons nous les candidats d'un même sujet ?
        La similarité est calculée entre toutes les paires de candidats. Nous
        appliquons l'algorithme de groupement hiérarchique agglomératif
        (\textit{Hierarchical Agglomerative Clustering -- \textsc{HAC}}) pour
        grouper les candidats les plus similaires. Initialement, chaque candidat
        représente un groupe et, jusqu'à l'obtention d'un nombre prédéfini de
        groupes, ceux ayant la plus forte similarité sont unis pour n'en former
        qu'un seul. Afin de ne pas fixer le nombre de sujets à créer comme
        condition d'arrêt de l'algorithme, nous définissons un seuil de
        similarité $\zeta$ entre les groupes deux à deux. Cette similarité entre
        deux groupes est déterminée à partir de la similarité de Jaccard
        calculée entre les candidats de chaque groupe (\TODO{algorithme}). Il
        existe trois stratégies pour calculer la similarité entre deux groupes~:
        \begin{itemize}
          \item{simple~: la plus grande valeur de similarité entre les candidats
                des deux groupes sert de similarité entre eux~;}
          \item{complète~: la plus petite valeur de similarité entre les
                candidats des deux groupes sert de similarité entre eux~;}
          \item{moyenne~: la moyenne de toutes les similarités entre les
                candidats des deux groupes sert de similarité entre eux
                (compromis entre les stratégies simple et complète).}
        \end{itemize}
        L'une ou l'autre de ces stratégies est à privilégier en fonction du type
        des candidats extraits. Pour des candidats qui ont de forts
        recouvrements, tels que les n-grammes, il serait plus pertinent
        d'utiliser la stratégie complète qui est la moins agglomérative. Dans le
        cas de TopicRank, où les candidats sont de meilleure qualité que les
        n-grammes, la stratégie moyenne est une meilleure alternative.

        \TODO{Exemple étape par étape}
        \TODO{illustrer les stratégies dans l'exemple (ou un autre ?)}

      \subsubsection{Construction du graphe}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-graph_construction}
        Afin d'identifier les sujets les plus importants du documents, nous
        utilisons un graphe qui représente tous les sujets du document avec les
        relations qu'ils entretiennent.

        % Comment le graphe est-il construit ?
        Soit le graphe complet $G = (N, A)$ non orienté, composé d'un ensemble
        de n\oe{}uds $N$ et d'arêtes $A$\footnote{$A = \{(n_1, n_2)\ |\
        \forall{n_1, n_2 \in N}, n_1 \neq n_2\}$, car $G$ est un graphe
        complet.}. Les sujets sont représentés par les n\oe{}uds du graphe et
        les arêtes qui les connectent représentent la force de leur lien
        sémantique. Contrairement aux travaux précédent, nous ne souhaitons pas
        utiliser de fenêtre de cooccurrence et ne pouvons donc pas exprimer la
        force du lien sémantique entre deux sujets par leur nombre de
        cooccurrences. Pour préserver l'intuition derrière l'usage du nombre de
        cooccurrences, nous connectons tous les n\oe{}uds deux à deux et
        exprimons la force de leur lien sémantique à partir de la distance (en
        nombre de mots) qui les sépare dans le document~:
        \begin{align}
          \text{poids}(n_i, n_j) &= \sum_{c_i \in n_i}\ \sum_{c_j \in n_j} \text{dist}(c_i, c_j) \label{math:ponderation}\\
          \text{dist}(c_i, c_j) &= \sum_{p_i \in \text{pos}(c_i)}\ \sum_{p_j \in \text{pos}(c_j)} \frac{1}{|p_i - p_j|} \label{math:distance}
        \end{align}
        où $\text{poids}(n_i, n_j)$ est le poids de l'arête entre les sujets
        $n_i$ et $n_j$, et où $\text{dist}(c_i, c_j)$ représente la force
        sémantique entre les candidats $c_i$ et $c_j$, calculée à partir de
        leurs positions respectives, $\text{pos}(c_i)$ et $\text{pos}(c_j)$,
        dans le document.

      \subsubsection{Ordonnancement des sujets}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-topic_ranking}
        % Quel est le but de l'ordonnancement ?
        % Comment est-il effectué ?
        L'ordonnancement des sujets doit établir un ordre d'importance des
        sujets du document.
        % Comment le graphe est-il utilisé pour ordonner les sujets ?
        % Quelle est l'intuition de PageRank/TextRank ?
        Pour cela, nous appliquons l'algorithme d'ordonnancement de
        SingleRank~\cite{wan2008expandrank} à notre graphe
        de sujets. Cet algorithme se fonde sur le principe de recommandation,
        ou de vote, c'est-à-dire un sujet est d'autant plus important s'il est
        fortement connecté avec un grand nombre de sujets et si les sujets avec
        lesquels il est fortement connecté sont importants~:
        \begin{align}
          S(n_i) &= (1 - \lambda) + \lambda \times \sum_{n_j \in A(n_i)} \frac{\text{poids}(n_j, n_i) \times S(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} \text{poids}(n_i, n_j)}
        \end{align}
        où $A(n_i)$ est l'ensemble des sujets\footnote{$A(n_i) = \{n_j\ |\
        \forall{n_j \in N}, n_j \neq n_i\}$, car $G$ est un graphe complet.}
        connectés au sujet $n_i$ et où $\lambda$ est un facteur d'atténuation.
        Défini entre 0 et 1, ce dernier peut être considéré comme la probabilité
        pour que le sujet $n_i$ soit utilisé par recommandation. Nous suivons
        \newcite{brin1998pagerank} et fixons $\lambda$ à 0,85.

      \subsubsection{Sélection des termes-clés}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-keyphrase_selection}
        % De quoi s'agit-il ?
        La sélection des termes-clés est la dernière étape de TopicRank. Elle
        consiste à chercher les termes-clés candidats qui représentent le mieux
        les sujets importants. Dans le but de ne pas extraire de termes-clés
        redondants, un seul candidat est sélectionné par sujet.
        % Quel en est le but ?
        Ainsi, pour $k$ sujets, $k$ termes-clés non redondants couvrant
        exactement $k$ sujets sont extraits.

        % Quelles sont les différentes stratégies envisageable ?
        La difficulté de ce principe de sélection réside dans la capacité à
        trouver parmi plusieurs termes-clés candidats d'un même sujet celui qui
        le représente le mieux. Nous proposons trois stratégies de sélection
        pouvant répondre à ce problème~:
        \begin{itemize}
          \item{position~: en supposant qu'un sujet est tout d'abord
                introduit par sa forme la plus appropriée, le terme-clé
                candidat sélectionné pour un sujet est celui qui apparaît en
                premier dans le document~;}
          \item{fréquence~: en supposant que la forme la plus représentative
                d'un sujet est sa forme la plus fréquente, le terme-clé candidat
                sélectionné pour un sujet est celui qui est le plus fréquent
                dans le document~;}
          \item{centroïde~: le terme-clé candidat sélectionné pour un sujet
                est celui qui est le plus similaire aux autres candidats du
                sujet (voir l'équation~\ref{equa:jaccard}).}
        \end{itemize}
        % Laquelle des trois stratégies semble être la mieux ?
        Parmi ces trois stratégies, celle qui semble la plus appropriée est la
        stratégie position. Sélectionner les candidats les plus fréquents risque
        de ne pas être une solution stable selon les genres de documents, en
        particulier selon leur taille~; sélectionner les centroïdes risque de ne
        pas fournir les termes-clés les plus précis (informatif), car celui-ci
        représente le tronc commun à la majorité des candidats.

      \subsubsection{Exemple}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-example}
        \TODO{exemple}

    \subsection{Évaluation}
    \label{subsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation}
      Pour valider notre approche, nous réalisons deux série d'expériences. Une
      première série pour déterminer les paramètres optimaux de TopicRank et
      une seconde séries pour le comparer aux travaux précédents, ainsi
      que pour analyser l'impact de chacune de nos contributions.
      
      \subsubsection{Méthodes de référence}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-baselines}
        % Comment les baselines sont-elles choisies ?
        Dans nos expériences, nous comparons TopicRank à trois autres
        méthodes non supervisées d'extraction automatique de termes-clés. Nous
        choisissons TextRank et SingleRank, les deux méthodes qui sont la
        fondation des méthodes à base de graphe, et la méthode TF-IDF.

      \subsubsection{Collections de données}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-evaluation_data}
        Pour évaluer ce travail, nous utilisons quatre des cinq collections dont
        nous disposons\footnote{La collection de données Termith est utilisée
        pour évaluer manuellement nos travaux. Les évaluations manuelles sont
        présentées dans le chapitre \TODO{6} (page \TODO{}).}. Nous utilisons
        les deux collections d'articles journalistiques \textsc{Duc} (anglais)
        et Wikinews (français), ainsi que les deux collections d'articles
        scientifiques SemEval (anglais) et \textsc{Deft} (français).

      \subsubsection{Mesures d'évaluation}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-evaluation_measures}
        Les performances des méthodes d'extraction de termes-clés sont exprimées
        en termes de précision (P), rappel (R) et f-mesure (f1-mesure, F). En
        accord avec l'évaluation menée dans les travaux précédents, nous
        considérons correcte l'extraction d'une variante flexionnelle d'un
        terme-clé de référence~\cite{kim2010semeval}. Les opérations de
        comparaison entre les termes-clés de référence et les termes-clés
        extraits sont donc effectuées à partir de la racine des mots qui les
        composent, selon la méthode de \newcite{porter1980suffixstripping}.

      \subsubsection{Analyse empirique de TopicRank}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-empirical_analysis_of_topicrank}
        Dans cette section, nous effectuons une première série d'expériences
        afin de déterminer quelle est la configuration optimale de TopicRank. En
        utilisant les ensembles d'entraînement de SemEval et de \textsc{Deft},
        nous réalisons deux expériences durant lesquelles nous faisons varier,
        dans un premier temps, le seuil de similarité ($\zeta$) et la stratégie
        de groupement (simple, complète et moyenne), puis dans un second temps,
        la stratégie de sélection du terme-clé candidat le plus représentatif de
        chacun des sujets les plus importants.
        \begin{figure}
          \centering
          \subfigure[SemEval]{
            \begin{tikzpicture}
              \pgfkeys{/pgf/number format/.cd, use comma, fixed}
              \begin{axis}[axis lines=middle,
                           x=0.37\linewidth,
                           xtick={0.0, 0.2, ..., 1.2},
                           xmin=0.0,
                           xmax=1.05,
                           xlabel=$\zeta$,
                           x label style={anchor=west},
                           y=0.012\textheight,
                           ytick={0, 5, 10, 15},
                           ymin=0,
                           ymax=18,
                           ylabel=F,
                           y label style={anchor=south}]
                % simple
                \addplot[green!66, mark=x] coordinates{
                  (0.05, 4.2)
                  (0.10, 4.2)
                  (0.15, 4.4)
                  (0.20, 4.7)
                  (0.25, 4.9)
                  (0.30, 5.3)
                  (0.35, 7.4)
                  (0.40, 7.4)
                  (0.45, 7.3)
                  (0.50, 7.3)
                  (0.55, 7.5)
                  (0.60, 7.5)
                  (0.65, 7.5)
                  (0.70, 8.0)
                  (0.75, 8.0)
                  (0.80, 8.0)
                  (0.85, 8.0)
                  (0.90, 8.0)
                  (0.95, 8.0)
                  (1.00, 8.0)
                };
                % complet
                \addplot[cyan!66, mark=+] coordinates{
                  (0.05, 11.5)
                  (0.10, 11.5)
                  (0.15, 10.9)
                  (0.20, 10.3)
                  (0.25, 9.3)
                  (0.30, 7.8)
                  (0.35, 7.6)
                  (0.40, 7.6)
                  (0.45, 7.5)
                  (0.50, 7.5)
                  (0.55, 7.5)
                  (0.60, 7.5)
                  (0.65, 7.6)
                  (0.70, 8.0)
                  (0.75, 8.0)
                  (0.80, 8.0)
                  (0.85, 8.0)
                  (0.90, 8.0)
                  (0.95, 8.0)
                  (1.00, 8.0)
                };
                % moyen
                \addplot[red!66, mark=o] coordinates{
                  (0.05, 12.2)
                  (0.10, 11.7)
                  (0.15, 11.2)
                  (0.20, 11.4)
                  (0.25, 11.1)
                  (0.30, 10.2)
                  (0.35, 8.7)
                  (0.40, 7.7)
                  (0.45, 7.7)
                  (0.50, 7.5)
                  (0.55, 7.6)
                  (0.60, 7.6)
                  (0.65, 7.5)
                  (0.70, 8.0)
                  (0.75, 8.0)
                  (0.80, 8.0)
                  (0.85, 8.0)
                  (0.90, 8.0)
                  (0.95, 8.0)
                  (1.00, 8.0)
                };
                \draw[thick] ({axis cs:0.05,0}|-{rel axis cs:0,1}) -- ({axis cs:0.05,0}|-{rel axis cs:0,0}) [color=red!66];
                \draw[densely dashed] ({axis cs:0.20,0}|-{rel axis cs:0,1}) -- ({axis cs:0.20,0}|-{rel axis cs:0,0}) [color=black!66];
                \node at (axis cs:0.05,17.5) [color=red!66, anchor=west] {\tiny{0,05}};
                \node at (axis cs:0.20,17.5) [color=black!66, anchor=west] {\tiny{0,20}};
                \legend{Simple, Complète, Moyenne}
              \end{axis}
            \end{tikzpicture}
          }
          \subfigure[\textsc{Deft}]{
            \begin{tikzpicture}
              \pgfkeys{/pgf/number format/.cd, use comma, fixed}
              \begin{axis}[axis lines=middle,
                           x=0.37\linewidth,
                           xtick={0.0, 0.2, ..., 1.2},
                           xmin=0.0,
                           xmax=1.05,
                           xlabel=$\zeta$,
                           x label style={anchor=west},
                           y=0.012\textheight,
                           ytick={0, 5, 10, 15},
                           ymin=0,
                           ymax=18,
                           ylabel=F,
                           y label style={anchor=south}]
                % simple
                \addplot[green!66, mark=x] coordinates{
                  (0.05, 8.6)
                  (0.10, 8.6)
                  (0.15, 8.6)
                  (0.20, 8.6)
                  (0.25, 8.6)
                  (0.30, 8.9)
                  (0.35, 11.1)
                  (0.40, 11.1)
                  (0.45, 11.2)
                  (0.50, 11.2)
                  (0.55, 15.3)
                  (0.60, 15.3)
                  (0.65, 15.3)
                  (0.70, 15.6)
                  (0.75, 15.6)
                  (0.80, 15.6)
                  (0.85, 15.6)
                  (0.90, 15.6)
                  (0.95, 15.6)
                  (1.00, 15.6)
                };
                % complet
                \addplot[cyan!66, mark=+] coordinates{
                  (0.05, 15.8)
                  (0.10, 15.8)
                  (0.15, 15.8)
                  (0.20, 15.8)
                  (0.25, 15.9)
                  (0.30, 15.5)
                  (0.35, 16.1)
                  (0.40, 16.1)
                  (0.45, 16.1)
                  (0.50, 16.1)
                  (0.55, 15.6)
                  (0.60, 15.6)
                  (0.65, 15.6)
                  (0.70, 15.6)
                  (0.75, 15.6)
                  (0.80, 15.6)
                  (0.85, 15.6)
                  (0.90, 15.6)
                  (0.95, 15.6)
                  (1.00, 15.6)
                };
                % moyen
                \addplot[red!66, mark=o] coordinates{
                  (0.05, 13.8)
                  (0.10, 13.9)
                  (0.15, 14.9)
                  (0.20, 15.4)
                  (0.25, 15.2)
                  (0.30, 15.3)
                  (0.35, 15.3)
                  (0.40, 15.5)
                  (0.45, 15.8)
                  (0.50, 15.9)
                  (0.55, 15.4)
                  (0.60, 15.5)
                  (0.65, 15.6)
                  (0.70, 15.6)
                  (0.75, 15.6)
                  (0.80, 15.6)
                  (0.85, 15.6)
                  (0.90, 15.6)
                  (0.95, 15.6)
                  (1.00, 15.6)
                };
                \draw[thick] ({axis cs:0.50,0}|-{rel axis cs:0,1}) -- ({axis cs:0.50,0}|-{rel axis cs:0,0}) [color=red!66];
                \draw[densely dashed] ({axis cs:0.20,0}|-{rel axis cs:0,1}) -- ({axis cs:0.20,0}|-{rel axis cs:0,0}) [color=black!66];
                \node at (axis cs:0.50,17.5) [color=red!66, anchor=west] {\tiny{0,50}};
                \node at (axis cs:0.20,17.5) [color=black!66, anchor=west] {\tiny{0,20}};
              \end{axis}
            \end{tikzpicture}
          }
          \caption[Résultats de l'extraction de dix termes-clés avec TopicRank,
                   en fonction de la stratégie de regroupement et de la valeur
                   du seuil de similarité $\zeta$]{
            Résultats de l'extraction de dix termes-clés avec TopicRank, en
            fonction de la stratégie de regroupement et de la valeur du seuil
            de similarité $\zeta$, sur les ensembles d'entraînement de
            SemEval et de \textsc{Deft}
            \label{fig:variation_du_seuil_de_similarite}
          }
        \end{figure}

        % Variation du seuil de similarité et de la stratégie de groupement
        La figure~\ref{fig:variation_du_seuil_de_similarite} présente les
        résultats de TopicRank lorsque nous faisons varier le seuil~$\zeta$ avec
        un pas de 0,05 pour toutes les stratégies de groupement\footnote{La
        stratégie de sélection du terme-clé le plus représentatif par sujet
        utilisée dans cette expérience est la stratégie position.}.
        % Quelle analyse peut-on faire à partir des courbes ?
        Globalement, chaque stratégie de groupement a un comportement qui lui
        est propre jusqu'à un certain point de convergence lorsque $\zeta$ vaut
        0,70, ce point de convergence correspondant à la valeur du seuil $\zeta$
        pour laquelle les sujets créés sont les mêmes quelle que soit la
        stratégie. Avec la stratégie simple, les résultats s'améliorent lorsque
        $\zeta$ augmente. Du fait qu'elle ne prend en compte que la similarité
        maximale entre deux candidats de deux groupes, cette stratégie à
        tendance à trop grouper et donc à créer des groupes contenant en réalité
        plusieurs sujets. L'augmentation du seuil $\zeta$ a pour effet de
        restreindre cette tendance et la qualité du groupement s'améliore. En
        opposition, la stratégie complète, qui a le fonctionnement inverse, voit
        ses résultats se dégrader lorsque $\zeta$ augmente. Enfin, la stratégie
        moyenne agit en compromis. Pour SemEval, son comportement est le même
        que celui de la stratégie complète, mais ses résultats sont supérieurs
        jusqu'au point de convergence. Pour \textsc{Deft}, son comportement est
        le même que celui de la stratégie simple, mais ses résultats sont très
        supérieurs jusqu'au point de convergence.
        % Quels sont les paramètres utilisés ?
        Après observation des résultats de cette expérience, nous décidons
        d'utiliser la stratégie de groupement moyenne avec un seuil $\zeta$ de
        0,20 pour toutes les expériences suivantes.

        La figure~\ref{fig:variation_de_la_selection_des_candidats} présente les
        résultats obtenus avec TopicRank et les différentes stratégies de
        sélection d'un terme-clé candidat par sujet. Les résultats confirment
        notre hypothèse qui est que le choix des candidats apparaissant en
        premier dans le document fournit de meilleurs termes-clés que le choix
        des candidats centroïdes ou des candidats les plus fréquents. La
        stratégie centroïde donne de très faibles résultats et la
        stratégie fréquence n'est pas stable comparée à la stratégie position.
        Enfin, bien que la stratégie position donne les résultats les plus
        satisfaisants, nous remarquons qu'il existe encore une marge de
        progression importante. Les valeurs indiquées par la borne haute
        représentent les résultats qui pourraient être obtenus avec un oracle.
        Pour chacun des sujets les plus importants, l'oracle sélectionne
        toujours un candidat positif, s'il y en a un. La marge de progression de
        14,8 points de f-mesure pour SemEval et de 5,4 points de f-mesure pour
        \textsc{Deft} est encourageante pour des travaux futurs.
        \begin{figure}
          \centering
          \begin{tikzpicture}
            \pgfkeys{/pgf/number format/.cd, use comma, fixed}
            \begin{axis}[axis lines=left,
                         symbolic x coords={SemEval, DEFT},
                         xtick=data,
                         xticklabels={SemEval, \textsc{Deft}},
                         enlarge x limits=0.5,
                         x=.3\linewidth,
                         nodes near coords,
                         nodes near coords align={vertical},
                         every node near coord/.append style={font=\tiny},
                         y=0.004\textheight,
                         ytick={0, 10, ..., 50},
                         ymin=0,
                         ymax=52.5,
                         ybar=8pt,
                         ylabel=F,
                         ylabel style={at={(ticklabel* cs:1)},
                                       anchor=south,
                                       rotate=270}]%,
                         %legend style={at={(0.5,-0.15)},
                         %              anchor=north,
                         %              legend columns=-1}]
              % centroïde
              \addplot[green!66,
                       pattern=north east lines,
                       pattern color=green!40] coordinates{
                (SemEval,   2.6)
                (DEFT,      4.7)
              };
              % fréquence
              \addplot[cyan!66,
                       pattern=north west lines,
                       pattern color=cyan!40] coordinates{
                (SemEval,   7.5)
                (DEFT,      14.2)
              };
              % position
              \addplot[black!66,
                       pattern=horizontal lines,
                       pattern color=black!40] coordinates{
                (SemEval,   11.4)
                (DEFT,      15.4)
              };
              % borne haute
              \addplot[red!66,fill=red!40] coordinates{
                (SemEval,   26.2)
                (DEFT,      20.8)
              };

              \legend{Centroïde, Fréquence, Position, Borne haute}
            \end{axis}
          \end{tikzpicture}
          \caption{Résultats de l'extraction de dix termes-clés, avec TopicRank,
                   en fonction des différentes stratégies de sélections d'un
                   terme-clé candidats par sujet
                   \label{fig:variation_de_la_selection_des_candidats}}
        \end{figure}

      \subsubsection{Paramétrage empirique de SingleRank}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-empirical_setting_of_singlerank}
        Contrairement aux autres méthodes de référence, SingleRank possède un
        paramètre qui est définit arbitrairement~: la fenêtre de cooccurrences
        fixée à dix par \newcite{wan2008expandrank}. De même que pour TopicRank,
        nous utilisons les ensembles d'entrainement de SemEval et de
        \textsc{Deft} pour déterminer qu'elle est la valeur optimale de la
        fenêtre de cooccurrences pour SingleRank\footnote{Nous ne répétons pas
        cette expérience pour TextRank, car le critère d'adjacence (fenêtre de
        valeur 2) est un critère fort dans la méthode TextRank.}. 

        La figure~\ref{fig:variation_de_la_fenetre} présente les résultats de
        SingleRank lorsque nous faisons varier la fenêtre de cooccurrences de
        deux à vingt mots, avec un pas de un. Globalement, nous observons une
        stabilité des performances de SingleRank quelle que soit la valeur
        utilisée pour la fenêtre de cooccurrences, avec des résultats optimaux
        obtenus lorsque celle-ci vaut 12. Dans les expériences suivantes, nous
        fixons donc la valeur de la fenêtre de cooccurrences à 12.
        \begin{figure}
          \centering
          \begin{tikzpicture}
            \begin{axis}[axis lines=middle,
                         x=0.025\linewidth,
                         xtick={2, 4, 6, 8, 10, 12, 14, 16, 18, 20},
                         xmin=1,
                         xmax=21,
                         xlabel=Fenêtre,
                         x label style={anchor=west},
                         y=0.012\textheight,
                         ytick={0, 5, 10, 15},
                         ymin=0,
                         ymax=18,
                         ylabel=F,
                         y label style={anchor=south}]
              % semeval
              \addplot[cyan!66, mark=+] coordinates{
                (2, 5.0)
                (3, 5.2)
                (4, 4.8)
                (5, 5.1)
                (6, 5.0)
                (7, 4.9)
                (8, 4.9)
                (9, 4.9)
                (10, 5.1)
                (11, 5.1)
                (12, 5.2)
                (13, 5.2)
                (14, 5.2)
                (15, 5.2)
                (16, 5.2)
                (17, 5.2)
                (18, 5.1)
                (19, 5.2)
                (20, 5.2)
              };
              % deft
              \addplot[red!66, mark=o] coordinates{
                (2, 3.5)
                (3, 6.1)
                (4, 6.3)
                (5, 6.4)
                (6, 6.8)
                (7, 6.7)
                (8, 6.9)
                (9, 6.9)
                (10, 7.1)
                (11, 7.2)
                (12, 7.1)
                (13, 7.0)
                (14, 7.0)
                (15, 7.0)
                (16, 7.0)
                (17, 7.3)
                (18, 7.3)
                (19, 7.3)
                (20, 7.1)
              };
              \draw[densely dashed] ({axis cs:12,0}|-{rel axis cs:0,1}) -- ({axis cs:12,0}|-{rel axis cs:0,0}) [color=black!66];
              \node at (axis cs:12,17.5) [color=black!66, anchor=west] {\tiny{12}};
              \legend{SemEval, \textsc{Deft}}
            \end{axis}
          \end{tikzpicture}
          \caption{Résultats de l'extraction de dix termes-clés, avec
                   SingleRank, en fonction de la fenêtre de cooccurrences
                   \label{fig:variation_de_la_fenetre}}
        \end{figure}

      \subsubsection{Comparaison de TopicRank avec l'existant}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-comparison}
        % Que représente le tableau ?
        Le tableau~\ref{tab:resultats_globaux} montre les performances de
        TopicRank comparées à celles des trois méthodes de référence. De manière
        générale, les performances des méthodes d'extraction de termes-clés sont
        basses. De plus, il est avéré que les documents de grande taille, tels
        que ceux de SemEval et de \textsc{Deft}, sont plus difficiles à traiter que les
        autres documents. \newcite{hasan2014state_of_the_art} explique qu'un
        grand nombre de termes-clés candidats sont sélectionnés dans ces
        documents (ils sont en moyenne 647 pour SemEval et 915 pour
        \textsc{Deft}), ce qui augmente la difficulté de l'extraction de
        termes-clés.

        % Que peut-on dire globalement ?
        Globalement, TopicRank donne de meilleurs résultats que les méthodes de
        référence utilisées.
        % Que peut-on dire de plus ? (analyse plus approfondie)
        Comparée à la méthode TF-IDF, TopicRank donne de meilleurs résultats pour
        SemEval, Wikinews et \textsc{Deft}. Cette supériorité vis-à-vis de TF-IDF est
        importante à noter, car cette méthode obtient de bons résultats en
        tirant parti de statistiques extraites de documents supplémentaires,
        alors que TopicRank n'utilise que le document à analyser. Comparé aux
        autres méthodes à base de graphe, TopicRank donne des résultats
        significativement meilleurs pour SemEval, Wikinews et \textsc{Deft}. Ceci
        confirme donc que le groupement des candidats permet de rassembler des
        informations pour améliorer la précision de l'ordonnancement. En ce qui
        concerne \textsc{Duc}, notre méthode est aussi significativement meilleure que
        TextRank, mais elle ne l'est pas vis-à-vis de SingleRank. D'après la
        borne haute, l'une des raisons à la plus faible performance de TopicRank
        pour \textsc{Duc} est que la stratégie de sélection des candidats les plus
        représentatifs des sujets est moins adaptée. En effet, la différence
        avec la borne haute est de 12,9 points de f-mesure. Une analyse plus
        approfondie des différents apports de TopicRank peut aussi aider à
        comprendre les raisons de ses moins bons résultats.
        \begin{table}
          \centering
          \begin{tabular}{l|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}}
            \toprule
            \multirow{2}{*}[-2pt]{\textbf{Méthode}} & \multicolumn{3}{c|}{\textbf{\textsc{Duc}}} & \multicolumn{3}{c|}{\textbf{SemEval}} & \multicolumn{3}{c|}{\textbf{Wikinews}} & \multicolumn{3}{c}{\textbf{\textsc{Deft}}}\\
            \cline{2-4}\cline{5-7}\cline{8-10}\cline{11-13}
            & P & R & F & P & R & F & P & R & F & P & R & F\\
            \hline
            TF-IDF & \textbf{23,8} & \textbf{30,7} & \textbf{26,4}$^{~}$ & 13,2 & $~~$8,9 & 10,5$^{~}$ & 33,9 & 35,9 & 34,3$^{~}$ & 10,3 & 19,1 & 13,2$^{~}$\\
            TextRank & $~~$4,9 & $~~$5,4 & $~~$5,0$^{~}$ & $~~$7,9 & $~~$4,5 & $~~$5,6$^{~}$ & $~~$9,3 & $~~$8,3 & $~~$8,6$^{~}$ & $~~$4,9 & $~~$7,1 & $~~$5,7$^{~}$\\
            SingleRank & 22,6 & 28,8 & 25,0$^{~}$ & $~~$4,8 & $~~$3,3 & $~~$3,9$^{~}$ & 19,2 & 20,4 & 19,5$^{~}$ & $~~$4,7 & $~~$9,4 & $~~$6,2$^{~}$\\
            TopicRank & 18,2 & 23,2 & 20,1 & \textbf{15,1}$^{~}$ & \textbf{10,6} & \textbf{12,3}$^\dagger$ & \textbf{34,8} & \textbf{37,3} & \textbf{35,4}$^\dagger$ & \textbf{11,3} & \textbf{21,0} & \textbf{14,5}$^\dagger$\\
            \hline
            \textbf{Borne haute} & \textbf{31,6} & \textbf{35,3} & \textbf{33,0}$^{~}$ & \textbf{33,8} & \textbf{23,3} & \textbf{27,3}$^{~}$ & \textbf{41,7} & \textbf{44,1} & \textbf{42,2}$^{~}$ & \textbf{14,5} & \textbf{27,0} & \textbf{18,7}$^{~}$\\
            \bottomrule
          \end{tabular}
          \caption[Résultats de l'extraction de dix termes-clés avec TF-IDF,
                   TextRank, SingleRank et TopicRank]{
            Résultats de l'extraction de dix termes-clés avec TF-IDF, TextRank,
            SingleRank et TopicRank. $\dagger$ indique une amélioration
            significative de TopicRank vis-à-vis de TextRank et SingleRank, à
            0,001 pour le t-test de Student.
            \label{tab:resultats_globaux}
          }
        \end{table}

        \begin{table}
          \centering
          \begin{tabular}{l|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}}
            \toprule
            \multirow{2}{*}[-2pt]{\textbf{Méthode}} & \multicolumn{3}{c|}{\textbf{\textsc{Duc}}} & \multicolumn{3}{c|}{\textbf{SemEval}} & \multicolumn{3}{c|}{\textbf{Wikinews}} & \multicolumn{3}{c}{\textbf{\textsc{Deft}}}\\
            \cline{2-4}\cline{5-7}\cline{8-10}\cline{11-13}
            & P & R & F & P & R & F & P & R & F & P & R & F\\
            \hline
            SingleRank & \textbf{22,6} & \textbf{28,8} & \textbf{25,0}$^{~}$ & $~~$4,8 & $~~$3,3 & $~~$3,9$^{~}$ & 19,2 & 20,4 & 19,5$^{~}$ & $~~$4,7 & $~~$9,4 & $~~$6,2$^{~}$\\
            + complet & 22,2 & 28,1 & 24,5$^{~}$ & $~~$5,5 & $~~$3,8 & $~~$4,4$^{~}$ & 20,0 & 21,4 & 20,3${~}$ & $~~$4,4 & $~~$9,0 & $~~$5,8$^{~}$\\
            + candidats & 10,4 & 13,5 & 11,6$^{~}$ & $~~$9,4 & $~~$6,8 & $~~$7,8$^\dagger$ & 28,5 & 30,0 & 28,8$^\dagger$ & 10,3 & 19,2 & 13,2$^\dagger$\\
            + sujets & 18,9 & 24,2 & 21,0$^{~}$ & 14,2 & $~~$9,9 & 11,6$^\dagger$ & 30,7 & 32,6 & 31,1$^\dagger$ & 11,1 & 20,4 & 14,2$^\dagger$\\
            TopicRank & 18,2 & 23,2 & 20,1$^{~}$ & \textbf{15,1} & \textbf{10,6} & \textbf{12,3}$^\dagger$ & \textbf{34,8} & \textbf{37,3} & \textbf{35,4}$^\dagger$ & \textbf{11,3} & \textbf{21,0} & \textbf{14,5}$^\dagger$\\
            \bottomrule
          \end{tabular}
          \caption[Résultats de l'extraction de dix termes-clés avec chacune des
                   contributions de TopicRank, appliquées séparément à
                   SingleRank]{
            Résultats de l'extraction de dix termes-clés avec chacune des
            contributions de TopicRank, appliquées séparément à SingleRank.
            $\dagger$ indique une amélioration significative vis-à-vis de
            SingleRank, à 0,001 pour le t-test de Student.
            \label{tab:evaluation_individuelle_des_ameliorations}
          }
        \end{table}

        Dans le but de confirmer la pertinence de tous les apports de TopicRank,
        nous réalisons une expérience supplémentaire dans laquelle nous
        appliquons individuellement à SingleRank toutes les modifications
        successives permettant d'obtenir la méthode TopicRank depuis la méthode
        SingleRank~: l'usage d'un graphe complet (+ complet), la projection des
        termes-clés candidats dans le graphe (+ candidats) et la projection des
        sujets dans le graphe (+ sujets). Les résultats de ces trois variantes
        de SingleRank sont présentés dans le
        tableau~\ref{tab:evaluation_individuelle_des_ameliorations}.
        Globalement, l'usage des termes-clés candidats, ou sujets, induit une
        amélioration significative des performances de SingleRank, avec une
        amélioration plus importante en utilisant les sujets. Cela confirme la
        pertinence d'ordonner directement les candidats, plutôt que les mots,
        ainsi que la pertinence de grouper les candidats représentant le même
        sujet pour mutualiser les relations qu'ils entretiennent avec les
        candidats représentant d'autres sujets. L'usage d'un graphe complet,
        quant à lui, n'améliore pas significativement les résultats de
        SingleRank. Ceux-ci sont compétitifs vis-à-vis de ceux obtenus en
        construisant un graphe de cooccurrences. Toutefois, nous pensons que
        l'usage du graphe complet est à privilégier afin d'éviter d'avoir à
        fixer le paramètre de la fenêtre de cooccurrences.
        
        En ce qui concerne la collection \textsc{Duc}, le
        tableau~\ref{tab:evaluation_individuelle_des_ameliorations} montre une
        perte de performance induite par la construction du graphe avec les
        termes-clés candidats. Cette perte de performance s'explique par le fait
        qu'il y a, dans les documents de \textsc{Duc}, peu de répétition des
        candidats, notamment ceux de plus d'un mot. Le graphe créé contient
        alors moins de relations de cooccurrences que lorsque les n\oe{}uds sont
        les mots du document et est donc moins précis pour l'ordonnancement.

      \subsection{Analyse d'erreurs}
      \label{subsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-error_analysis}
        Dans cette section, nous proposons d'analyser les erreurs de TopicRank.
        Dans un premier temps, nous analysons les sujets que détecte TopicRank,
        puis dans un second temps, nous analysons les termes-clés de référence
        qui ne sont pas extraits par Topic\-Rank.

        \subsubsection{Analyse des sujets détectés}
        \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-error_analysis-detected_topics}
          Dans cette section, nous analysons les groupements en sujets effectués
          par Topic\-Rank afin de déterminer quelles sont les principales causes
          d'erreurs.

          \TODO{peut-être revoir les exemples qui suivent}

          Nous observons des erreurs liées à la sélection des termes-clés
          candidats. Lors de cette étape, certaines unités textuelles sont
          sélectionnées comme candidats à cause d'erreurs commises lors de
          l'étiquetage grammatical. Ces erreurs concernent principalement la
          détection des participes. Par exemple, dans la phrase \og{}[\dots]
          elles ne cessent de se développer à travers le monde et
          particulièrement dans les pays dits ``du
          sud''~[\dots]\fg{}\footnote{Exemple issu de l'article d'anthropologie
          \textit{Le marché parallèle du médicament en milieu rural au Sénégal}
          (\url{http://id.erudit.org/iderudit/014935ar}) de la collection
          \textsc{Deft}.}, \og{}dits\fg{} est un adjectif selon l'outils MElt, ce qui
          entraîne la sélection erronée du terme-clé candidat \og{}pays
          dits\fg{}.

          Nous observons également de nombreuses erreurs lorsque les groupements
          sont déclenchés par un adjectif. Ce sont particulièrement les
          expansions nominales s'effectuant à gauche qui en sont la cause (par
          exemple \og{}même langue\fg{} groupé avec \og{}même
          représentation\fg{}). Parmi les expansions nominales s'effectuant à
          droite, les adjectifs relationnels sont moins sujets aux erreurs que
          les autres adjectifs. Notons tout de même que lorsque ces adjectifs
          sont liés au contexte général du document, ils sont très fréquemment
          utilisés et beaucoup de candidats les contenant sont groupés par
          erreur (par exemple \og{}forces économiques\fg{} peut être groupé
          avec \og{}délabrement économique\fg{} dans un document d'économie).
          Outres ces groupements erronés, nous observons aussi de mauvais
          groupements lorsque les candidats ne contiennent que très peu de mots.
          Pour les candidats de deux mots, il ne suffit que d'un seul mot en
          commun pour les grouper. Ces candidats étant très fréquents, ils sont
          la cause de nombreuses erreurs.

        \subsubsection{Analyse des faux négatifs}
        \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-error_analysis-false_negatives}
          Dans cette section, nous analysons les termes-clés de référence qui
          n'ont pas été extraits par TopicRank. Plus particulièrement, nous nous
          intéressons à ceux qui sont présents dans les dix sujets jugés les
          plus importants de chaque document, mais qui n'ont pas été
          sélectionnés pour les représenter. Nous observons deux sources
          d'erreurs.

          La première source d'erreurs est le groupement en sujets. Lorsqu'un
          sujet détecté contient en réalité des termes-clés candidats
          représentant des sujets différents, la stratégie de sélection du
          meilleur terme-clé dans le sujet parvient à sélectionner le terme-clé
          correct dans certains cas, mais elle échoue parfois.

          \TODO{peut-être revoir les exemples qui suivent}

          La seconde source d'erreurs est la spécialisation des termes-clés de
          référence. Nous observons deux problèmes de sous et sur-spécialisation
          de certains termes-clés extraits vis-à-vis des termes-clés de
          référence. Dans le cas de la sous-spécialisation, nous pouvons citer,
          par exemple, \og{}papillons\fg{} qui est extrait à la place de
          \og{}papillons mutants\fg{}\footnote{Exemple issue de l'article
          journalistique \textit{Fukushima fait muter les papillons}
          (\url{http://fr.wikinews.org/w/index.php?oldid=432477}) de la
          collection Wikinews.}. Bien que ce problème de sous-spécialisation
          soit identifié, l'existance du problème inverse le rend plus difficile
          à résoudre. Dans le cas de la sur-spécialisation, nous pouvons citer,
          par exemple, \og{}député Antoni Pastor\fg{} qui est extrait à la place
          de \og{}Antoni Pastor\fg{}\footnote{Exemple issu de l'article
          journalistique \textit{Îles Baléares : le Parti populaire exclut le
          député Antoni Pastor pour avoir défendu la langue catalane}
          (\url{http://fr.wikinews.org/w/index.php?oldid=479948}) de la
          collection Wikinews.}. La raison principale de ce problème est
          l'aspect libre et ambigu de l'annotation manuelle des termes-clés.
%          Toutefois, privilégier les modifications adjectivales (par exemple
%          \og{}mutants\fg{}) et, au contraire, éviter les modifications
%          nominales (par exemple \og{}député\fg{}) semblent être une hypothèse à
%          vérifier.

      \subsection{Bilan}
      \label{subsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-bilan}
        Avec TopicRank, nous proposons une méthode à base de graphe pour
        l'extraction non supervisée de termes-clés. Elle groupe les termes-clés
        candidats en sujets, détermine quels sont ceux les plus importants, puis
        extrait le terme-clé candidat qui représente le mieux chacun des sujets
        les plus importants. Cette nouvelle méthode offre plusieurs avantages
        vis-à-vis des précédentes méthodes à base de graphe. Le groupement des
        termes-clés potentiels en sujets distincts permet de rassembler des
        informations relatives au même sujets et le choix d'un seul terme-clé
        pour représenter un sujet important permet d'extraire un ensemble de
        termes-clés non redondants (pour $k$ termes-clés extraits, exactement
        $k$ sujets sont couverts). Enfin, le graphe est complet et ne requiert
        plus le paramétrage d'une fenêtre de cooccurrences.

        Les bons résultats de notre méthode montrent la pertinence d'un
        groupement des candidats en sujets et d'un ordonnancement de ces sujets,
        plutôt que des mots. Les expériences montrent aussi qu'il est encore
        possible d'améliorer notre méthode en proposant une nouvelle stratégie
        de sélection du terme-clé candidat le plus représentatif d'un sujet.
        Dans un premier temps, nous souhaitons explorer plus encore l'usage du
        graphe et l'étendre à l'assignement de termes-clés.

  %-----------------------------------------------------------------------------

  \section{Conclusion}
  \label{sec:main-domain_independent_keyphrase_extraction-conclusion}
    \TODO{\dots}


