\chapter{Extraction de termes-clés indépendante du domaine}
\label{chap:main-domain_independent_keyphrase_extraction}
  \smallchaptercite{
    [\dots] there is still room for improvement over the task.
  }{
    \newcite{kim2010semeval}
  }

  %-----------------------------------------------------------------------------

  \section{Introduction}
  \label{sec:main:domain_independent_keyphrase_extraction-introduction}
    Dans ce chapitre, nous nous intéressons à la tâche d'extraction automatique
    de termes-clés. Cette tâche consiste à identifier dans un document ses mots
    et expressions qui permettent le mieux d'en caractériser le contenu. Cette
    tâche de l'indexation par termes-clés est celle la plus étudiée de nos
    jours. Elle peut être réalisée de manière non supervisée ou supervisée,
    grâce à la mise en \oe{}uvre d'algorithmes d'ordonnancement par importance
    des mots du document ou grâce à l'entraînement de classifieurs capables de
    déterminer si une unité textuelle est un terme-clé ou non.

    Nous proposons deux contributions à l'extraction automatique de termes-clés.
    Tout d'abord, nous nous intéressons à l'étape préliminaire de sélection des
    termes-clés candidats, puis nous nous intéressons à leur ordonnancement par
    importance. Les méthodes proposées sont non supervisées, aucun biais
    induisant une quelconque dépendance à une langue ou à un domaine n'est
    introduit.

    \TODO{pas très complet}

  %-----------------------------------------------------------------------------

  \section{Sélection des termes-clés candidats}
  \label{sec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection}
    La sélection des termes-clés candidats établit la liste des termes-clés
    potentiels pour un document donné. Bien qu'étudiée en surface, ou de manière
    ad-hoc à une méthode particulière d'extraction de termes-clés, cette étape
    est critique pour l'extraction de termes-clés. Si elle ne sélectionne pas
    suffisamment de candidats, alors la performance maximale pouvant être
    atteinte pour l'extraction de termes-clés est faible et, au contraire, si
    elle sélectionne un nombre important de candidats, alors elle augmente le
    risque de sélectionner de mauvais candidats pouvant dégrader la performance
    d'une méthode d'extraction de termes-clés~\cite{hasan2014state_of_the_art}.
    De nombreux travaux semblent montrer que les groupes nominaux, souvent
    approximés par les séquences de noms et d'adjectifs, forment de bons
    termes-clés candidats et sont très proches des termes-clés de
    référence~\cite{barker2000nounphrasehead,hulth2003keywordextraction,wan2008expandrank}.

    Dans notre travail, nous remettons en question la sélection systématique
    d'un adjectif apposé à un nom. En nous appuyant sur une analyse linguistique
    des termes-clés de trois collections de données, nous proposons une méthode
    qui juge si un adjectif apporte du sens bénéfique à la caractérisation du
    contenu du document, auquel cas il est sélectionné avec le nom qu'il
    modifie, ou non, auquel cas seul le nom est sélectionné comme terme-clé
    candidat. Le bien fondé de cette méthode est montré au travers de deux
    évaluations~: l'une intrinsèque, l'autre extrinsèque. L'évaluation
    intrinsèque compare la qualité de l'ensemble de termes-clés candidats
    sélectionnés par notre méthode à ceux sélectionnés par les méthodes les plus
    utilisées ($\{1..3\}$-grammes, \textit{NP-chunks} et \texttt{/(N|A)+/})~;
    l'évaluation extrinsèque compare l'impact de notre méthode de sélection sur
    deux méthodes d'extraction de termes-clés à celui des méthodes de sélection
    les plus utilisées.

    \subsection{Analyse des propriétés linguistiques des termes-clés}
    \label{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-analysis_of_keyphrase_properties}
      Afin de sélectionner plus finement les termes-clés candidats, nous
      extrayons et analysons des statistiques concernant les termes-clés~: leur
      taille (en nombre de mots) et la catégorie grammaticale des mots qui les
      composent. Cela nous permet de confirmer les observations faites dans les
      travaux précédents et d'en inférer de nouvelles, axées sur la catégorie
      grammaticale des mots des termes-clés.

      Notre analyse couvre les deux langues de nos ressources (français et
      anglais). Elle se porte sur les collections \textsc{De}ft (français),
      \textsc{Duc} (anglais) et SemEval (anglais). Dans le but de ne pas biaiser
      les résultats des évaluations de ce travail, l'analyse est effectuée sur
      un sous-ensemble de ces collections. Pour permettre des comparaisons avec
      des travaux futures, les évaluations sont réalisées sur les ensembles de
      test de nos collections et l'analyse est donc réalisée sur les ensembles
      normalement destinés à l'apprentissage. \textsc{Duc} n'étant pas répartie
      en plusieurs sous-ensembles, nous utilisons 208 documents pour l'analyse
      et 100 pour les évaluations.

      \subsubsection{Analyse surfacique}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-analysis_of_keyphrase_properties-shalow_analysis}
      Le tableau~\ref{tab:candidate_selection-train_stats} montre la
      proportion de termes-clés uni-grammes, bi-grammes et tri-grammes, ainsi
      que la proportion de termes-clés multi-mots contenant au moins un mot
      appartenant à l'une des sept catégories grammaticales que nous observons
      en leur sein\footnote{ Nous nous focalisons sur les expressions
      (termes-clés multi-mots), car nous avons observé que la quasi totalité des
      termes-clés composés d'un unique mot sont des noms. }~: nom commun, nom
      propre, adjectif, verbe, adverbe, préposition et déterminant. Pour obtenir
      ces informations, les termes-clés ont été automatiquement segmentés en
      mots et étiquetés grammaticalement à l'aide des outils utilisés pour
      prétraiter les collections de données (cf
      section~\ref{sec:main-data_description-preprocessing}
      page~\pageref{sec:main-data_description-preprocessing}), puis manuellement
      corrigés.
      \begin{table}[!h]
        \centering
        \begin{tabular}{ll|ccc}
          \toprule
          & & \textbf{\textsc{Duc}} \textit{(en)} & \textbf{SemEval} \textit{(en)} & \textbf{\textsc{Deft}} \textit{(fr)}\\
          \hline
          \multicolumn{2}{l|}{\textbf{Taux (en \%) de termes-clés~:}}\\
          & Uni-grammes & 17,1 & 20,2 & 60,2\\
          & Bi-grammes & 60,8 & 53,4 & 24,5\\
          & Tri-grammes & 17,8 & 21,3 & 8,8\\
          \hline
          \multicolumn{2}{l|}{\textbf{Taux (en \%) de termes-clés}} & & &\\
          \multicolumn{2}{l|}{\textbf{contenant au moins un(e)~:}} & & &\\
          & Nom commun & 94,5 & 98,7 & 93,1\\
          & Nom propre & 17,1 & $~~$4,3 & $~~$6,9\\
          & Adjectif & 50,0 & 50,2 & 65,5\\
          & Verbe & $~~$1,0 & $~~$4,0 & $~~$1,0\\
          & Adverbe & $~~$1,6 & $~~$0,7 & $~~$1,3\\
          & Préposition & $~~$0,3 & $~~$1,5 & 31,2\\
          & Déterminant & $~~$0,0 & $~~$0,0 & 20,4\\
          \bottomrule
        \end{tabular}
        \caption{Statistiques concernant les termes-clés de référence des
                 collections \textsc{Deft}, SemEval et \textsc{Duc}
                 \label{tab:candidate_selection-train_stats}}
      \end{table}

      Concernant la taille des termes-clés de référence, les uni-grammes,
      bi-grammes et tri-grammes couvrent plus de 90~\% des termes-clés de
      références. En français, ce sont les uni-grammes qui sont les plus
      utilisés, suivis par les bi-grammes, tandis qu'en anglais, ce sont les
      bi-grammes qui sont les plus employés, avec des proportions équivalentes
      d'uni-grammes et de tri-grammes. Ces premières observations font écho à
      celles que nous trouvons dans la littérature. Nous en concluons qu'il
      s'agit de propriétés stables des termes-clés. Une approche raisonable peut
      donc se restreindre aux $\{1..3\}$-grammes, à l'instar de celle de
      \newcite{witten1999kea}.

      Concernant les catégories des mots que contiennent les termes-clés de
      référence, nous observons que la quasi-totalité des termes-clés
      contiennent un nom (ce sont majoritairement des groupes nominaux) et
      que la moitié d'entre eux est modifiée par un adjectif. Les autres
      catégories de mots, comme le verbe et l'adverbe sont très peu utilisées.
      L'usage de ces dernières au sein de termes-clés semble être exceptionnel.
      Les déterminants et prépositions ont un usage presque exclusivement
      français. En anglais, les formes composés (par exemple,
      \textit{\og{}nature conservation\fg{}} -- \og{}conservation de la
      nature\fg{}) sont préférées aux formes syntagmatiques (par exemple~:
      \textit{\og{}conservation of nature\fg{}} -- \og{}conservation de la
      nature\fg{}).

      \subsubsection{Analyse des adjectifs}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-analysis_of_keyphrase_properties-adjective_analysis}
      L'adjectif étant utilisé à plus forte proportion que les catégories
      grammaticales autres que le nom et le nom propre, nous analysons plus
      finement sa nature. Nous nous intéressons aux trois catégories d'adjectifs
      suivantes~: relationnel, composé complexe et qualificatif.
      
      Un adjectif relationnel est un adjectif
      dénominal~\cite{bally1944linguistiquegeneraleetlinguistiquefrancaise}. Il
      est dérivé d'un nom (par exemple~: l'adjectif relationnel
      \og{}culturel\fg{} est dérivé du nom \og{}culture\fg{}) pour lequel il
      établit une relation équivalente à celle exprimée par le complément du nom
      (par exemple~: \og{}héritage culturel\fg{} équivaut à \og{}héritage de la
      culture\fg{}). Caractéristique du discours du
      spécialiste~\cite{maniez2009denominaladjectives}, l'adjectif relationnel
      sert de modificateur dans les titre de catégories, telles que celles de
      Wikipedia (par exemple \og{}héritage
      culturel\fg{}\footnote{\url{http://en.wikipedia.org/wiki/Category:Cultural_heritage}}),
      qui constituent de bons termes-clés
      candidats~\cite{medelyan2008smalltrainingset,eichler2010keywe}. Par
      transitivité, l'adjectif relationnel semble donc être un modificateur qui
      apporte du sens bénéfique à la caractérisation  de tout ou partie du
      contenu d'un document.
      
      Un adjectif composé complexe est un adjectif constitué de plusieurs mots,
      souvent délimités graphiquement par un trait d'union (par exemple,
      \og{}socio-éducatif\fg{}). L'adjectif composé complexe contribue avec
      précision et concision à la caractérisation du nom qu'il modifie (par
      exemple, \og{}activité socio-éducative\fg{} hyponyme de
      \og{}activité\fg{}). Pour cette raison, nous pensons qu'il apporte du sens
      bénéfique à la caractérisation de tout ou partie du contenu d'un document.
      De plus, la composition adjectival est l'un des processus privilégiés pour
      la formation de néologismes\footnote{Néologisme~: mot nouveau, emprunt
      récent à une autre langue ou nouvelle emploi d'un mot déjà existant
      (nouvelle acception).}~\cite{boughedaoui1997adjectifscomposes}. Pour cette
      autre raison, l'adjectif composé complexe peut s'avérer très utile en tant
      que modificateur dans un terme-clé.

      Un adjectif qualificatif est un adjectif qui donne une qualification à un
      nom. Il désigne la qualité ou manière d'être (par exemple,
      \og{}grand\fg{}) de ce dernier. Cette catégorie d'adjectifs est la
      plus couramment utilisée. L'ensemble des cas d'utilisation des adjectifs
      qualificatifs est moins restreint que celui des adjectifs relationnels et
      composés complexes. Nous faisons donc l'hypothèse qu'un adjectif
      appartenant à cette catégorie n'est pas toujours utile à la
      caractérisation du contenu important d'un document.
      
      ~\\Pour détecter les adjectifs relationnels, nous utilisons une technique
      simple, adaptée (ou adaptable) à plusieurs langues et ne requérant pas
      nécessairement de données riches.

      Dans un premier temps, les adjectifs relationnels sont détectés avec une
      base de données lexicale. Pour le français, nous utilisons la base
      WoNeF~\cite{pradet2013wonef} dont la propriété \texttt{[DERIVED]}
      indique que l'adjectif est relationnel. Pour l'anglais, nous
      utilisons la base  WordNet~\cite{miller1995wordnet} dont la propriété
      \texttt{[PERTAINYM]} indique que l'adjectif est relationnel.

      Dans un second temps, les adjectifs relationnels qui ne sont pas présents
      dans la base de données lexicale sont détectés à l'aide de leur
      suffixe~\cite{dubois1999derivation}. Une liste des suffixes les plus
      productifs pour les adjectifs relationnels est utilisée pour identifier
      les adjectifs relationnels potentiels. En français, les suffixes les plus
      productifs sont \textit{-ain}, \textit{-aire}, \textit{-al}, \textit{-el},
      \textit{-esque}, \textit{-estre}, \textit{-eux}, \textit{-ien},
      \textit{-ier}, \textit{-if}, \textit{-il}, \textit{-in}, \textit{-ique},
      \textit{-ois}, et
      \textit{-é}~\cite{harastani2013relationaladjectivetranslation}~; en
      anglais, les suffixes utilisés sont \textit{-al}, \textit{-ant},
      \textit{-ary}, \textit{-ic}, \textit{-ous} et
      \textit{-ive}~\cite{grabar2006terminologystructuring}.

      La détection des adjectifs relationnels, telle que nous la réalisons,
      n'est pas exacte. En effet, les adjectifs qualificatifs et/ou
      dénominaux se terminant par un suffixe d'adjectif relationnel sont
      détectés comme relationnels, et les adjectifs à usage tentôt qualificatif,
      tentôt relationnel selon le contexte~\cite{maniez2009denominaladjectives}
      sont toujours détectés comme relationnels. Dans la littérature, les
      approches pour identifier les adjectifs relationnels (dans le cadre de
      l'extraction terminologique) reposent sur une analyse en
      corpus~\cite{daille2000relationaladjectives,maniez2005automaticrelationaladjectiveidentification,harastani2013relationaladjectivetranslation},
      où il s'agit notamment de trouver des paraphrases avec un complément de
      nom. Dans le contexte de l'extraction de termes-clés, où de larges corpus
      ne sont pas toujours disponibles, les paraphrases ne sont pas toutes
      présentes et de telles approches ne sont pas applicables. De plus,
      \newcite{harastani2013relationaladjectivetranslation} montrent qu'une
      approche comme la notre reste une alternative viable.

      ~\\Pour déterminer si un adjectif est composé, nous regardons s'il possède
      un trait d'union. Le trait d'union est l'unique marque explicite de
      composition en français et en anglais, et son usage est le procédé le plus
      productif. Néanmoins, il existe deux autres procédés que nous ne traitons
      pas~: les mots qui constituent l'adjectif composé sont parfois séparés
      par un espace ou concaténés sans marque explicite.

      ~\\Le tableau~\ref{tab:candidate_selection-adjective_categories} montre le
      taux d'adjectifs, par catégorie, dans les termes-clés de référence.
      Nous observons que la majorité de ces adjectifs sont relationnels, ce qui
      conforte notre hypothèse que les adjectifs relationnels sont des
      modificateurs utiles pour les termes-clés. Ceci se confirme aussi avec
      le tableau~\ref{tab:candidate_selection-best_patterns} qui montre que l'un
      des patrons grammaticaux les plus productifs de termes-clés représente un
      nom modifié par un adjectif relationnel. Le cas des adjectifs composés
      complexes est moins marqué. Ils sont peu employés par rapport aux
      adjectifs relationnels et aux adjectifs qualificatifs. Ces derniers, quant
      à eux, ont un emploi non négligeable, en particulier en anglais où ils
      font partie de l'un des patrons grammaticaux les plus productifs de
      termes-clés (cf tableau~\ref{tab:candidate_selection-best_patterns}).
      \begin{table}[!ht]
        \centering
          \begin{tabular}{l|ccc}
            \toprule
            & \textbf{\textsc{Duc}} \textit{(en)} & \textbf{SemEval} \textit{(en)} & \textbf{\textsc{De}ft} \textit{(fr)}\\
            \hline
            Adjectifs relationnels \hfill(\%) & 53,1 & 43,6 & 87,1\\
            Adjectifs composés complexes \hfill(\%) & 10,6 & 16,4 & $~~$3,3\\
            Adjectifs qualificatifs \hfill(\%) & 36,3 & 40,0 & $~~$9,6\\
            \bottomrule
        \end{tabular}
        \caption{Taux d'adjectifs, par catégorie (relationnel, composé complexe
                 ou qualificatif), au sein des termes-clés de référence}
                 \label{tab:candidate_selection-adjective_categories}
      \end{table}

      Le tableau~\ref{tab:candidate_selection-adjective_categories_in_documents}
      montre le taux d'adjectifs, par catégorie, dans les documents. Par
      comparaison avec les taux présentés dans le
      tableau~\ref{tab:candidate_selection-adjective_categories}, ceux du
      tableau~\ref{tab:candidate_selection-adjective_categories_in_documents}
      permettent de déduire le degré d'ambigüité d'un adjectif en tant que
      modificateur au sein d'un terme-clé. Ainsi, ce tableau montre qu'il y a
      moins d'ambigüité quant à l'appartenance d'un adjectif relationnel ou
      composé à un terme-clé, car ces deux catégories d'adjectifs sont nettement
      moins utilisées dans les documents que dans les termes-clés de référence.
      À l'inverse, les adjectifs qualificatifs ont un très fort usage dans les
      documents et il y a donc plus d'ambigüité quant à leur nécessité en tant
      que modificateur dans un terme-clé.
      \begin{table}[!h]
        \centering
          \begin{tabular}{l|ccc}
            \toprule
            & \textbf{\textsc{Duc}} \textit{(en)} & \textbf{SemEval} \textit{(en)} & \textbf{\textsc{De}ft} \textit{(fr)}\\
            \hline
            Adjectifs relationnels \hfill(\%) & 29,9 & 30,7 & 61,9\\
            Adjectifs composés complexes \hfill(\%) & $~~$8,8 & $~~$7,9 & $~~$0,4\\
            Adjectifs qualificatifs \hfill(\%) & 61,3 & 61,4 & 37,7\\
            \bottomrule
        \end{tabular}
        \caption{Taux d'adjectifs, par catégorie (relationnel, composé complexe
                 ou qualificatif), au sein des documents}
                 \label{tab:candidate_selection-adjective_categories_in_documents}
      \end{table}

      \begin{table}[!h]
        \centering
        \begin{tabular}{r@{~}|@{~}l@{~}l@{~}l@{~}llr}
          \toprule
          \multicolumn{1}{r@{~}|@{~}}{} & \multicolumn{4}{@{}l}{\textbf{Pattern}} & \textbf{Example} & \textbf{\%}\\
          \hline
          \multirow{5}{*}{\begin{sideways}\textbf{Français}\end{sideways}}
          & \texttt{Nc} & \texttt{Ar} & & & \TODO{exemple} & 46,4\\
          & \texttt{NC} & \texttt{Sp} & \texttt{D} & \texttt{Nc} & \TODO{exemple} & 12,5\\
          & \texttt{Nc} & \texttt{Sp} & \texttt{Nc} & & \TODO{exemple} & $~~$8,2\\
          & \texttt{Nc} & \texttt{A} & & & \TODO{exemple} & $~~$4,3\\
          & \texttt{Np} & \texttt{Np} & & & \TODO{exemple} & $~~$3,0\\
          \hline
          \multirow{5}{*}{\begin{sideways}\textbf{Anglais}\end{sideways}}
          & \texttt{Nc} & \texttt{Nc} & & & \TODO{exemple} & 32,5\\
          & \texttt{Ar} & \texttt{Nc} & & & \TODO{exemple} & 15,1\\
          & \texttt{A} & \texttt{Nc} & & & \TODO{exemple} & $~~$9,5\\
          & \texttt{Nc} & \texttt{Nc} & \texttt{Nc} & & \TODO{exemple} & $~~$5,3\\
          & \texttt{Ac} & \texttt{Nc} & & & \TODO{exemple} & $~~$4,9\\
          \bottomrule
        \end{tabular}
        \caption[
          Patrons grammaticaux les plus fréquents parmi les termes-clés
          français et anglais
        ]{
          Patrons grammaticaux les plus fréquents parmi les termes-clés
          français et anglais. Les classes grammaticales sont exprimées au
          format Multext~\cite{ide1994multext}, sauf \texttt{Ar} et \texttt{Ac}
          qui représentent, respectivement, un adjectif relationnel et un
          adjectif composé.
          \label{tab:candidate_selection-best_patterns}
        }
      \end{table}

      \subsubsection{Bilan}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-analysis_of_keyphrase_properties-conclusion}
        Cette analyse des propriétés linguistiques des termes-clés montre que ce
        sont majoritairement des groupes nominaux de petite taille.
        La modification adjectivale est très utilisée (dans plus de la moitié
        des cas) pour rendre plus spécifique les termes-clés. Les adjectifs
        utilisés comme modificateurs au sein des termes-clés peuvent être de
        différentes natures, les plus remarquables étant les adjectifs
        relationnels, de par leur définition et de par leur très faible
        ambigüité observée quant à leur appartenance à un terme-clé.
        Inversement, les adjectifs qualificatifs sont les plus courants et ne
        sont pas nécessairement utiles au sein de termes-clés. Ils doivent être
        retenus comme modificateusr dans les termes-clés candidats que s'ils
        respectent certaines conditions (définis ci-après).

    \subsection{Sélection fine des termes-clés candidats}
    \label{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-modifiers_filtering}
      Pour sélectionner les termes-clés candidats, nous proposons une méthode
      explorant les propriétés linguistiques remarquables des termes-clés. Cette
      méthode commence par présélectionner les termes-clés candidats à l'aide
      d'un patron grammatical, puis elle filtre les adjectifs qualificatifs dans
      certaines conditions.

      \subsubsection{Présélection des termes-clés candidats}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-modifiers_filtering-candidate_pre_selection}
        L'étape de présélection des candidats utilise un patron grammatical
        défini sous la forme d'une expression rationnelle. Celui-ci est appliqué
        aux catégories grammaticales des séquences de mots adjacents dans le
        document et sélectionne celles qui le respectent. Ce patron est
        gourmand, c'est-à-dire qu'il capture les plus longues séquences
        possibles sans produire de candidats qui se recouvrent dans le texte
        (comme c'est le cas avec les n-grammes). Il permet ainsi de diminuer le
        risque d'extraire des termes-clés
        redondants~\cite{hasan2014state_of_the_art}.

        D'après nos observations, seuls les noms, les adjectifs, les
        prépositions et les déterminants sont utiles pour sélectionner les
        termes-clés candidats en permettant une performance maximale
        quasi-optimale. Dans le cas de l'anglais, les prépositions et les
        déterminants sont en proportions très faibles et peuvent donc ne pas
        être considéré lors de la définition du patron grammatical. Dans le cas
        du français, les prépositions et les déterminants apparaissent au sein
        de plus de 30~\% des termes-clés de référence. Notre étude se portant
        sur les adjectifs uniquement, nous faisons le choix de ne pas considérer
        ces deux classes grammaticales lors de la définition du patron de
        présélection des termes-clés candidats. Pour l'adjectif, nous nous
        appuyons sur les patrons grammaticaux les plus productifs de termes-clés
        du tableau~\ref{tab:candidate_selection-best_patterns} et décidons de
        limiter le nombre d'adjectifs à un pour le français et
        l'anglais\footnote{En français et en anglais, 3,3~\% et 5,3~\% des
        termes-clés contiennent plus d'un adjectif, respectivement.}.
        
        Pour le français, nous définissons le patron \texttt{/N+ A?/}, qui
        accepte une séquence de noms (ou noms propres) se terminant
        optionnellement par un adjectif. En français, l'adjectif peut être soit
        antéposé, soit postposé. Le patron que nous avons défini n'accepte que
        les adjectifs postposés pour deux raisons. La première raison est que
        les adjectifs relationnels, que nous jugeons être les modificateurs les
        plus utiles au sein des termes-clés, sont toujours postposés. La seconde
        raison est que l'adjectif antéposé ne fait pas partie des patrons les
        plus productifs de termes-clés\footnote{En français, seulement 0,7~\%
        des termes-clés commencent par un adjectif.} (cf
        tableau~\ref{tab:candidate_selection-best_patterns}).
        
        Pour l'anglais, nous définissons le parton \texttt{/A? N+/}, qui
        accepte une séquence de noms (ou noms propres) modifié par un adjectif
        antéposé. En anglais, tous les adjectifs sont antéposés. Ce patron ne
        filtre donc aucun adjectif à cette étape de présélection.

      \subsubsection{Filtrage des adjectifs superflus}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-modifiers_filtering-adjective_filtering}
        L'orsqu'un candidat contient un adjectif, cette étape juge s'il doit
        faire partie du terme-clé candidat ou non, auquel cas il  en est retiré.
        Sur la base de notre analyse, les adjectifs relationnels et composés
        complexes sont systématiquement jugés utiles. Seuls les adjectifs
        qualificatifs nécessitent une prise de décision.

        Pour décider si un adjectif qualificatif apporte du sens utile au groupe
        nominal qu'il modifie dans le terme-clé candidat, nous comparons les
        usages respectifs du candidat avec l'adjectif et sans l'adjectif. Notre
        intuition est qu'un adjectif est superflu (inutile) s'il modifie un
        groupe nominal qui est utilisé de manière autonome (sans l'adjectif) un
        nombre significatif de fois. Concrètement, si le groupe nominal occure
        plus souvent sans l'adjectif qu'avec l'adjectif, alors ce dernier est
        jugé inutile et est donc retiré du terme-clé candidat.

        L'algorithme~\ref{algo:candidate_pruning} résume le fonctionnement de
        notre méthode de sélection des termes-clés candidats. Les lignes
        \ref{algo:line:start_preselection} à \ref{algo:line:end_preselection}
        concernent la présélection des candidats et les lignes
        \ref{algo:line:start_filtering} à \ref{algo:line:end_filtering}
        identifient et filtrent les adjectifs qualificatifs superflus.
        \begin{algorithm}
          \SetKwInOut{kwInput}{Entrée}
          \SetKwInOut{kwOutput}{Sortie}
          \SetKwFor{For}{Pour chaque}{faire}{}
          \SetKwIF{If}{ElseIf}{Else}{Si}{alors}{Sinon si}{Sinon}{}
          \SetKw{KwRet}{Retourner}
          \DontPrintSemicolon{}

          \kwInput{document}
          \kwOutput{candidats}
          \BlankLine

          patron $\leftarrow$ Nil\;\label{algo:line:start_preselection}
          \If{\textnormal{document.langue = "francais"}}{
            patron $\leftarrow$ \texttt{/N+ A?/}\;
          }\Else{
            \If{\textnormal{document.langue = "anglais"}}{
              patron $\leftarrow$ \texttt{/A? N+/}\;
            }
          }

          candidats $\leftarrow$ \{\}\;
          candidats\_preliminaires $\leftarrow$ preselection(document, patron)\;\label{algo:line:end_preselection}

          \For{\textnormal{cdt} $\in$ \textnormal{candidats\_preliminaires}}{\label{algo:line:start_filtering}
            \If{$\exists{}\textnormal{mot} \in$ \textnormal{cdt},
            \textnormal{estAdjectif(mot)} $\wedge$ $\overline{\textnormal{estRelationnel(mot)}}$ $\wedge$ $\overline{\textnormal{estCompose(mot)}}$}{
              tete\_cdt $\leftarrow$ cdt $-$ mot\;
              freq\_cdt $\leftarrow$ \textnormal{document.conter(cdt)}\;
              freq\_tete\_cdt $\leftarrow$ \textnormal{document.conter(tete\_cdt)} $-$ freq\_cdt\;
              \If{\textnormal{freq\_cdt} $>$ \textnormal{freq\_tete\_cdt}}{
                candidats $\leftarrow$ candidats $\cup$ \{cdt\}\;
              }\Else{
                candidats $\leftarrow$ candidats $\cup$ \{tete\_cdt\}\;
              }
            }\Else{
              candidats $\leftarrow$ candidats $\cup$ \{cdt\}\;
            }
          }\label{algo:line:end_filtering}

          \caption{Sélection fine des termes-clés candidats
                   \label{algo:candidate_pruning}}
        \end{algorithm}

    \subsection{Évaluation}
    \label{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation}
      Afin de montrer la validité de notre méthode de sélection de candidats,
      nous réalisons deux expériences~: l'une intrinsèque, où les ensembles de
      termes-clés candidats de différentes méthodes de sélections sont comparés
      qualitativement, l'autre extrinsèque, où les différentes méthodes de
      sélections sont comparés d'après les performances de deux méthodes
      d'extraction de termes-clés.

      \subsubsection{Méthodes de référence}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-baselines}
        Nous comparons notre méthode de sélection de termes-clés candidats a
        trois autres méthodes utilisées dans les travaux précédents en
        extraction automatique de termes-clés~:
        \begin{itemize}
          \item{sélection des n-grammes ($1 \leq n \leq 3$)~;}
          \item{sélection des plus longues séquences de noms et d'adjectifs~:
                \texttt{/(N|A)+/}~;}
          \item{sélection des \textit{NP-chunks}~:}
          \begin{itemize}
            \item{\texttt{/Np+|(A? Nc A+)|(A Nc)|Nc+/} en français~;}
            \item{\texttt{/Np+|(A+ Nc)|Nc+/} en anglais.}
          \end{itemize}
        \end{itemize}

        Pour l'évaluation extrinsèque, nous utilisons deux méthodes d'extraction
        automatique de termes-clés très utilisées~: la méthode non supervisée
        \textsc{Tf-Idf} et la méthode supervisée \textsc{Kea}. Bien que des
        méthodes plus récentes donnent de meilleures performances que
        \textsc{Tf-Idf} et \textsc{Kea}~\cite{kim2010semeval}, ces dernières
        présentent l'avantage d'être reproductibles, ce qui nous permet de les
        utiliser avec les mêmes prétraitements des collections de données et
        avec les termes-clés candidats que nous souhaitons.

      \subsubsection{Collections de données}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-evaluation_data}
        Pour évaluer ce travail, nous utilisons les ensembles de test de toutes
        nos collections de données, sauf Wikinews. Cette dernière collection ne
        possède pas d'ensemble d'entraînement et ne peut donc pas être utilisée
        pour la méthode de référence \textsc{Kea}.
      
      \subsubsection{Mesures d'évaluation}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-evaluation_measures}
        Pour évaluer la qualité des ensembles de termes-clés candidats
        sélectionnés par les différentes méthodes de sélection, nous comparons
        le nombre moyen de candidats sélectionnés au rappel maximal
        (R$_\textnormal{max}$). Nous estimons que plus un ensemble de
        termes-clés candidats permet d'atteindre une performance maximale élevée
        (R$_\textnormal{max}$) avec un nombre de candidats réduit, alors plus il
        est de bonne qualité. Pour cela, nous dérterminons la qualité $Q$ d'un
        ensemble de termes-clés candidats en calculant le rapport entre le
        rappel maximal et le nombre de candidats~:
        \begin{align}
          Q &= \frac{\textnormal{R}_{\textnormal{max}}}{\textnormal{Candidats}}
        \end{align}
        Plus $Q$ est élevé, meilleure est la qualité de l'ensemble des
        termes-clés candidats sélectionnés.

        Les performances des méthodes d'extraction de termes-clés sont exprimées
        en termes de précision (P), rappel (R) et f-mesure (f1-mesure, F). En
        accord avec l'évaluation menée dans les travaux
        précédents~\cite{kim2010semeval}, les opérations de comparaison entre
        les termes-clés de référence et les termes-clés extraits sont effectuées
        à partir de la racine des mots qui les composent, d'après la méthode de
        \newcite{porter1980suffixstripping}.

      \subsubsection{Évaluation intrinsèque}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-intrinsic_evaluation}
        L'évaluation intrinsèque a pour objectif d'évaluer la qualité de
        l'ensemble des termes-clés candidats sélectionnés par notre méthode
        (\textsc{Lr-Np}, pour \textit{Linguistically-Refined Noun Phrases}) et
        de la comparer à celle des ensembles de termes-clés sélectionnés par les
        méthodes de référence. Nous faisons l'hypothèse que plus une
        méthode de sélection de candidats permet un rappel maximum élevé
        (quasi-optimal) tout en limitant la quantité de termes-clés candidats
        sélectionnés, alors plus elle fournit un ensemble de candidats de bonne
        qualité.

        Les tableau~\ref{tab:candidate_extraction_statistics_termith}
        et~\ref{tab:candidate_extraction_statistics_deft_semeval_duc} présentent
        les résultats de l'évaluation intrinsèque. Le nombre de candidats
        sélectionnés par chaque méthode, le rappel maximum pouvant être atteint
        avec ceux-ci et la mesure QR sont reportés pour chacune des
        trois collections de données utilisées pour cette évaluation.
        \begin{table}[!h]
          \centering
          \resizebox{\linewidth}{!}{
            \begin{tabular}{r|cc|c|cc|c|cc|c|cc|c}
              \toprule
              \multirow{2}{*}[-2pt]{\textbf{Méthode}} & \multicolumn{3}{c|}{\textbf{Linguistique}} & \multicolumn{3}{c|}{\textbf{Sciences de l'information}} & \multicolumn{3}{c|}{\textbf{Archéologie}} & \multicolumn{3}{c}{\textbf{Chimie}}\\
              \cline{2-13}
              & Candidats & R$_{\text{max}}$ & $Q$ & Candidats & R$_{\text{max}}$ & $Q$ & Candidats & R$_{\text{max}}$ & $Q$ & Candidats & R$_{\text{max}}$ & $Q$\\
              \hline
              n-grammes & & \textbf{35,9} & & & \textbf{32,4} & & & \textbf{58,5} & & & \textbf{20.5} &\\
              \texttt{/(N|A)+/} & & 25,1 & & & 24,2 & & & 43,9 & & & 16,8 &\\
              \textit{NP-chunks} & & 24,0 & & & 24,5 & & & 44.0 & & & 16,5 &\\
              \textsc{Lr-Np} & & 23,9 & & & 24,2 & & & 43,7 & & & 16,7 &\\
              \bottomrule
            \end{tabular}
          }
          \caption{Résultats de l'évaluation intrinsèque des méthodes de
                   sélection des termes-clés candidats sur les collections de
                   données Termith
                   \label{tab:candidate_extraction_statistics_termith}}
        \end{table}
        \begin{table}[!h]
          \centering
          \resizebox{\linewidth}{!}{
            \begin{tabular}{r|cc|c|cc|c|cc|c}
              \toprule
              \multirow{2}{*}[-2pt]{\textbf{Méthode}} & \multicolumn{3}{c|}{\textbf{\textsc{Duc}}} & \multicolumn{3}{c|}{\textbf{SemEval}} & \multicolumn{3}{c}{\textbf{\textsc{De}ft}}\\
              \cline{2-10}
              & Candidats & R$_{\text{max}}$ & $Q$ & Candidats & R$_{\text{max}}$ & $Q$ & Candidats & R$_{\text{max}}$ & $Q$\\
              \hline
              n-grammes & $~~~$596.2 & \textbf{90.8} & 0.15 & 2580.5 & \textbf{72.2} & 0.03 & 4070.2 & \textbf{74.1} & 0.02\\
              \texttt{/(N|A)+/} & $~~~$155.6 & 88.7 & 0.57 & $~~~$646.5 & 62.4 & 0.10 & $~~~$914.5 & 61.1 & 0.07\\
              \textit{NP-chunks} & $~~~$149.9 & 76.0 & 0.51 & $~~~$598.4 & 56.6 & 0.10 & $~~~$812.3 & 63.0 & \textbf{0.08}\\
              LR-NP & \textbf{$~~~$143.8} & 85.3 & \textbf{0.59} & \textbf{$~~~$538.2} & 59.4 & \textbf{0.11} & \textbf{$~~~$738.2} & 60.1 & \textbf{0.08}\\
              \bottomrule
            \end{tabular}
          }
          \caption{Résultats de l'évaluation intrinsèque des méthodes de
                   sélection des termes-clés candidats sur les collections
                   \textsc{De}ft, SemEval et \textsc{Duc}
                   \label{tab:candidate_extraction_statistics_deft_semeval_duc}}
        \end{table}
        
        Globalement, nous remarquons que notre méthode sélectionne le moins de
        candidats sans nécessairement induire le moins bon rappel maximum
        (obtenu avec les \textit{NP-chunks}).
        C'est, sans surprise, la sélections des n-grammes qui induit le meilleur
        rappel maximum. Celui-ci est très proche du rappel maximum optimal, mais
        au prix d'un nombre de candidats 4 à 5 fois supérieur à celui des autres
        méthodes. Comme le montre la mesure de compromis entre nombre de
        candidats sélectionnés et rappel maximum (QR), notre méthode
        est de meilleure qualité que les autres, suivit par la méthode de
        sélection des \texttt{/(N|A)+/}, par la méthode de sélection des
        \textit{NP-chunks} et, de loin, par la méthode de sélection des
        n-grammes.

      \subsubsection{Évaluation extrinsèque}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-evaluation-extrinsic_evaluation}
        L'évaluation extrinsèque a pour objectif d'évaluer l'efficacité de notre
        méthode de sélection de termes-clés en situation réelle d'extraction de
        termes-clés et de la comparer à celle des méthodes de référence.
        Il s'agit aussi de valider notre hypothèse par laquelle plus une méthode
        de sélection de candidats permet un rappel maximum élevé tout en
        limitant la quantité de termes-clés candidats sélectionnés, alors plus
        elle fournit un ensemble de candidats de bonne qualité.

        Les
        tableaux~\ref{tab:keyphrase_extraction_results_with_filtering_termith}
        et~\ref{tab:keyphrase_extraction_results_with_filtering_deft_semeval_duc}
        présente les résultats de l'évaluation extrinsèque. La performance, en
        termes de précision, rappel et f-mesure, des méthodes \textsc{Tf-Idf} et
        \textsc{Kea} est reportée pour chacune des trois collections de données
        utilisées pour cette évaluation.
        \begin{table}[h!]
          \centering
          \resizebox{\linewidth}{!}{
            \begin{tabular}{r@{~}|c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}}
              \toprule
              \multirow{2}{*}[-2pt]{\textbf{Method}} & \multicolumn{6}{c@{~}|@{~}}{\textbf{Linguistique}} & \multicolumn{6}{c@{~}|@{~}}{\textbf{Sciences de l'information}} & \multicolumn{6}{c@{~}|@{~}}{\textbf{archéologie}} & \multicolumn{6}{c}{\textbf{Chimie}}\\
              \cline{2-25}
              & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c@{~}|@{~}}{KEA} & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c@{~}|@{~}}{KEA} & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c@{~}|@{~}}{KEA} & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c}{KEA}\\
              \cline{2-25}
              & P & R & F & P & R & F & P & R & F & P & R & F & P & R & F & P & R & F & P & R & F & P & R & F\\
              \hline
              n-grammes & 11,9 & 14,3 & 12,8 & 12,4 & 14,8 & 13,3 & 11,1 & 11,6 & 10,9 & 11,6 & 12,4 & 11,6 & 22,3 & 15,4 & 17,8 & 21,7 & 15,1 & 17,4 & 10,4 & $~~$8,3 & $~~$8,8 & $~~$9,8 & $~~$8,2 & $~~$8,5\\
              \texttt{/(N|A)+/} & 12,9 & 15,2 & 13,8 & 13,5 & 15,9 & 14,4 & 13,3 & 13,8 & 13,1 & 12,6 & 13,0 & 12,4 & 27,6 & 18,8 & 21,8 & 29,3 & 20,2 & 23,4 & 14,2 & 11,0 & 11,9 & 14,7 & 11,9 & 12,6\\
              \textit{NP-chunks} & 13,1 & 15,6 & 14,0 & \textbf{13,6} & \textbf{16,0} & \textbf{14,5} & \textbf{13,6} & \textbf{14,2} & \textbf{13,5} & \textbf{13,0} & \textbf{13,6} & \textbf{12,9} & \textbf{28,1} & \textbf{19,1} & \textbf{22,2} & 29,3 & 20,3 & 23,4 & 14,8 & 11,6 & 12,5 & 14,6 & 11,8 & 12,5\\
              \textsc{Lr-Np} & \textbf{13,3} & \textbf{15,8} & \textbf{14,2} & \textbf{13,6} & \textbf{16,0} & \textbf{14,5} & 13,4 & 14,1 & 13,3 & 12,6 & 13,2 & 12,5 & \textbf{28,1} & \textbf{19,1} & \textbf{22,2} & \textbf{29,9} & \textbf{20,5} & \textbf{23,8} & \textbf{15,0} & \textbf{11,8} & \textbf{12,6} & \textbf{14,9} & \textbf{12,0} & \textbf{12,7}\\
              \bottomrule
            \end{tabular}
          }
          \caption[
            Résultats de \textsc{Tf-Idf} et \textsc{Kea} selon la
            méthode de sélection des termes-clés candidats utilisée
          ]{
            Résultats de \textsc{Tf-Idf} et \textsc{Kea} d'après la
            méthode de sélection des termes-clés candidats utilisée.
            $\ddagger$ indique une amélioration significative par rapport à
            toutes les autres méthodes de sélection de candidats et $\dagger$
            indique une amélioration significative par rapport à toutes les
            méthodes sauf celle qui extrait les \texttt{/(N|A)+/}, à 0.001 pour
            le t-test de Student.
           \label{tab:keyphrase_extraction_results_with_filtering_termith}}
        \end{table}
        \begin{table}[h!]
          \centering
          \resizebox{\linewidth}{!}{
            \begin{tabular}{r@{~}|c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c@{~}|@{~}c@{~~}c@{~~}c}
              \toprule
              \multirow{2}{*}[-2pt]{\textbf{Method}} & \multicolumn{6}{c@{~}|@{~}}{\textbf{DUC}} & \multicolumn{6}{c@{~}|@{~}}{\textbf{SemEval}} & \multicolumn{6}{c}{\textbf{DEFT}}\\
              \cline{2-19}
              & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c@{~}|@{~}}{KEA} & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c@{~}|@{~}}{KEA} & \multicolumn{3}{c@{~}|@{~}}{TF-IDF} & \multicolumn{3}{c}{KEA}\\
              \cline{2-19}
              & P & R & F & P & R & F & P & R & F & P & R & F & P & R & F & P & R & F\\
              \hline
              n-grammes & 14.3 & 19.0 & 16.1$~~$ & 12.0 & 16.6 & 13.7$~~$ & $~~$9.0 & $~~$6.6 & $~~$7.2$~~$ & 19.4 & 13.7 & 15.9 & $~~$6.7 & 12.5 & $~~$8.6 & 13.4 & 25.3 & 17.3\\
              \texttt{/(N|A)+/} & 24.2 & 31.7 & 27.0$~~$ & \textbf{14.5} & 19.9 & 16.5$~~$ & 11.7 & $~~$7.9 & $~~$9.3$~~$ & 19.6 & 13.7 & 16.0 & $~~$9.5 & 17.6 & 12.1 & 14.1 & 26.3  &18.1\\
              \textit{NP-chunks} & 21.1 & 28.1 & 23.8$~~$ & 13.5 & 18.6 & 15.4$~~$ & 11.9 & $~~$8.0 & $~~$9.5$~~$ & 19.5 & 13.7 & 16.0 & $~~$9.6 & 17.9 & 12.3 & 14.3 & 26.8 & 18.4\\
              LR-NP & \textbf{24.3} & \textbf{32.0} & \textbf{27.2$^\dagger$} & \textbf{14.5} & \textbf{20.0} & \textbf{16.6$^\ddagger$} & \textbf{12.4} & \textbf{$~~$8.4} & \textbf{$~~$9.9$^\ddagger$} & \textbf{20.4} & \textbf{14.4} & \textbf{16.7}& \textbf{10.1} & \textbf{18.5} & \textbf{12.9} & \textbf{14.4} & \textbf{27.0} & \textbf{18.6}\\
              \bottomrule
            \end{tabular}
          }
          \caption[
            Résultats de \textsc{Tf-Idf} et \textsc{Kea} selon la
            méthode de sélection des termes-clés candidats utilisée
          ]{
            Résultats de \textsc{Tf-Idf} et \textsc{Kea} d'après la
            méthode de sélection des termes-clés candidats utilisée.
            $\ddagger$ indique une amélioration significative par rapport à
            toutes les autres méthodes de sélection de candidats et $\dagger$
            indique une amélioration significative par rapport à toutes les
            méthodes sauf celle qui extrait les \texttt{/(N|A)+/}, à 0.001 pour
            le t-test de Student.
           \label{tab:keyphrase_extraction_results_with_filtering_deft_semeval_duc}}
        \end{table}

        Globalement, la performance des méthodes d'extraction de termes-clés est
        corrélée à la qualité de l'ensemble des termes-clés candidats
        sélectionnés. Les candidats sélectionnés avec notre méthode induisent
        les meilleures performances dans les six cas de figure étudiés et, dans
        la moitié des cas, l'amélioration vis-à-vis des méthodes de référence
        est significative. Au delà de montrer la pertinence de filtrer certains
        adjectifs lors de la sélection des termes-clés candidats, les résultats
        montrent la validité de notre hypothèse par laquelle plus une méthode de
        sélection de candidats permet un rappel maximum élevé tout en limitant
        la quantité de termes-clés candidats sélectionnés, alors plus
        elle fournit un ensemble de candidats de bonne qualité et plus aisée
        sera l'extraction de termes-clés.

    \subsection{Bilan}
    \label{subsec:main:domain_independent_keyphrase_extraction-keyphrase_candidate_selection-conclusion}
      Nous avons proposé une méthode de sélection des termes-clés candidats d'un
      document. Développée à l'issue d'une analyse des propriétés linguistiques
      des termes-clés de référence de trois collections de données, notre
      méthode préselectionne des termes-clés candidats composés uniquement de
      noms et d'au plus un adjectif, puis détermine si l'adjectif des candidats
      apporte du sens selon sa catégorie (relationnel, composé complexe ou
      qualificatif) et son usage dans le document. Vis-à-vis des méthodes de
      sélection de termes-clés candidats les plus utilisées, celle-ci présente
      l'avantage de sélectionner moins de candidats sans réduire
      significativement le nombre de candidats positifs qui s'y trouvent. La
      qualité de l'ensemble de candidats proposés est donc supérieure et permet
      de réduire aussi bien le temps de traitement pour l'extraction de
      termes-clés que les risques d'erreurs.

      Ce travail s'intéresse principalement aux adjectifs relationnels, qui
      constituent une sous-partie des adjectifs dénominaux. À l'avenir, il
      serait intéressant d'élargir notre étude à tous les adjectifs dénominaux,
      ainsi qu'à d'autres adjectifs dérivés~: les déverbaux. Est-ce l'aspect
      relationnel de l'adjectif qui le rend si particulier dans le context de
      l'extraction de termes-clés, ou est-ce parce qu'il est issu d'un nom~? La
      dérivation comme procéssus de formation d'un adjectif est-elle un indice
      quant à l'apport de l'adjectif au sens d'un terme-clé~? Autant de
      questions auxquelles il faudra répondre.

  %-----------------------------------------------------------------------------

  \section{Extraction automatique non supervisée de termes-clés}
  \label{sec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction}
    Dans cet section, nous présentons TopicRank, une méthode non supervisée à
    base de graphe pour l'extraction automatique de termes-clés. Ce travail se
    fonde sur celui de \newcite{mihalcea2004textrank}, qui ont proposé TextRank.
    Notre objectif est de résoudre les faiblesses de l'approche à base de
    graphe, que nous identifions dans le
    \ANNOTATE{chapitre~\ref{chap:main-state_of_the_art}
    (page~\pageref{chap:main-state_of_the_art})}{état de l'art}.

    \TODO{enlever le paragraphe precedent et intégrer celui-ci}
    L'ordonnancement des unités textuelles du document, afin de déterminer
    lesquelles sont les plus importantes vis-à-vis de son contenu, est
    principalement réalisé avec des approches non supervisées. Parmi elles, nous
    nous intéressons à l'approche à base de graphe. Celle-ci consiste à
    représenter le document sous la forme d'un graphe de cooccurrences de mots
    et à appliquer à ce graphe un algorithme pour identifier les n\oe{}uds
    (mots) les plus centraux dans le graphe. Dans notre travail, nous remettons
    en question l'ordonnancement des mots alors que les termes-clés peuvent être
    des expressions multi-mots. Nous groupons les termes-clés candidats qui
    expriment le même sujet et proposons d'ordonner ces sujets plutôt que les
    mots.

    Les méthodes à base de graphe actuelles déterminent l'importance des mots du
    document, puis utilisent cette importance soit pour générer les
    termes-clés~\cite{mihalcea2004textrank}, soit pour déterminer l'importance
    des termes-clés candidats en faisant la somme du score d'importance de leurs
    mots~\cite{wan2008expandrank}. Nous jugeons qu'il est plus pertinent
    d'utiliser l'algorithme d'ordonnancement à base de graphe pour ordonner
    directement les termes-clés candidats et ainsi éviter les problèmes de
    redondance que nous évoquons dans le
    \ANNOTATE{chapitre~\ref{chap:main-state_of_the_art}
    (page~\pageref{chap:main-state_of_the_art})}{état de l'art} et que nous montrons dans
    l'exemple \TODO{ref vers l'exemple à mettre dans l'état de l'art}
    (\TODO{page ???}).
    
    En plus de cela, les méthodes actuelles ne tiennent pas compte du phénomène
    de variation lexicale, qui consiste à utiliser des unités textuelles
    différentes d'un point de vue lexicale mais équivalentes d'un point de vue
    sémantique afin d'éviter les répétitions dans le texte. Ne pas tenir compte
    de ce phénomène engendre une dispersion, dans le graphe, d'informations
    relatives à un même sujet.
    
    Enfin, les expériences réalisées dans le travail de
    \newcite{mihalcea2004textrank} et dans celui de \newcite{wan2008expandrank}
    montrent un comportement marginal des différentes approches à base de graphe
    vis-à-vis de la valeur de la fenêtre de cooccurrence. Les performances
    relevées dans les expériences de \newcite{mihalcea2004textrank} montrent que
    plus la fenêtre de cooccurrence est élevée, moins l'extraction de
    termes-clés est performante, alors que celles relevées par
    \newcite{wan2008expandrank} montrent le comportement inverse. \TODO{mettre
    les courbes de Mihalcea et celles de Wan}

    Avec TopicRank, nous proposons une solution pour résoudre les trois
    problèmes énoncés ci-dessus. Dans la suite, nous présentons TopicRank, nous
    l'évaluons, nous le comparons à l'existant, puis nous en analysons les
    erreurs.

    \subsection{TopicRank}
    \label{subsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank}
      TopicRank est une méthode à base de graphe pour extraire des termes-clés
      représentant chacun un sujet important dans le document.
      % Quel en est le fonctionnement général ?
      Elle repose sur les quatre étapes suivantes, qui sont détaillées dans
      la suite~: identification des sujets, construction d'un graphe de sujets,
      ordonnancement des sujets et sélection du terme-clé candidat le plus
      représentatif de chaque sujet.

      \subsubsection{Identification des sujets}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-topic_identification}
        Pour TopicRank, un sujet représente un thème du document qui est
        véhiculé par un ou plusieurs termes-clés candidats.
%
%        % Que nous faut-il pour identifier les sujets ?
%        La première étape de l'identification des sujets consiste à sélectionner
%        les termes-clés candidats.
%        % Quels candidats composent les sujets ?
%        Pour ce travail, nous suivons \newcite{wan2008expandrank} et
%        sélectionnons les plus longues séquences de noms, de noms propres et
%        d'adjectifs à partir du patron grammatical suivant~:\texttt{/(N|A)+}.
%        Celui-ci présente l'avantage d'être simple et adapté à plusieurs
%        langues, telles que les langues latines (anglais, français, etc.),
%        lorsque les outils d'étiquetage grammatical sont disponibles pour la
%        langue concernée. De plus, ce patron est gourmand, c'est-à-dire qu'il
%        capture les séquences les plus longues qui le respectent, et il est donc
%        adapté pour le groupement que nous effectuons ensuite.
%
        % Comment détectons nous deux candidats appartenant au même sujet ?
        L'identification des sujets à partir des termes-clés candidats consiste
        à les grouper lorsqu'ils sont supposés appartenir au même sujet. Afin de
        proposer une méthode générique n'utilisant pas de données
        supplémentaires, nous appliquons un groupement \og{}naïf\fg{} des
        candidats, fondé sur les mots qu'ils partagent.

        Deux candidats $c_1$ et $c_2$ sont considérés comme des ensembles de
        mots (sacs de mots) et leur degré de similarité est calculé à l'aide de
        la mesure de Jaccard (cf équation~\ref{equa:jaccard}). Ce dernier est
        d'autant plus élevé que les candidats partagent un grand nombre de mots.
        À l'instar des systèmes d'évaluation automatique, nous ajoutons plus de
        souplesse à la mesure de similarité, en tronquant les mots avec la
        méthode de racinisation de~\newcite{porter1980suffixstripping}.
        \begin{align}
          \text{sim}(c_1, c_2) &= \frac{|\textnormal{Porter}(c_1)\ \cap\ \textnormal{Porter}(c_2)|}{|\textnormal{Porter}(c_1)\ \cup\ \textnormal{Porter}(c_2)|} \label{equa:jaccard}
        \end{align}
        Cette mesure est \og{}naïve\fg{}, car l'ordre des mots, leur ambiguïté
        et leur synonymie ne sont pas pris en compte (\TODO{exempleS}). À cela
        s'ajoute aussi des erreurs introduites par l'usage de la méthode de
        \newcite{porter1980suffixstripping} (par exemple les mots
        \og{}empire\fg{} et \og{}empirique\fg{} partagent le même radical
        \og{}empir\fg{}).

        % Comment groupons nous les candidats d'un même sujet ?
        Le groupement des termes-clés candidats en sujets est effectué avec
        l'algorithme de groupement hiérarchique agglomératif
        (\textit{Hierarchical Agglomerative Clustering -- \textsc{Hac}}).
        L'algorithme~\ref{algo:hac} décrit le fonctionnement classique du
        groupement \textsc{Hac}. Initialement, chaque candidat représente un
        groupe et, jusqu'à l'obtention d'un nombre prédéfini de groupes, ceux
        dont les candidats ont la plus forte similarité sont unis pour ne former
        qu'un seul groupe. Afin de ne pas fixer le nombre de sujets (groupe) à
        identifier comme condition d'arrêt de l'algorithme, nous définissons un
        seuil de similarité $\zeta$ devant être dépassé ou égalé afin de pouvoir
        unifier deux groupes. La similarité entre deux groupes est déterminée à
        partir de la similarité de Jaccard calculée entre tous les candidats de
        chaque groupe. Il existe trois stratégies pour la calculer~:
        \begin{itemize}
          \item{simple~: la plus grande valeur de similarité entre les candidats
                des deux groupes sert de similarité entre eux~;}
          \item{complète~: la plus petite valeur de similarité entre les
                candidats des deux groupes sert de similarité entre eux~;}
          \item{moyenne~: la moyenne de toutes les similarités entre les
                candidats des deux groupes sert de similarité entre eux
                (compromis entre les stratégies simple et complète).}
        \end{itemize}
        L'une ou l'autre de ces stratégies est à privilégier en fonction du type
        des candidats extraits. Pour des candidats qui ont de forts
        recouvrements, tels que les n-grammes, il serait plus pertinent
        d'utiliser la stratégie complète qui est la moins agglomérative. Dans le
        cas de TopicRank, où les candidats sont de meilleure qualité que les
        n-grammes, la stratégie moyenne est une meilleure alternative.
        \begin{algorithm}
          \SetKwInOut{kwInput}{Entrée}
          \SetKwInOut{kwOutput}{Sortie}
          \SetKwFor{For}{Pour chaque}{faire}{}
          \SetKwFor{While}{Tant que}{faire}{}
          \SetKwIF{If}{ElseIf}{Else}{Si}{alors}{Sinon si}{Sinon}{}
          \SetKw{KwRet}{Retourner}
          \DontPrintSemicolon{}

          \kwInput{candidats $= \{c_1, \dots, c_n\}$}
          \kwInput{nb\_groupes}
          \kwOutput{groupes}
          \BlankLine

          groupes $\leftarrow \left\{\{c_1\}, \dots, \{c_n\}\right\}$\;
          \While{|\textnormal{groupes}| > \textnormal{nb\_groupes}}{
            $\langle{}g_i, g_j\rangle{} \leftarrow \arg\max_{g_i, g_j \in \textnormal{groupes}, g_i \neq g_j}\textnormal{sim}(g_i, g_j)$\;
            groupes $\leftarrow \textnormal{groupes}_{\setminus\{g_i, g_j\}} \cup \{g_i \cup g_j\}$
          }

          \caption{\textsc{Hac}
                   \label{algo:hac}}
        \end{algorithm}

        \TODO{Exemple étape par étape}
        \TODO{illustrer les stratégies dans l'exemple (ou un autre ?)}

      \subsubsection{Construction du graphe}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-graph_construction}
        Afin d'identifier les sujets les plus importants du documents, nous
        utilisons un graphe qui représente tous les sujets du document avec les
        relations qu'ils entretiennent.

        % Comment le graphe est-il construit ?
        Soit le graphe complet $G = (N, A)$ non orienté, composé d'un ensemble
        de n\oe{}uds $N$ et d'arêtes $A$\footnote{$A = \{(n_1, n_2)\ |\
        \forall{n_1, n_2 \in N}, n_1 \neq n_2\}$, car $G$ est un graphe
        complet.}. Les sujets sont représentés par les n\oe{}uds du graphe et
        les arêtes qui les connectent représentent la force de leur lien
        sémantique. Contrairement aux travaux précédent, nous ne souhaitons pas
        utiliser de fenêtre de cooccurrence et ne pouvons donc pas exprimer la
        force du lien sémantique entre deux sujets par leur nombre de
        cooccurrences. Pour préserver l'intuition derrière l'usage du nombre de
        cooccurrences, nous connectons tous les n\oe{}uds deux à deux et
        exprimons la force de leur lien sémantique à partir de la distance (en
        nombre de mots) qui les sépare dans le document~:
        \begin{align}
          \text{poids}(n_i, n_j) &= \sum_{c_i \in n_i}\ \sum_{c_j \in n_j} \text{dist}(c_i, c_j) \label{math:ponderation}\\
          \text{dist}(c_i, c_j) &= \sum_{p_i \in \text{pos}(c_i)}\ \sum_{p_j \in \text{pos}(c_j)} \frac{1}{|p_i - p_j|} \label{math:distance}
        \end{align}
        où $\text{poids}(n_i, n_j)$ est le poids de l'arête entre les sujets
        $n_i$ et $n_j$, et où $\text{dist}(c_i, c_j)$ représente la force
        sémantique entre les candidats $c_i$ et $c_j$, calculée à partir de
        leurs positions respectives, $\text{pos}(c_i)$ et $\text{pos}(c_j)$,
        dans le document.

      \subsubsection{Ordonnancement des sujets}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-topic_ranking}
        % Quel est le but de l'ordonnancement ?
        % Comment est-il effectué ?
        L'ordonnancement des sujets doit établir un ordre d'importance des
        sujets du document.
        % Comment le graphe est-il utilisé pour ordonner les sujets ?
        % Quelle est l'intuition de PageRank/TextRank ?
        Pour cela, nous appliquons l'algorithme d'ordonnancement de
        SingleRank~\cite{wan2008expandrank} à notre graphe
        de sujets. Cet algorithme se fonde sur le principe de recommandation,
        ou de vote, c'est-à-dire un sujet est d'autant plus important s'il est
        fortement connecté avec un grand nombre de sujets et si les sujets avec
        lesquels il est fortement connecté sont importants~:
        \begin{align}
          S(n_i) &= (1 - \lambda) + \lambda \times \sum_{n_j \in A(n_i)} \frac{\text{poids}(n_j, n_i) \times S(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} \text{poids}(n_i, n_j)}
        \end{align}
        où $A(n_i)$ est l'ensemble des sujets\footnote{$A(n_i) = \{n_j\ |\
        \forall{n_j \in N}, n_j \neq n_i\}$, car $G$ est un graphe complet.}
        connectés au sujet $n_i$ et où $\lambda$ est un facteur d'atténuation.
        Défini entre 0 et 1, ce dernier peut être considéré comme la probabilité
        pour que le sujet $n_i$ soit utilisé par recommandation. Nous suivons
        \newcite{brin1998pagerank} et fixons $\lambda$ à 0,85.

      \subsubsection{Sélection des termes-clés}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-keyphrase_selection}
        % De quoi s'agit-il ?
        La sélection des termes-clés est la dernière étape de TopicRank. Elle
        consiste à chercher les termes-clés candidats qui représentent le mieux
        les sujets importants. Dans le but de ne pas extraire de termes-clés
        redondants, un seul candidat est sélectionné par sujet.
        % Quel en est le but ?
        Ainsi, pour $k$ sujets, $k$ termes-clés non redondants couvrant
        exactement $k$ sujets sont extraits.

        % Quelles sont les différentes stratégies envisageable ?
        La difficulté de ce principe de sélection réside dans la capacité à
        trouver parmi plusieurs termes-clés candidats d'un même sujet celui qui
        le représente le mieux. Nous proposons trois stratégies de sélection
        pouvant répondre à ce problème~:
        \begin{itemize}
          \item{position~: en supposant qu'un sujet est tout d'abord
                introduit par sa forme la plus appropriée, le terme-clé
                candidat sélectionné pour un sujet est celui qui apparaît en
                premier dans le document~;}
          \item{fréquence~: en supposant que la forme la plus représentative
                d'un sujet est sa forme la plus fréquente, le terme-clé candidat
                sélectionné pour un sujet est celui qui est le plus fréquent
                dans le document~;}
          \item{centroïde~: le terme-clé candidat sélectionné pour un sujet
                est celui qui est le plus similaire aux autres candidats du
                sujet (voir l'équation~\ref{equa:jaccard}).}
        \end{itemize}
        % Laquelle des trois stratégies semble être la mieux ?
        Parmi ces trois stratégies, celle qui semble la plus appropriée est la
        stratégie position. Sélectionner les candidats les plus fréquents risque
        de ne pas être une solution stable selon les genres de documents, en
        particulier selon leur taille~; sélectionner les centroïdes risque de ne
        pas fournir les termes-clés les plus précis (informatif), car celui-ci
        représente le tronc commun à la majorité des candidats.

      \subsubsection{Exemple}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-topicrank-example}
        \TODO{exemple}

    \subsection{Évaluation}
    \label{subsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation}
      Pour valider notre approche, nous réalisons deux série d'expériences. Une
      première série pour déterminer les paramètres optimaux de TopicRank et
      une seconde séries pour le comparer aux travaux précédents, ainsi
      que pour analyser l'impact de chacune de nos contributions.
      
      \subsubsection{Méthodes de référence}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-baselines}
        % Comment les baselines sont-elles choisies ?
        Dans nos expériences, nous comparons TopicRank à trois autres
        méthodes non supervisées d'extraction automatique de termes-clés. Nous
        choisissons TextRank et SingleRank, les deux méthodes qui sont la
        fondation des méthodes à base de graphe, et la méthode TF-IDF.

        \TODO{Dans un but de comparaison, nous reportons tout d'abord les
        résultats de TopicRank avec le patrons \texttt{/(N|A)+/} utilisé pour
        SingleRank pour la sélection des candidats}

      \subsubsection{Collections de données}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-evaluation_data}
        Pour évaluer ce travail, nous utilisons quatre des cinq collections dont
        nous disposons\footnote{La collection de données Termith est utilisée
        pour évaluer manuellement nos travaux. Les évaluations manuelles sont
        présentées dans le chapitre \TODO{6} (page \TODO{}).}. Nous utilisons
        les deux collections d'articles journalistiques \textsc{Duc} (anglais)
        et Wikinews (français), ainsi que les deux collections d'articles
        scientifiques SemEval (anglais) et \textsc{Deft} (français).

      \subsubsection{Mesures d'évaluation}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-evaluation_measures}
        Les performances des méthodes d'extraction de termes-clés sont exprimées
        en termes de précision (P), rappel (R) et f-mesure (f1-mesure, F). En
        accord avec l'évaluation menée dans les travaux précédents, nous
        considérons correcte l'extraction d'une variante flexionnelle d'un
        terme-clé de référence~\cite{kim2010semeval}. Les opérations de
        comparaison entre les termes-clés de référence et les termes-clés
        extraits sont donc effectuées à partir de la racine des mots qui les
        composent, selon la méthode de \newcite{porter1980suffixstripping}.

      \subsubsection{Analyse empirique de TopicRank}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-empirical_analysis_of_topicrank}
        Dans cette section, nous effectuons une première série d'expériences
        afin de déterminer quelle est la configuration optimale de TopicRank. En
        utilisant les ensembles d'entraînement de SemEval et de \textsc{Deft},
        nous réalisons deux expériences durant lesquelles nous faisons varier,
        dans un premier temps, le seuil de similarité ($\zeta$) et la stratégie
        de groupement (simple, complète et moyenne), puis dans un second temps,
        la stratégie de sélection du terme-clé candidat le plus représentatif de
        chacun des sujets les plus importants.
        \begin{figure}
          \centering
          \subfigure[Linguistique]{
            \begin{tikzpicture}
              \pgfkeys{/pgf/number format/.cd, use comma, fixed}
              \begin{axis}[x=0.37\linewidth,
                           xtick={0.0, 0.25, ..., 1.0},
                           xmin=0.0,
                           xmax=1.0,
                           xlabel=$\zeta$,
                           x label style={yshift=.34em},
                           y=0.04\textheight,
                           ytick={0, 2, ..., 100},
                           ymin=12,
                           ymax=18,
                           ylabel=F,
                           y label style={yshift=-1.1em, rotate=270}]
                % simple
                \addplot[green!66, mark=x] coordinates{
                  (0.05, 13.3)
                  (0.10, 13.3)
                  (0.15, 13.3)
                  (0.20, 13.3)
                  (0.25, 13.3)
                  (0.30, 13.3)
                  (0.35, 13.6)
                  (0.40, 13.6)
                  (0.45, 13.6)
                  (0.50, 13.6)
                  (0.55, 14.4)
                  (0.60, 14.4)
                  (0.65, 14.4)
                  (0.70, 14.4)
                  (0.75, 14.4)
                  (0.80, 14.4)
                  (0.85, 14.4)
                  (0.90, 14.4)
                  (0.95, 14.4)
                  (1.00, 14.4)
                };
                % complet
                \addplot[cyan!66, mark=+] coordinates{
                  (0.05, 13.8)
                  (0.10, 13.8)
                  (0.15, 13.8)
                  (0.20, 13.8)
                  (0.25, 13.8)
                  (0.30, 13.9)
                  (0.35, 14.2)
                  (0.40, 14.2)
                  (0.45, 14.2)
                  (0.50, 14.2)
                  (0.55, 14.4)
                  (0.60, 14.4)
                  (0.65, 14.4)
                  (0.70, 14.4)
                  (0.75, 14.4)
                  (0.80, 14.4)
                  (0.85, 14.4)
                  (0.90, 14.4)
                  (0.95, 14.4)
                  (1.00, 14.4)
                };
                % moyen
                \addplot[red!66, mark=o] coordinates{
                  (0.05, 13.3)
                  (0.10, 13.4)
                  (0.15, 13.5)
                  (0.20, 13.8)
                  (0.25, 13.8)
                  (0.30, 13.9)
                  (0.35, 13.9)
                  (0.40, 14.0)
                  (0.45, 14.2)
                  (0.50, 14.2)
                  (0.55, 14.4)
                  (0.60, 14.4)
                  (0.65, 14.4)
                  (0.70, 14.4)
                  (0.75, 14.4)
                  (0.80, 14.4)
                  (0.85, 14.4)
                  (0.90, 14.4)
                  (0.95, 14.4)
                  (1.00, 14.4)
                };
%                \draw[thick] ({axis cs:0.55,0}|-{rel axis cs:0,1}) -- ({axis cs:0.55,0}|-{rel axis cs:0,0}) [color=red!66];
%                \draw[densely dashed] ({axis cs:0.25,0}|-{rel axis cs:0,1}) -- ({axis cs:0.25,0}|-{rel axis cs:0,0}) [color=black!66];
%                \node at (axis cs:0.55,17.5) [color=red!66, anchor=west] {\tiny{0,55}};
%                \node at (axis cs:0.25,17.5) [color=black!66, anchor=west] {\tiny{0,25}};
              \end{axis}
            \end{tikzpicture}
          }
          \subfigure[Sciences de l'info.]{
            \begin{tikzpicture}
              \pgfkeys{/pgf/number format/.cd, use comma, fixed}
              \begin{axis}[x=0.37\linewidth,
                           xtick={0.0, 0.25, ..., 1.0},
                           xmin=0.0,
                           xmax=1.0,
                           xlabel=$\zeta$,
                           x label style={yshift=.34em},
                           y=0.04\textheight,
                           ytick={0, 2, ..., 100},
                           ymin=12,
                           ymax=18,
                           ylabel=F,
                           y label style={yshift=-1.1em, rotate=270}]
                % simple
                \addplot[green!66, mark=x] coordinates{
                  (0.05, 12.3)
                  (0.10, 12.3)
                  (0.15, 12.3)
                  (0.20, 12.3)
                  (0.25, 12.3)
                  (0.30, 12.3)
                  (0.35, 12.6)
                  (0.40, 12.6)
                  (0.45, 12.6)
                  (0.50, 12.6)
                  (0.55, 13.3)
                  (0.60, 13.3)
                  (0.65, 13.3)
                  (0.70, 13.4)
                  (0.75, 13.4)
                  (0.80, 13.4)
                  (0.85, 13.4)
                  (0.90, 13.4)
                  (0.95, 13.4)
                  (1.00, 13.4)
                };
                % complet
                \addplot[cyan!66, mark=+] coordinates{
                  (0.05, 12.8)
                  (0.10, 12.8)
                  (0.15, 12.8)
                  (0.20, 12.8)
                  (0.25, 12.8)
                  (0.30, 12.8)
                  (0.35, 12.9)
                  (0.40, 12.9)
                  (0.45, 12.9)
                  (0.50, 12.9)
                  (0.55, 13.4)
                  (0.60, 13.4)
                  (0.65, 13.4)
                  (0.70, 13.4)
                  (0.75, 13.4)
                  (0.80, 13.4)
                  (0.85, 13.4)
                  (0.90, 13.4)
                  (0.95, 13.4)
                  (1.00, 13.4)
                };
                % moyen
                \addplot[red!66, mark=o] coordinates{
                  (0.05, 12.3)
                  (0.10, 12.4)
                  (0.15, 12.5)
                  (0.20, 12.6)
                  (0.25, 12.6)
                  (0.30, 12.7)
                  (0.35, 12.8)
                  (0.40, 12.7)
                  (0.45, 12.8)
                  (0.50, 12.9)
                  (0.55, 13.3)
                  (0.60, 13.4)
                  (0.65, 13.4)
                  (0.70, 13.4)
                  (0.75, 13.4)
                  (0.80, 13.4)
                  (0.85, 13.4)
                  (0.90, 13.4)
                  (0.95, 13.4)
                  (1.00, 13.4)
                };
%                \draw[thick] ({axis cs:0.55,0}|-{rel axis cs:0,1}) -- ({axis cs:0.55,0}|-{rel axis cs:0,0}) [color=red!66];
%                \draw[densely dashed] ({axis cs:0.25,0}|-{rel axis cs:0,1}) -- ({axis cs:0.25,0}|-{rel axis cs:0,0}) [color=black!66];
%                \node at (axis cs:0.55,17.5) [color=red!66, anchor=west] {\tiny{0,55}};
%                \node at (axis cs:0.25,17.5) [color=black!66, anchor=west] {\tiny{0,25}};
                \legend{Simple, Complète, Moyenne}
              \end{axis}
            \end{tikzpicture}
          }
          \subfigure[Archéologie]{
            \begin{tikzpicture}
              \pgfkeys{/pgf/number format/.cd, use comma, fixed}
              \begin{axis}[x=0.37\linewidth,
                           xtick={0.0, 0.25, ..., 1.0},
                           xmin=0.0,
                           xmax=1.0,
                           xlabel=$\zeta$,
                           x label style={yshift=.34em},
                           y=0.04\textheight,
                           ytick={0, 2, ..., 100},
                           ymin=18,
                           ymax=24,
                           ylabel=F,
                           y label style={yshift=-1.1em, rotate=270}]
                % simple
                \addplot[green!66, mark=x] coordinates{
                  (0.05, 20.0)
                  (0.10, 20.0)
                  (0.15, 20.0)
                  (0.20, 20.0)
                  (0.25, 20.1)
                  (0.30, 20.9)
                  (0.35, 20.9)
                  (0.40, 20.9)
                  (0.45, 20.9)
                  (0.50, 22.5)
                  (0.55, 22.5)
                  (0.60, 22.5)
                  (0.65, 22.6)
                  (0.70, 22.6)
                  (0.75, 22.6)
                  (0.80, 22.6)
                  (0.85, 22.6)
                  (0.90, 22.6)
                  (0.95, 22.6)
                  (1.00, 22.6)
                };
                % complet
                \addplot[cyan!66, mark=+] coordinates{
                  (0.05, 20.1)
                  (0.10, 20.1)
                  (0.15, 20.1)
                  (0.20, 20.2)
                  (0.25, 20.2)
                  (0.30, 20.5)
                  (0.35, 21.3)
                  (0.40, 21.3)
                  (0.45, 21.3)
                  (0.50, 21.3)
                  (0.55, 22.5)
                  (0.60, 22.5)
                  (0.65, 22.5)
                  (0.70, 22.6)
                  (0.75, 22.6)
                  (0.80, 22.6)
                  (0.85, 22.6)
                  (0.90, 22.6)
                  (0.95, 22.6)
                  (1.00, 22.6)
                };
                % moyen
                \addplot[red!66, mark=o] coordinates{
                  (0.05, 20.0)
                  (0.10, 20.1)
                  (0.15, 20.1)
                  (0.20, 20.1)
                  (0.25, 20.1)
                  (0.30, 20.4)
                  (0.35, 21.0)
                  (0.40, 21.0)
                  (0.45, 21.3)
                  (0.50, 21.3)
                  (0.55, 22.5)
                  (0.60, 22.5)
                  (0.65, 22.5)
                  (0.70, 22.6)
                  (0.75, 22.6)
                  (0.80, 22.6)
                  (0.85, 22.6)
                  (0.90, 22.6)
                  (0.95, 22.6)
                  (1.00, 22.6)
                };
%                \draw[thick] ({axis cs:0.65,0}|-{rel axis cs:0,1}) -- ({axis cs:0.65,0}|-{rel axis cs:0,0}) [color=red!66];
%                \draw[densely dashed] ({axis cs:0.25,0}|-{rel axis cs:0,1}) -- ({axis cs:0.25,0}|-{rel axis cs:0,0}) [color=black!66];
%                \node at (axis cs:0.65,27.5) [color=red!66, anchor=west] {\tiny{0,65}};
%                \node at (axis cs:0.25,27.5) [color=black!66, anchor=west] {\tiny{0,25}};
              \end{axis}
            \end{tikzpicture}
          }
          \subfigure[Chimie]{
            \begin{tikzpicture}
              \pgfkeys{/pgf/number format/.cd, use comma, fixed}
              \begin{axis}[x=0.37\linewidth,
                           xtick={0.0, 0.25, ..., 1.0},
                           xmin=0.0,
                           xmax=1.0,
                           xlabel=$\zeta$,
                           x label style={yshift=.34em},
                           y=0.04\textheight,
                           ytick={0, 2, ..., 100},
                           ymin=8,
                           ymax=14,
                           ylabel=F,
                           y label style={yshift=-1.1em, rotate=270}]
                % simple
                \addplot[green!66, mark=x] coordinates{
                  (0.05, 10.7)
                  (0.10, 10.7)
                  (0.15, 10.7)
                  (0.20, 10.7)
                  (0.25, 10.7)
                  (0.30, 10.7)
                  (0.35, 10.9)
                  (0.40, 10.9)
                  (0.45, 10.9)
                  (0.50, 10.9)
                  (0.55, 11.3)
                  (0.60, 11.3)
                  (0.65, 11.3)
                  (0.70, 11.2)
                  (0.75, 11.2)
                  (0.80, 11.2)
                  (0.85, 11.2)
                  (0.90, 11.2)
                  (0.95, 11.2)
                  (1.00, 11.2)
                };
                % complet
                \addplot[cyan!66, mark=+] coordinates{
                  (0.05, 10.9)
                  (0.10, 10.9)
                  (0.15, 10.9)
                  (0.20, 10.9)
                  (0.25, 10.9)
                  (0.30, 10.9)
                  (0.35, 10.9)
                  (0.40, 10.9)
                  (0.45, 10.9)
                  (0.50, 10.9)
                  (0.55, 11.3)
                  (0.60, 11.3)
                  (0.65, 11.3)
                  (0.70, 11.2)
                  (0.75, 11.2)
                  (0.80, 11.2)
                  (0.85, 11.2)
                  (0.90, 11.2)
                  (0.95, 11.2)
                  (1.00, 11.2)
                };
                % moyen
                \addplot[red!66, mark=o] coordinates{
                  (0.05, 10.7)
                  (0.10, 10.7)
                  (0.15, 10.8)
                  (0.20, 10.9)
                  (0.25, 10.9)
                  (0.30, 10.9)
                  (0.35, 10.9)
                  (0.40, 11.0)
                  (0.45, 10.9)
                  (0.50, 10.9)
                  (0.55, 11.3)
                  (0.60, 11.3)
                  (0.65, 11.3)
                  (0.70, 11.2)
                  (0.75, 11.2)
                  (0.80, 11.2)
                  (0.85, 11.2)
                  (0.90, 11.2)
                  (0.95, 11.2)
                  (1.00, 11.2)
                };
%                \draw[thick] ({axis cs:0.55,0}|-{rel axis cs:0,1}) -- ({axis cs:0.55,0}|-{rel axis cs:0,0}) [color=red!66];
%                \draw[densely dashed] ({axis cs:0.25,0}|-{rel axis cs:0,1}) -- ({axis cs:0.25,0}|-{rel axis cs:0,0}) [color=black!66];
%                \node at (axis cs:0.55,17.5) [color=red!66, anchor=west] {\tiny{0,55}};
%                \node at (axis cs:0.25,17.5) [color=black!66, anchor=west] {\tiny{0,25}};
              \end{axis}
            \end{tikzpicture}
          }
          \subfigure[\textsc{De}ft]{
            \begin{tikzpicture}
              \pgfkeys{/pgf/number format/.cd, use comma, fixed}
              \begin{axis}[x=0.37\linewidth,
                           xtick={0.0, 0.25, ..., 1.0},
                           xmin=0.0,
                           xmax=1.0,
                           xlabel=$\zeta$,
                           x label style={yshift=.34em},
                           y=0.024\textheight,
                           ytick={0, 2, ..., 100},
                           ymin=8,
                           ymax=18,
                           ylabel=F,
                           y label style={yshift=-1.1em, rotate=270}]
                % simple
                \addplot[green!66, mark=x] coordinates{
                  (0.05, 8.6)
                  (0.10, 8.6)
                  (0.15, 8.6)
                  (0.20, 8.6)
                  (0.25, 8.6)
                  (0.30, 8.9)
                  (0.35, 11.1)
                  (0.40, 11.1)
                  (0.45, 11.2)
                  (0.50, 11.2)
                  (0.55, 15.3)
                  (0.60, 15.3)
                  (0.65, 15.3)
                  (0.70, 15.6)
                  (0.75, 15.6)
                  (0.80, 15.6)
                  (0.85, 15.6)
                  (0.90, 15.6)
                  (0.95, 15.6)
                  (1.00, 15.6)
                };
                % complet
                \addplot[cyan!66, mark=+] coordinates{
                  (0.05, 15.8)
                  (0.10, 15.8)
                  (0.15, 15.8)
                  (0.20, 15.8)
                  (0.25, 15.9)
                  (0.30, 15.5)
                  (0.35, 16.1)
                  (0.40, 16.1)
                  (0.45, 16.1)
                  (0.50, 16.1)
                  (0.55, 15.6)
                  (0.60, 15.6)
                  (0.65, 15.6)
                  (0.70, 15.6)
                  (0.75, 15.6)
                  (0.80, 15.6)
                  (0.85, 15.6)
                  (0.90, 15.6)
                  (0.95, 15.6)
                  (1.00, 15.6)
                };
                % moyen
                \addplot[red!66, mark=o] coordinates{
                  (0.05, 13.8)
                  (0.10, 13.9)
                  (0.15, 14.9)
                  (0.20, 15.4)
                  (0.25, 15.2)
                  (0.30, 15.3)
                  (0.35, 15.3)
                  (0.40, 15.5)
                  (0.45, 15.8)
                  (0.50, 15.9)
                  (0.55, 15.4)
                  (0.60, 15.5)
                  (0.65, 15.6)
                  (0.70, 15.6)
                  (0.75, 15.6)
                  (0.80, 15.6)
                  (0.85, 15.6)
                  (0.90, 15.6)
                  (0.95, 15.6)
                  (1.00, 15.6)
                };
%                \draw[thick] ({axis cs:0.50,0}|-{rel axis cs:0,1}) -- ({axis cs:0.50,0}|-{rel axis cs:0,0}) [color=red!66];
%                \draw[densely dashed] ({axis cs:0.25,0}|-{rel axis cs:0,1}) -- ({axis cs:0.25,0}|-{rel axis cs:0,0}) [color=black!66];
%                \node at (axis cs:0.50,17.5) [color=red!66, anchor=west] {\tiny{0,50}};
%                \node at (axis cs:0.25,17.5) [color=black!66, anchor=west] {\tiny{0,25}};
              \end{axis}
            \end{tikzpicture}
          }
          \subfigure[SemEval]{
            \begin{tikzpicture}
              \pgfkeys{/pgf/number format/.cd, use comma, fixed}
              \begin{axis}[x=0.37\linewidth,
                           xtick={0.0, 0.25, ..., 1.0},
                           xmin=0.0,
                           xmax=1.0,
                           xlabel=$\zeta$,
                           x label style={yshift=.34em},
                           y=0.024\textheight,
                           ytick={0, 2, ..., 100},
                           ymin=4,
                           ymax=14,
                           ylabel=F,
                           y label style={yshift=-1.1em, rotate=270}]
                % simple
                \addplot[green!66, mark=x] coordinates{
                  (0.05, 4.2)
                  (0.10, 4.2)
                  (0.15, 4.4)
                  (0.20, 4.7)
                  (0.25, 4.9)
                  (0.30, 5.3)
                  (0.35, 7.4)
                  (0.40, 7.4)
                  (0.45, 7.3)
                  (0.50, 7.3)
                  (0.55, 7.5)
                  (0.60, 7.5)
                  (0.65, 7.5)
                  (0.70, 8.0)
                  (0.75, 8.0)
                  (0.80, 8.0)
                  (0.85, 8.0)
                  (0.90, 8.0)
                  (0.95, 8.0)
                  (1.00, 8.0)
                };
                % complet
                \addplot[cyan!66, mark=+] coordinates{
                  (0.05, 11.5)
                  (0.10, 11.5)
                  (0.15, 10.9)
                  (0.20, 10.3)
                  (0.25, 9.3)
                  (0.30, 7.8)
                  (0.35, 7.6)
                  (0.40, 7.6)
                  (0.45, 7.5)
                  (0.50, 7.5)
                  (0.55, 7.5)
                  (0.60, 7.5)
                  (0.65, 7.6)
                  (0.70, 8.0)
                  (0.75, 8.0)
                  (0.80, 8.0)
                  (0.85, 8.0)
                  (0.90, 8.0)
                  (0.95, 8.0)
                  (1.00, 8.0)
                };
                % moyen
                \addplot[red!66, mark=o] coordinates{
                  (0.05, 12.2)
                  (0.10, 11.7)
                  (0.15, 11.2)
                  (0.20, 11.4)
                  (0.25, 11.1)
                  (0.30, 10.2)
                  (0.35, 8.7)
                  (0.40, 7.7)
                  (0.45, 7.7)
                  (0.50, 7.5)
                  (0.55, 7.6)
                  (0.60, 7.6)
                  (0.65, 7.5)
                  (0.70, 8.0)
                  (0.75, 8.0)
                  (0.80, 8.0)
                  (0.85, 8.0)
                  (0.90, 8.0)
                  (0.95, 8.0)
                  (1.00, 8.0)
                };
                %\draw[thick] ({axis cs:0.05,0}|-{rel axis cs:0,1}) -- ({axis cs:0.05,0}|-{rel axis cs:0,0}) [color=red!66];
%                \draw[densely dashed] ({axis cs:0.25,0}|-{rel axis cs:0,1}) -- ({axis cs:0.25,0}|-{rel axis cs:0,0}) [color=black!66];
%                \node at (axis cs:0.05,17.5) [color=red!66, anchor=west] {\tiny{0,05}};
%                \node at (axis cs:0.25,17.5) [color=black!66, anchor=west] {\tiny{0,25}};
              \end{axis}
            \end{tikzpicture}
          }
          \caption[Résultats de l'extraction de dix termes-clés avec TopicRank,
                   en fonction de la stratégie de regroupement et de la valeur
                   du seuil de similarité $\zeta$]{
            Résultats de l'extraction de dix termes-clés avec TopicRank, en
            fonction de la stratégie de regroupement et de la valeur du seuil
            de similarité $\zeta$
            \label{fig:variation_du_seuil_de_similarite}
          }
        \end{figure}

        % Variation du seuil de similarité et de la stratégie de groupement
        La figure~\ref{fig:variation_du_seuil_de_similarite} présente les
        résultats de TopicRank lorsque nous faisons varier le seuil~$\zeta$ avec
        un pas de 0,05 pour toutes les stratégies de groupement\footnote{La
        stratégie de sélection du terme-clé le plus représentatif par sujet
        utilisée dans cette expérience est la stratégie position.}.
        % Quelle analyse peut-on faire à partir des courbes ?
        Globalement, chaque stratégie de groupement a un comportement qui lui
        est propre jusqu'à un certain point de convergence lorsque $\zeta$ vaut
        0,70, ce point de convergence correspondant à la valeur du seuil $\zeta$
        pour laquelle les sujets créés sont les mêmes quelle que soit la
        stratégie. Avec la stratégie simple, les résultats s'améliorent lorsque
        $\zeta$ augmente. Du fait qu'elle ne prend en compte que la similarité
        maximale entre deux candidats de deux groupes, cette stratégie à
        tendance à trop grouper et donc à créer des groupes contenant en réalité
        plusieurs sujets. L'augmentation du seuil $\zeta$ a pour effet de
        restreindre cette tendance et la qualité du groupement s'améliore. En
        opposition, la stratégie complète, qui a le fonctionnement inverse, voit
        ses résultats se dégrader lorsque $\zeta$ augmente. Enfin, la stratégie
        moyenne agit en compromis. Pour SemEval, son comportement est le même
        que celui de la stratégie complète, mais ses résultats sont supérieurs
        jusqu'au point de convergence. Pour \textsc{Deft}, son comportement est
        le même que celui de la stratégie simple, mais ses résultats sont très
        supérieurs jusqu'au point de convergence.
        % Quels sont les paramètres utilisés ?
        Dans la suite de nos expériences, nous décidons d'utiliser la stratégie
        de groupement moyenne et de fixer le seuil $\zeta$ à 0,25.

        La figure~\ref{fig:variation_de_la_selection_des_candidats} présente les
        résultats obtenus avec TopicRank et les différentes stratégies de
        sélection d'un terme-clé candidat par sujet. Les résultats confirment
        notre hypothèse qui est que le choix des candidats apparaissant en
        premier dans le document fournit de meilleurs termes-clés que le choix
        des candidats centroïdes ou des candidats les plus fréquents. La
        stratégie centroïde donne de très faibles résultats et la
        stratégie fréquence n'est pas stable comparée à la stratégie position.
        Enfin, bien que la stratégie position donne les résultats les plus
        satisfaisants, nous remarquons qu'il existe encore une marge de
        progression importante. Les valeurs indiquées par la borne haute
        représentent les résultats qui pourraient être obtenus avec un oracle.
        Pour chacun des sujets les plus importants, l'oracle sélectionne
        toujours un candidat positif, s'il y en a un. La marge de progression de
        14,8 points de f-mesure pour SemEval et de 5,4 points de f-mesure pour
        \textsc{Deft} est encourageante pour des travaux futurs.
        \begin{figure}
          \centering
          \begin{tikzpicture}
            \pgfkeys{/pgf/number format/.cd, use comma, fixed}
            \begin{axis}[symbolic x coords={Linguistique, SciencesDeLInfo, Archeologie, Chimie, DEFT, SemEval},
                         xtick=data,
                         xticklabels={Linguistique, Sciences de l'info., Archéologie, Chimie, \textsc{De}ft, SemEval},
                         %enlarge x limits=0.5,
                         x=.15\linewidth,
                         xticklabel style={anchor=east, xshift=.5em, yshift=-.25em, rotate=22.5},
                         nodes near coords,
                         nodes near coords align={vertical},
                         every node near coord/.append style={font=\tiny},
                         y=0.004\textheight,
                         ytick={0, 10, ..., 50},
                         ymin=0,
                         ymax=52.5,
                         ybar=3pt,
                         ylabel=F,
                         ylabel style={yshift=-1.1em, rotate=270}]
              % centroïde
              \addplot[green!66,
                       pattern=north east lines,
                       pattern color=green!40] coordinates{
                (Linguistique, 11.9)
                (SciencesDeLInfo, 11.5)
                (Archeologie, 18.9)
                (Chimie, 10.7)
                (DEFT, 0.0)
                (SemEval, 0.0)
              };
              % fréquence
              \addplot[cyan!66,
                       pattern=north west lines,
                       pattern color=cyan!40] coordinates{
                (Linguistique, 14.1)
                (SciencesDeLInfo, 13.0)
                (Archeologie, 22.5)
                (Chimie, 11.2)
                (DEFT, 0.0)
                (SemEval, 0.0)
              };
              % position
              \addplot[black!66,
                       pattern=horizontal lines,
                       pattern color=black!40] coordinates{
                (Linguistique, 13.8)
                (SciencesDeLInfo, 12.6)
                (Archeologie, 20.1)
                (Chimie, 10.9)
                (DEFT, 15.2)
                (SemEval, 11.1)
              };
              % borne haute
              \addplot[red!66,fill=red!40] coordinates{
                (Linguistique, 0.0)
                (SciencesDeLInfo, 0.0)
                (Archeologie, 0.0)
                (Chimie, 0.0)
                (DEFT, 0.0)
                (SemEval, 0.0)
              };

              \legend{Centroïde, Fréquence, Position, Borne haute}
            \end{axis}
          \end{tikzpicture}
          \caption{Résultats de l'extraction de dix termes-clés, avec TopicRank,
                   en fonction des différentes stratégies de sélections d'un
                   terme-clé candidats par sujet
                   \label{fig:variation_de_la_selection_des_candidats}}
        \end{figure}

      \subsubsection{Paramétrage empirique de SingleRank}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-empirical_setting_of_singlerank}
        Contrairement aux autres méthodes de référence, SingleRank possède un
        paramètre qui est définit arbitrairement~: la fenêtre de cooccurrences
        fixée à dix par \newcite{wan2008expandrank}. De même que pour TopicRank,
        nous utilisons les ensembles d'entrainement de SemEval et de
        \textsc{Deft} pour déterminer qu'elle est la valeur optimale de la
        fenêtre de cooccurrences pour SingleRank\footnote{Nous ne répétons pas
        cette expérience pour TextRank, car le critère d'adjacence (fenêtre de
        valeur 2) est un critère fort dans la méthode TextRank.}. 

        La figure~\ref{fig:variation_de_la_fenetre} présente les résultats de
        SingleRank lorsque nous faisons varier la fenêtre de cooccurrences de
        deux à vingt mots, avec un pas de un. Globalement, nous observons une
        stabilité des performances de SingleRank quelle que soit la valeur
        utilisée pour la fenêtre de cooccurrences, avec des résultats optimaux
        obtenus lorsque celle-ci vaut 12. Dans les expériences suivantes, nous
        fixons donc la valeur de la fenêtre de cooccurrences à 12.
        \begin{figure}
          \centering
          \begin{tikzpicture}
            \begin{axis}[x=0.025\linewidth,
                         xtick={0, 2, ..., 22},
                         xmin=0,
                         xmax=22,
                         xlabel=Fenêtre,
                         x label style={yshift=.34em},
                         y=0.018\textheight,
                         ytick={0, 2, ..., 100},
                         ymin=2,
                         ymax=20,
                         ylabel=F,
                         y label style={yshift=-1.1em, rotate=270}]
              % linguistique
              \addplot[green!66, mark=x] coordinates{
                (2, 6.6)
                (3, 7.2)
                (4, 8.4)
                (5, 9.0)
                (6, 9.6)
                (7, 9.7)
                (8, 10.0)
                (9, 9.8)
                (10, 9.6)
                (11, 9.7)
                (12, 9.6)
                (13, 9.7)
                (14, 9.9)
                (15, 9.9)
                (16, 9.9)
                (17, 9.7)
                (18, 9.7)
                (19, 9.7)
                (20, 9.8)
              };
              % sciences de l'information
              \addplot[red!66, mark=+] coordinates{
                (2, 9.1)
                (3, 10.1)
                (4, 11.1)
                (5, 11.5)
                (6, 11.9)
                (7, 11.8)
                (8, 12.0)
                (9, 12.1)
                (10, 12.0)
                (11, 11.8)
                (12, 12.0)
                (13, 11.9)
                (14, 11.9)
                (15, 11.8)
                (16, 12.0)
                (17, 11.9)
                (18, 11.9)
                (19, 11.8)
                (20, 11.8)
              };
              % archeologie
              \addplot[cyan!66, mark=o] coordinates{
                (2, 5.3)
                (3, 7.1)
                (4, 8.4)
                (5, 8.9)
                (6, 9.2)
                (7, 9.6)
                (8, 9.9)
                (9, 10.0)
                (10, 9.9)
                (11, 10.2)
                (12, 10.2)
                (13, 10.2)
                (14, 10.0)
                (15, 10.1)
                (16, 10.1)
                (17, 10.1)
                (18, 10.3)
                (19, 10.2)
                (20, 10.4)
              };
              % chimie
              \addplot[orange!66, mark=square] coordinates{
                (2,  8.7)
                (3,  9.0)
                (4,  9.6)
                (5,  9.9)
                (6,  9.8)
                (7,  9.8)
                (8,  9.9)
                (9,  10.0)
                (10, 10.0)
                (11, 10.1)
                (12, 10.1)
                (13, 10.1)
                (14, 10.0)
                (15, 10.0)
                (16, 10.0)
                (17, 10.0)
                (18, 9.9)
                (19, 9.8)
                (20, 9.8)
              };
              % deft
              \addplot[black!66, mark=triangle] coordinates{
                (2, 3.5)
                (3, 6.1)
                (4, 6.3)
                (5, 6.4)
                (6, 6.8)
                (7, 6.7)
                (8, 6.9)
                (9, 6.9)
                (10, 7.1)
                (11, 7.2)
                (12, 7.1)
                (13, 7.0)
                (14, 7.0)
                (15, 7.0)
                (16, 7.0)
                (17, 7.3)
                (18, 7.3)
                (19, 7.3)
                (20, 7.1)
              };
              % semeval
              \addplot[gray!66, mark=diamond] coordinates{
                (2, 5.0)
                (3, 5.2)
                (4, 4.8)
                (5, 5.1)
                (6, 5.0)
                (7, 4.9)
                (8, 4.9)
                (9, 4.9)
                (10, 5.1)
                (11, 5.1)
                (12, 5.2)
                (13, 5.2)
                (14, 5.2)
                (15, 5.2)
                (16, 5.2)
                (17, 5.2)
                (18, 5.1)
                (19, 5.2)
                (20, 5.2)
              };
              %\draw[densely dashed] ({axis cs:12,0}|-{rel axis cs:0,1}) -- ({axis cs:12,0}|-{rel axis cs:0,0}) [color=black!66];
              %\node at (axis cs:12,17.5) [color=black!66, anchor=west] {\tiny{12}};
              \legend{Linguistique, Sciences de l'info., Archéologie, Chimie, \textsc{De}ft, SemEval}
            \end{axis}
          \end{tikzpicture}
          \caption{Résultats de l'extraction de dix termes-clés, avec
                   SingleRank, en fonction de la fenêtre de cooccurrences
                   \label{fig:variation_de_la_fenetre}}
        \end{figure}

      \subsubsection{Comparaison de TopicRank avec l'existant}
      \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-evaluation-comparison}
        % Que représente le tableau ?
        Le tableau~\ref{tab:resultats_globaux} montre les performances de
        TopicRank comparées à celles des trois méthodes de référence. De manière
        générale, les performances des méthodes d'extraction de termes-clés sont
        basses. De plus, il est avéré que les documents de grande taille, tels
        que ceux de SemEval et de \textsc{Deft}, sont plus difficiles à traiter que les
        autres documents. \newcite{hasan2014state_of_the_art} explique qu'un
        grand nombre de termes-clés candidats sont sélectionnés dans ces
        documents (ils sont en moyenne 647 pour SemEval et 915 pour
        \textsc{Deft}), ce qui augmente la difficulté de l'extraction de
        termes-clés.

        % Que peut-on dire globalement ?
        Globalement, TopicRank donne de meilleurs résultats que les méthodes de
        référence utilisées.
        % Que peut-on dire de plus ? (analyse plus approfondie)
        Comparée à la méthode TF-IDF, TopicRank donne de meilleurs résultats pour
        SemEval, Wikinews et \textsc{Deft}. Cette supériorité vis-à-vis de TF-IDF est
        importante à noter, car cette méthode obtient de bons résultats en
        tirant parti de statistiques extraites de documents supplémentaires,
        alors que TopicRank n'utilise que le document à analyser. Comparé aux
        autres méthodes à base de graphe, TopicRank donne des résultats
        significativement meilleurs pour SemEval, Wikinews et \textsc{Deft}. Ceci
        confirme donc que le groupement des candidats permet de rassembler des
        informations pour améliorer la précision de l'ordonnancement. En ce qui
        concerne \textsc{Duc}, notre méthode est aussi significativement meilleure que
        TextRank, mais elle ne l'est pas vis-à-vis de SingleRank. D'après la
        borne haute, l'une des raisons à la plus faible performance de TopicRank
        pour \textsc{Duc} est que la stratégie de sélection des candidats les plus
        représentatifs des sujets est moins adaptée. En effet, la différence
        avec la borne haute est de 12,9 points de f-mesure. Une analyse plus
        approfondie des différents apports de TopicRank peut aussi aider à
        comprendre les raisons de ses moins bons résultats.
        \begin{table}
          \centering
          \begin{tabular}{l|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}}
            \toprule
            \multirow{2}{*}[-2pt]{\textbf{Méthode}} & \multicolumn{3}{c|}{\textbf{\textsc{Duc}}} & \multicolumn{3}{c|}{\textbf{SemEval}} & \multicolumn{3}{c|}{\textbf{Wikinews}} & \multicolumn{3}{c}{\textbf{\textsc{Deft}}}\\
            \cline{2-4}\cline{5-7}\cline{8-10}\cline{11-13}
            & P & R & F & P & R & F & P & R & F & P & R & F\\
            \hline
            TF-IDF & \textbf{23,8} & \textbf{30,7} & \textbf{26,4}$^{~}$ & 13,2 & $~~$8,9 & 10,5$^{~}$ & 33,9 & 35,9 & 34,3$^{~}$ & 10,3 & 19,1 & 13,2$^{~}$\\
            TextRank & $~~$4,9 & $~~$5,4 & $~~$5,0$^{~}$ & $~~$7,9 & $~~$4,5 & $~~$5,6$^{~}$ & $~~$9,3 & $~~$8,3 & $~~$8,6$^{~}$ & $~~$4,9 & $~~$7,1 & $~~$5,7$^{~}$\\
            SingleRank & 22,6 & 28,8 & 25,0$^{~}$ & $~~$4,8 & $~~$3,3 & $~~$3,9$^{~}$ & 19,2 & 20,4 & 19,5$^{~}$ & $~~$4,7 & $~~$9,4 & $~~$6,2$^{~}$\\
            TopicRank & 18,2 & 23,2 & 20,1 & \textbf{15,1}$^{~}$ & \textbf{10,6} & \textbf{12,3}$^\dagger$ & \textbf{34,8} & \textbf{37,3} & \textbf{35,4}$^\dagger$ & \textbf{11,3} & \textbf{21,0} & \textbf{14,5}$^\dagger$\\
            \hline
            \textbf{Borne haute} & \textbf{31,6} & \textbf{35,3} & \textbf{33,0}$^{~}$ & \textbf{33,8} & \textbf{23,3} & \textbf{27,3}$^{~}$ & \textbf{41,7} & \textbf{44,1} & \textbf{42,2}$^{~}$ & \textbf{14,5} & \textbf{27,0} & \textbf{18,7}$^{~}$\\
            \bottomrule
          \end{tabular}
          \caption[Résultats de l'extraction de dix termes-clés avec TF-IDF,
                   TextRank, SingleRank et TopicRank]{
            Résultats de l'extraction de dix termes-clés avec TF-IDF, TextRank,
            SingleRank et TopicRank. $\dagger$ indique une amélioration
            significative de TopicRank vis-à-vis de TextRank et SingleRank, à
            0,001 pour le t-test de Student.
            \label{tab:resultats_globaux}
          }
        \end{table}

        \begin{table}
          \centering
          \begin{tabular}{l|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}|c@{~~}c@{~~}c@{~}}
            \toprule
            \multirow{2}{*}[-2pt]{\textbf{Méthode}} & \multicolumn{3}{c|}{\textbf{\textsc{Duc}}} & \multicolumn{3}{c|}{\textbf{SemEval}} & \multicolumn{3}{c|}{\textbf{Wikinews}} & \multicolumn{3}{c}{\textbf{\textsc{Deft}}}\\
            \cline{2-4}\cline{5-7}\cline{8-10}\cline{11-13}
            & P & R & F & P & R & F & P & R & F & P & R & F\\
            \hline
            SingleRank & \textbf{22,6} & \textbf{28,8} & \textbf{25,0}$^{~}$ & $~~$4,8 & $~~$3,3 & $~~$3,9$^{~}$ & 19,2 & 20,4 & 19,5$^{~}$ & $~~$4,7 & $~~$9,4 & $~~$6,2$^{~}$\\
            + complet & 22,2 & 28,1 & 24,5$^{~}$ & $~~$5,5 & $~~$3,8 & $~~$4,4$^{~}$ & 20,0 & 21,4 & 20,3${~}$ & $~~$4,4 & $~~$9,0 & $~~$5,8$^{~}$\\
            + candidats & 10,4 & 13,5 & 11,6$^{~}$ & $~~$9,4 & $~~$6,8 & $~~$7,8$^\dagger$ & 28,5 & 30,0 & 28,8$^\dagger$ & 10,3 & 19,2 & 13,2$^\dagger$\\
            + sujets & 18,9 & 24,2 & 21,0$^{~}$ & 14,2 & $~~$9,9 & 11,6$^\dagger$ & 30,7 & 32,6 & 31,1$^\dagger$ & 11,1 & 20,4 & 14,2$^\dagger$\\
            TopicRank & 18,2 & 23,2 & 20,1$^{~}$ & \textbf{15,1} & \textbf{10,6} & \textbf{12,3}$^\dagger$ & \textbf{34,8} & \textbf{37,3} & \textbf{35,4}$^\dagger$ & \textbf{11,3} & \textbf{21,0} & \textbf{14,5}$^\dagger$\\
            \bottomrule
          \end{tabular}
          \caption[Résultats de l'extraction de dix termes-clés avec chacune des
                   contributions de TopicRank, appliquées séparément à
                   SingleRank]{
            Résultats de l'extraction de dix termes-clés avec chacune des
            contributions de TopicRank, appliquées séparément à SingleRank.
            $\dagger$ indique une amélioration significative vis-à-vis de
            SingleRank, à 0,001 pour le t-test de Student.
            \label{tab:evaluation_individuelle_des_ameliorations}
          }
        \end{table}

        Dans le but de confirmer la pertinence de tous les apports de TopicRank,
        nous réalisons une expérience supplémentaire dans laquelle nous
        appliquons individuellement à SingleRank toutes les modifications
        successives permettant d'obtenir la méthode TopicRank depuis la méthode
        SingleRank~: l'usage d'un graphe complet (+ complet), la projection des
        termes-clés candidats dans le graphe (+ candidats) et la projection des
        sujets dans le graphe (+ sujets). Les résultats de ces trois variantes
        de SingleRank sont présentés dans le
        tableau~\ref{tab:evaluation_individuelle_des_ameliorations}.
        Globalement, l'usage des termes-clés candidats, ou sujets, induit une
        amélioration significative des performances de SingleRank, avec une
        amélioration plus importante en utilisant les sujets. Cela confirme la
        pertinence d'ordonner directement les candidats, plutôt que les mots,
        ainsi que la pertinence de grouper les candidats représentant le même
        sujet pour mutualiser les relations qu'ils entretiennent avec les
        candidats représentant d'autres sujets. L'usage d'un graphe complet,
        quant à lui, n'améliore pas significativement les résultats de
        SingleRank. Ceux-ci sont compétitifs vis-à-vis de ceux obtenus en
        construisant un graphe de cooccurrences. Toutefois, nous pensons que
        l'usage du graphe complet est à privilégier afin d'éviter d'avoir à
        fixer le paramètre de la fenêtre de cooccurrences.
        
        En ce qui concerne la collection \textsc{Duc}, le
        tableau~\ref{tab:evaluation_individuelle_des_ameliorations} montre une
        perte de performance induite par la construction du graphe avec les
        termes-clés candidats. Cette perte de performance s'explique par le fait
        qu'il y a, dans les documents de \textsc{Duc}, peu de répétition des
        candidats, notamment ceux de plus d'un mot. Le graphe créé contient
        alors moins de relations de cooccurrences que lorsque les n\oe{}uds sont
        les mots du document et est donc moins précis pour l'ordonnancement.

      \subsection{Analyse d'erreurs}
      \label{subsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-error_analysis}
        Dans cette section, nous proposons d'analyser les erreurs de TopicRank.
        Dans un premier temps, nous analysons les sujets que détecte TopicRank,
        puis dans un second temps, nous analysons les termes-clés de référence
        qui ne sont pas extraits par Topic\-Rank.

        \subsubsection{Analyse des sujets détectés}
        \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-error_analysis-detected_topics}
          Dans cette section, nous analysons les groupements en sujets effectués
          par Topic\-Rank afin de déterminer quelles sont les principales causes
          d'erreurs.

          \TODO{peut-être revoir les exemples qui suivent}

          Nous observons des erreurs liées à la sélection des termes-clés
          candidats. Lors de cette étape, certaines unités textuelles sont
          sélectionnées comme candidats à cause d'erreurs commises lors de
          l'étiquetage grammatical. Ces erreurs concernent principalement la
          détection des participes. Par exemple, dans la phrase \og{}[\dots]
          elles ne cessent de se développer à travers le monde et
          particulièrement dans les pays dits ``du
          sud''~[\dots]\fg{}\footnote{Exemple issu de l'article d'anthropologie
          \textit{Le marché parallèle du médicament en milieu rural au Sénégal}
          (\url{http://id.erudit.org/iderudit/014935ar}) de la collection
          \textsc{Deft}.}, \og{}dits\fg{} est un adjectif selon l'outils MElt, ce qui
          entraîne la sélection erronée du terme-clé candidat \og{}pays
          dits\fg{}.

          Nous observons également de nombreuses erreurs lorsque les groupements
          sont déclenchés par un adjectif. Ce sont particulièrement les
          expansions nominales s'effectuant à gauche qui en sont la cause (par
          exemple \og{}même langue\fg{} groupé avec \og{}même
          représentation\fg{}). Parmi les expansions nominales s'effectuant à
          droite, les adjectifs relationnels sont moins sujets aux erreurs que
          les autres adjectifs. Notons tout de même que lorsque ces adjectifs
          sont liés au contexte général du document, ils sont très fréquemment
          utilisés et beaucoup de candidats les contenant sont groupés par
          erreur (par exemple \og{}forces économiques\fg{} peut être groupé
          avec \og{}délabrement économique\fg{} dans un document d'économie).
          Outres ces groupements erronés, nous observons aussi de mauvais
          groupements lorsque les candidats ne contiennent que très peu de mots.
          Pour les candidats de deux mots, il ne suffit que d'un seul mot en
          commun pour les grouper. Ces candidats étant très fréquents, ils sont
          la cause de nombreuses erreurs.

        \subsubsection{Analyse des faux négatifs}
        \label{subsubsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-error_analysis-false_negatives}
          Dans cette section, nous analysons les termes-clés de référence qui
          n'ont pas été extraits par TopicRank. Plus particulièrement, nous nous
          intéressons à ceux qui sont présents dans les dix sujets jugés les
          plus importants de chaque document, mais qui n'ont pas été
          sélectionnés pour les représenter. Nous observons deux sources
          d'erreurs.

          La première source d'erreurs est le groupement en sujets. Lorsqu'un
          sujet détecté contient en réalité des termes-clés candidats
          représentant des sujets différents, la stratégie de sélection du
          meilleur terme-clé dans le sujet parvient à sélectionner le terme-clé
          correct dans certains cas, mais elle échoue parfois.

          \TODO{peut-être revoir les exemples qui suivent}

          La seconde source d'erreurs est la spécialisation des termes-clés de
          référence. Nous observons deux problèmes de sous et sur-spécialisation
          de certains termes-clés extraits vis-à-vis des termes-clés de
          référence. Dans le cas de la sous-spécialisation, nous pouvons citer,
          par exemple, \og{}papillons\fg{} qui est extrait à la place de
          \og{}papillons mutants\fg{}\footnote{Exemple issue de l'article
          journalistique \textit{Fukushima fait muter les papillons}
          (\url{http://fr.wikinews.org/w/index.php?oldid=432477}) de la
          collection Wikinews.}. Bien que ce problème de sous-spécialisation
          soit identifié, l'existance du problème inverse le rend plus difficile
          à résoudre. Dans le cas de la sur-spécialisation, nous pouvons citer,
          par exemple, \og{}député Antoni Pastor\fg{} qui est extrait à la place
          de \og{}Antoni Pastor\fg{}\footnote{Exemple issu de l'article
          journalistique \textit{Îles Baléares : le Parti populaire exclut le
          député Antoni Pastor pour avoir défendu la langue catalane}
          (\url{http://fr.wikinews.org/w/index.php?oldid=479948}) de la
          collection Wikinews.}. La raison principale de ce problème est
          l'aspect libre et ambigu de l'annotation manuelle des termes-clés.
%          Toutefois, privilégier les modifications adjectivales (par exemple
%          \og{}mutants\fg{}) et, au contraire, éviter les modifications
%          nominales (par exemple \og{}député\fg{}) semblent être une hypothèse à
%          vérifier.

      \subsection{Bilan}
      \label{subsec:main:domain_independent_keyphrase_extraction-unsupervised_automatic_keyphrase_extraction-bilan}
        Avec TopicRank, nous proposons une méthode à base de graphe pour
        l'extraction non supervisée de termes-clés. Elle groupe les termes-clés
        candidats en sujets, détermine quels sont ceux les plus importants, puis
        extrait le terme-clé candidat qui représente le mieux chacun des sujets
        les plus importants. Cette nouvelle méthode offre plusieurs avantages
        vis-à-vis des précédentes méthodes à base de graphe. Le groupement des
        termes-clés potentiels en sujets distincts permet de rassembler des
        informations relatives au même sujets et le choix d'un seul terme-clé
        pour représenter un sujet important permet d'extraire un ensemble de
        termes-clés non redondants (pour $k$ termes-clés extraits, exactement
        $k$ sujets sont couverts). Enfin, le graphe est complet et ne requiert
        plus le paramétrage d'une fenêtre de cooccurrences.

        Les bons résultats de notre méthode montrent la pertinence d'un
        groupement des candidats en sujets et d'un ordonnancement de ces sujets,
        plutôt que des mots. Les expériences montrent aussi qu'il est encore
        possible d'améliorer notre méthode en proposant une nouvelle stratégie
        de sélection du terme-clé candidat le plus représentatif d'un sujet.
        Dans un premier temps, nous souhaitons explorer plus encore l'usage du
        graphe et l'étendre à l'assignement de termes-clés.

  %-----------------------------------------------------------------------------

  \section{Conclusion}
  \label{sec:main-domain_independent_keyphrase_extraction-conclusion}
    \TODO{\dots}


