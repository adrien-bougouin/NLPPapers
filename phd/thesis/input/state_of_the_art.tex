\chapter[Indexation automatique par termes-clés]{Indexation automatique\\par termes-clés}
\label{part:main-state_of_the_art}
  \section{Introduction}
  \label{sec:main-state_of_the_art-introduction}
    Les termes-clés\index{Terme-cle@Terme-clé \textit{(keyphrase)}|textbf},
    souvent appelés mots-clés\index{Mot-cle@Mot-clé
    \textit{(keyword)}|textbf}\footnote{Lorsque nous utilisons le terme
    \og{}mot-clé\fg{}, il s'agit d'un terme-clé composé d'un et un seul mot.},
    sont les unités textuelles (mots ou expressions) qui caractérisent le mieux
    le contenu principal d'un document~: les sujets qu'il aborde, ses idées,
    etc. Ceux-ci donnent une description précise de ce que contient un document
    et peuvent servir à la Recherche d'Information (\textsc{Ri}). Nous parlons
    donc d'indexation par termes-clés\index{Indexation par
    termes-cles@Indexation par termes-clés \textit{(automatic keyphrase
    annotation)}|textbf}. Cette indexation ne doit toutefois pas être confondue
    avec l'indexation dite \og{}plein texte\fg{} au c\oe{}ur de nombreux
    systèmes de \textsc{Ri}. L'indexation plein texte pondère tous les mots d'un
    document selon leur importance relative à celui-ci, tandis que l'indexation
    par termes-clés fournit un ensemble restreint de mots ou expressions qui
    représentent ses sujets importants, explicites ou non.

    Dans la littérature, nous distinguons deux catégories d'indexations
    automatiques par termes-clés~: l'une libre, l'autre contrôlée. L'indexation
    libre\index{Indexation libre@Indexation libre \textit{(free indexing)}|see
    {Extraction automatique de termes-clés \textit{(automatic keyphrase
    extraction)}}} consiste à extraire du document les unités textuelles jugées
    les plus importantes dans son contexte. Nous parlons d'extraction
    automatique de termes-clés\index{Extraction automatique de
    termes-cles@Extraction automatique de termes-clés \textit{(automatic
    keyphrase extraction)}|textbf}. L'indexation contrôlée\index{Indexation
    controlee@Indexation contrôlée \textit{(controlled indexing)}|see
    {Assignation automatique de termes-clés \textit{(automatic keyphrase
    assignment)}}} fournit les termes-clés en se fondant sur un vocabulaire
    contrôlé et sans se restreindre aux unités textuelles présentes dans le
    document. Nous parlons d'assignation automatique de
    termes-clés\index{Assignation automatique de termes-cles@Assignation
    automatique de termes-clés \textit{(automatic keyphrase
    assignment)}|textbf}.

    Dans la suite, nous présentons les tâches d'extraction automatique de
    termes-clés et d'assignation automatique de termes-clés. Nous commençons par
    introduire une étape préliminaire à la plupart des méthodes d'extraction et
    d'assignation automatique de termes-clés~: la sélection des termes-clés
    candidats, qui devient un objet d'étude à part
    entière~\cite{wang2014keyphraseextractionpreprocessing}.

  %-----------------------------------------------------------------------------

  \section{Sélection des termes-clés candidats}
  \label{sec:main-state_of_the_art-keyphrase_candidate_selection}
    % Quel est l'objectif ?
    La sélection des termes-clés candidats\index{Selection des termes-cles
    candidats@Sélection des termes-clés candidats \textit{Keyphrase candidate
    selection}|textbf}\index{Terme-cle candidat@Terme-clé candidat
    \textit{(keyphrase candidate)}|textbf} consiste à déterminer quelles sont
    les unités textuelles qui sont potentiellement des termes-clés, c'est-à-dire
    les unités textuelles qui ont des particularités similaires à celles des
    termes-clés définis par des humains. Nous savons par exemple que les
    termes-clés sont majoritairement constitués de noms et d'adjectifs
    (\TODO{exemple}). Cette étape présente deux avantages. Le premier est la
    réduction du temps de calcul nécessaire à l'extraction des  termes-clés. Le
    second est la suppression d'unités textuelles non pertinentes pouvant
    affecter négativement les performances de l'ordonnancement. Pour distinguer
    les différents candidats sélectionnés, nous définissons deux catégories~:
    les candidats positifs\index{Candidat positif@Candidat positif
    \textit{(positive candidate)}|textbf}, qui correspondent aux termes-clés
    assignés par des humains (termes-clés de référence), et les candidats
    négatifs\index{Candidat negatif@Candidat négatif \textit{(negative
    candidate)}|textbf}. Parmi les candidats négatifs, nous distinguons deux
    sous-catégories~: les candidats porteurs d'indices\index{Candidat porteur
    d'indices@Candidat porteur d'indices \textit{(clue candidate)}|textbf} de
    différentes natures pouvant influencer la promotion de candidats positifs
    (\TODO{exemple}) et les candidats non pertinents\index{Candidat non
    pertinent@Candidat non pertinent \textit{(irrelevant candidate)}|textbf},
    que nous considérons comme des erreurs de sélection.

    Plusieurs méthodes de sélection de candidats sont utilisées, de la simple
    sélection de n-grammes jusqu'à la sélection de \textit{chunks} nominaux, en
    passant par la sélection d'unités textuelles grammaticalement définies.

    ~\\Les n-grammes\index{N-gramme@N-gramme \textit{(n-gram)}|textbf} sont
    toutes les séquences ordonnées de $n$ mots adjacents. La sélection des
    n-grammes est très exhaustive, elle fournit un grand nombre de termes-clés
    candidats, ce qui maximise la quantité de candidats positifs, la quantité de
    candidats porteurs d'indices, mais aussi la quantité de candidats non
    pertinents. Pour réduire cette dernière, il est courant de filtrer les
    n-grammes avec un
    anti-dictionnaire\index{Anti-dictionnaire@Anti-dictionnaire
    \textit{(stopwords)}|textbf}, selon le principe suivant~: un n-gramme
    contenant un mot de l'anti-dictionnaire en début ou en fin n'est pas
    considéré comme un terme-clé candidat. L'anti-dictionnaire regroupe les mots
    fonctionnels de la langue (conjonctions, prépositions,~etc.) et les mots à
    usage courants (\og{}particulier\fg{}, \og{}près\fg{}, \og{}beaucoup\fg{},
    etc.).
    
    Malgré son aspect bruité, la sélection des n-grammes est largement utilisée
    pour l'indexation par termes-clés, notamment par les méthodes
    supervisées~\cite{witten1999kea,turney1999learningalgorithms,hulth2003keywordextraction},
    dont la phase d'apprentissage les rend moins sensibles aux éventuels
    candidats erronés (bruit) que les méthodes non supervisées.

    \begin{example}
      \TODO{$\{1..3\}$-grammes à partir d'une phrase de l'exemple fil rouge}
    \end{example}

    ~\\Les \textit{chunks} nominaux\index{NP-chunk@NP-\textit{chunk}|textbf}
    sont des syntagmes\index{Syntagme@Syntagme
    \textit{(syntagm)}|textbf}\footnote{Syntagme~: Unité syntaxique
    intermédiaire entre le mot et la phrase. Aussi appelé groupe, le syntagme
    constitue une unité de sens dont chaque constituant conserve sa
    signification et sa syntaxe propre.} non récursifs (ou minimaux) dont la
    tête est un nom, accompagné de ses éventuels déterminants et modifieurs
    usuels. Ils sont linguistiquement définis et leur sélection est donc plus
    fiable que celle des n-grammes. \newcite{hulth2003keywordextraction} le
    montre dans ses expériences consacrées à l'apport de connaissances
    linguistiques pour l'extraction automatique de termes-clés. Cependant, ses
    propos sont nuancés par un autre de ses constats~: l'usage de l'étiquetage
    grammatical des n-grammes dans une méthode supervisée d'extraction
    automatique de termes-clés permet d'éliminer les n-grammes grammaticalement
    incorrects et induit de meilleures performances qu'avec les \textit{chunks}
    nominaux.

    \begin{example}
      \TODO{NP-\textit{chunks} à partir d'une phrase de l'exemple fil rouge}
    \end{example}

    ~\\La sélection d'unités textuelles qui forment des séquences
    grammaticalement définies\index{Sequence grammaticalement definie@Séquence
    grammaticalement définie \textit{(POS sequence)}|textbf} permet de contrôler
    avec précision la nature et la grammaticalité des candidats sélectionnés.
    Pour cela, il faut définir des patrons grammaticaux tels que \texttt{(<NOM>
    | <ADJ>)*}, qui représente les plus longues séquences de noms et
    d'adjectifs, d'après la syntaxe des expréssions rationnelles.

    À l'instar des \textit{chunks} nominaux, la sélection des séquences
    grammaticalement définies est plus fondée linguistiquement que celle des
    n-grammes. Dans ses travaux, \newcite{hulth2003keywordextraction}
    sélectionne les candidats à partir des patrons des termes-clés de référence
    les plus fréquents dans son corpus d'apprentissage. D'autres chercheurs,
    tels que \newcite{wan2008expandrank}, se concentrent uniquement sur les plus
    longues séquences de noms (noms propres inclus) et d'adjectifs.

    \begin{example}
      \TODO{Plus longues séquences de noms et d'adjectifs à partir d'une phrase de l'exemple fil rouge}
    \end{example}

    ~\\En plus des trois précédentes méthodes de sélection de termes-clés
    candidats, d'autre chercheurs comme
    \newcite{huang2006semanticnetworkstructureanalysis} proposent un filtrage
    des candidats sélectionnés.
    \newcite{huang2006semanticnetworkstructureanalysis} filtrent tout d'abord
    les candidats peu fréquents dans le document, puis mettent ensuite en
    compétition ceux ayant un mot en commun. Pour chaque groupe de
    candidats mis en compétitions, un seul candidat peut être retenu comme
    terme-clé candidat, celui le plus fréquent. Un candidat peut être en
    compétition dans différents groupes. Dans ce cas, il doit être le
    \og{}vainqueur\fg{} de chaque groupe pour être retenu.

    Le travail de \newcite{huang2006semanticnetworkstructureanalysis}, sur la
    sélection des termes-clés candidats, fait partie d'un système d'extraction
    de termes-clés qu'ils ont développés. Ce dernier à fait l'objet d'une
    évaluation, mais aucune étude n'a été conduite pour montrer l'efficacité de
    leur filtrage hors des frontières de leur système.

    ~\\Contrairement à \newcite{huang2006semanticnetworkstructureanalysis},
    \newcite{you2009refinedcandidateset} se sont fixé pour objectif d'améliorer
    la qualité de l'extraction automatique de termes-clés en réduisant le nombre
    de candidats sélectionnés sans perdre de candidats positifs ni même
    augmenter la complexité algorithmique de la sélection. Leur méthode se
    divise en deux étapes: sélection de candidats préliminaires grâce à une
    liste de mots-clés, puis réduction de cet ensemble de candidats
    préliminaires à un ensemble non redondant de candidats porteurs de sens.

    Dans un premier temps, \newcite{you2009refinedcandidateset} extraient les
    $k$ mots les plus fréquents du document, excluant les mots d'un
    anti-dictionnaire, et les définissent comme mots-clés du document. Ensuite,
    chaque occurrence de chaque mot-clé sert à définir au plus sept candidats
    préliminaires~: le mot-clé lui même, un bi-gramme commençant par le mot-clé,
    un bi-gramme se terminant par le mot-clé, un tri-gramme commençant par le
    mot-clé, un tri-gramme se terminant par le mot-clé, un quadri-gramme
    commençant par le mot-clé et un quadri-gramme se terminant par le
    mot-clé\footnote{La taille maximale de 4 pour les n-grammes a été fixée par
    les auteurs après une analyse statistique de leurs données. Cette taille peut
    diverger selon les données, auquel cas les candidats préliminaires
    sélectionnés pour chaque occurrence d'un mots-clés peut excéder sept.}.

    \begin{example}
      \TODO{Un 1-gramme, deux 2-grammes, deux 3-grammes et deux 4-grammes à partir d'une phrase de l'exemple fil rouge}
    \end{example}

    Dans un second temps, \newcite{you2009refinedcandidateset} analysent chaque
    7-uplets de $\{1..4\}$-grammes et retirent les candidats préliminaires jugés
    incomplets, non porteurs de sens. À la fin de cette étape, seuls deux
    candidats préliminaires peuvent être retenus pour chaque 7-uplet~: l'un
    commençant par le mot-clé et l'autre se terminant par le mot-clé. Pour cela,
    les auteurs utilisent deux arbres par mot-clé. Un mot-clé est la racine de
    chaque arbre et les fils de chaque noeuds sont leurs mots les précédant ou
    succedant dans les candidats préliminaires. La profondeur de chaque arbre ne
    peut excéder quatre et un mot apparaissant moins de deux fois forme un
    n\oe{}ud feuille. Pour sélectionner les termes-clés candidats, il suffit
    ensuite de parcourir l'arbre en profondeur et de ne retenir que les
    séquences constituées uniquement de n\oe{}uds non feuilles.

    \TODO{Exemple de graphe obtenu à partir de l'exemple précédent (faire
    référence à ce graph dans le paragraph précédent)}

    Comparée à la sélection des $\{1..3\}$-grammes réalisée dans plusieurs
    travaux, la méthode de \newcite{you2009refinedcandidateset} réduit
    significativement le nombre de candidats (environ 75~\%), mais n'induit pas
    une amélioration significative des performances des méthodes d'indexation
    par termes-clés.

    ~\\Pour contribuer à la sélection des termes-clés candidats,
    \newcite{newman2012bayesiantextsegmentation} se sont intéressés aux travaux
    effectués dans le domaine de la segmentation en mots et à l'adaptation de
    l'un d'eux~\cite{goldwater2009bayesianwordsegmentation} pour la détection
    des frontières séparant les mots et les expressions dans la phrase. Leur
    méthode parcours le document pour apprendre un lexique en suivant un
    processus de Dirichlet. Ce lexique est ensuite considéré comme l'ensemble
    des termes-clés candidats pour le document.

    En utilisant un simple ordonnancement par fréquence pour la tâche
    d'extraction de termes-clés, ce qui n'est pas une heuristique suffisante
    pour déterminer l'importance d'un terme-clé candidat, leur approche obtient
    de meilleurs résultats que la majorité des systèmes états de l'art. Ceci
    tant à montrer la capacité de leur méthode à fournir des candidats de très
    bonne qualité.

  %-----------------------------------------------------------------------------

  \section{Extraction automatique de termes-clés}
  \label{sec:main-state_of_the_art-automatic_keyphrase_extraction}
    L'extraction automatique de termes-clés est la tâche la plus utilisée pour
    faire de l'indexation par termes-clés. Les méthodes d'extraction automatique
    de termes-clés effectuent principalement un ordonnancement ou une
    classification des termes-clés candidats, puis choissisent les $k$
    meilleurs. L'ordonnancement est principalement réalisé avec une approche non
    supervisée, tandis que l'apprentissage est réalisé avec une approche
    supervisée. Contrairement à l'approche non supervisée, l'approche supervisée
    requiert des données d'entraînement afin d'apprendre à partir des
    caractéristiques des termes-clés de références qui y sont manuellement
    annotés.

    \subsection{Approche non supervisée}
    \label{subsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction}
      Les méthodes non supervisées d'extraction de termes-clés ordonnent
      principalement les termes-clés candidats par importance. Du fait qu'elles
      ne requièrent pas de données d'entraînement, elles ont la particularité de
      s'abstraire du domaine et de la langue des documents qu'elles traitent.
      Les termes-clés candidats sont analysés avec des règles simples fondées
      sur des traits statistiques extraits du document ou d'un corpus de
      référence non annoté.

      De nombreuses méthodes ont été proposées. Certaines se fondent uniquement
      sur des statistiques et d'autres les combinent avec des représentations
      plus complexes du document, principalement des groupes sémantiques et des
      graphes de cooccurrences de mots. Dans la suite, nous présentons ces
      défférentes méthodes, des plus simples aux plus sofistiquées. Notez qu'il
      existe aussi une étude comparative des performances de certaines d'entre
      elles~\cite{hassan2010conundrums}.

      \subsubsection{Méthodes statistiques}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches}
        Les méthodes statistiques se fondent majoritairement sur le nombre de
        cooccurrences des termes-clés candidats (souvent assimilé à leur
        fréquence) ou aux mots qui le composent, soit dans le document, soit
        dans un corpus de référence, ou bien les deux.

        ~\\TF-IDF de \newcite{jones1972tfidf} et
        Likey de \newcite{paukkeri2010likey}
        sont deux méthodes similaires qui comparent le comportement d'une unité
        textuelle dans le document avec son comportement dans un corpus de
        référence. L'objectif est de trouver celles dont le
        comportement dans le document varie positivement comparé à leur
        comportement global dans le corpus. Dans TF-IDF et Likey ceci
        s'exprime par le fait qu'une unité textuelle a une forte importance
        vis-à-vis du document si elle y est très fréquente et si elle l'est
        peu dans le corpus de référence.
        \begin{align}
          \text{TF-IDF}(\text{\textit{ut}}) &= TF(\text{\textit{ut}}) \times \log\left(\frac{N}{DF(\text{\textit{ut}})}\right) \label{math:tfidf}\\
          \notag\\
          \text{Likey}(\text{\textit{ut}}) &= \frac{\text{rang}_{\text{document}}(\text{\textit{ut}})}{\text{rang}_{\text{corpus}}(\text{\textit{ut}})} \label{math:likey}
        \end{align}\\
        Dans TF-IDF, $TF$ (\textit{Term Frequency}) représente le nombre
        d'occurrences d'une unité textuelle \textit{ut} dans le document et $DF$
        (\textit{Document Frequency}) représente le nombre de documents du
        corpus de référence dans lequel elle apparaît, $N$ étant son nombre
        total de documents. Plus le score TF-IDF d'une unité textuelle est
        élevé, plus celle-ci est importante dans le document. Dans Likey, le
        rang d'une unité textuelle dans le document et dans le corpus est obtenu
        à partir de son nombre d'occurrences, respectivement dans le document et
        dans le corpus. Plus le rapport entre ces deux rangs est faible, plus
        l'unité textuelle évaluée est importante dans le document.

        La granularité de l'unité textuelle peut être définie au mot ou au
        terme-clé candidat. Si la granularité choisie est le mot, il est
        courant de déterminer le score d'importance des termes-clés candidat en
        faisant la somme du score (TF-IDF ou Likey) des mots qui les composent.

        ~\\Okapi (ou BM25) \cite{robertson1999okapi} est une mesure alternative
        à TF-IDF. En Recherche d'Information (RI), celle-ci est plus utilisée
        que le TF-IDF. Bien que l'extraction automatique de termes-clés soit
        une discipline à la frontière entre le TAL et la RI, la méthode de
        pondération Okapi n'a, à notre connaissance, pas été appliquée pour
        l'extraction de termes-clés. Dans l'article de
        \newcite{claveau2012vectorisation}, Okapi est décrit comme un TF-IDF
        prenant mieux en compte la longueur des documents. Cette dernière est
        utilisée pour normaliser le $TF$ ($TF_{BM25}$)~:
        \begin{align}
          \text{Okapi}(\text{\textit{ut}}) &= TF_{BM25}(\text{\textit{ut}}) \times \log\left(\frac{N - DF(\text{\textit{ut}}) + 0,5}{DF(\text{\textit{ut}}) + 0,5}\right) \label{math:okapi}\\
          \notag\\
          TF_{BM25}(\text{\textit{ut}}) &= \frac{TF(\text{\textit{ut}}) \times (k_1 + 1)}{TF(\text{\textit{ut}}) + k_1 \times \left(1 - b + b \times \frac{DL}{DL_{\text{moyenne}}}\right)} \label{math:tf_bm25}
        \end{align}\\
        où $k_1$ est une constante fixée à 2, $b$ est une constante fixée à
        $0,75$, $DL$ représente la longueur du document et où $DL_{moyenne}$
        représente la longueur moyenne des documents du corpus de référence.

        ~\\Le travail de \newcite{barker2000nounphrasehead} est un autre exemple
        d'utilisation de la fréquence pour extraire les termes-clés. Se reposant
        sur des fondements plus linguistiques, ils utilisent des groupes
        nominaux comme candidats et utilisent à la fois leur fréquence et celle
        de leur tête nominale pour déterminer leur importance. Ils définissent
        un candidat important comme étant un candidat informatif et fréquent.
        L'informativité est ici assimilée à sa taille, en nombre de mots~: plus
        il contient de mots, plus il est informatif. Cependant, pour éviter les
        répétitions, jugées inesthétiques, de tels candidats informatifs sont
        parfois abrégés et leur fréquence réel ne reflète donc pas leur usage.
        \newcite{barker2000nounphrasehead} proposent alors d'utiliser la
        fréquence de la tête du candidat pour décider s'il doit être extrait ou
        non. Leur méthode fonctionne en quatre étapes. Ils extraient tout
        d'abbord les noms les plus fréquents, ils gardent uniquement les groupes
        nominaux contenant un de ces noms, puis les ordonnent selon le produit
        de leur taille et de leur fréquence réel. Enfin, ils extraient les $k$
        groupes nominaux de meilleur rang.

        ~\\\newcite{tomokiyo2003languagemodel} tentent aussi de vérifier
        statistiquement deux propriétés que doit respecter un terme-clé candidat
        pour être extrait comme terme-clé~:
        \begin{itemize}
          \item{informativité : un terme-clé doit capturer au moins une des
                idées essentielles exprimées dans le document analysé;}
          \item{grammaticalité : un terme-clé doit être bien formé
                syntaxiquement.}
        \end{itemize}
        Pour vérifier ces deux propriétés, trois modèles de langue ($ML$) sont
        utilisés. Les deux premiers modèles, l'un uni-gramme,
        $ML_{\text{document}}^1$, l'un n-gramme, $ML_{\text{document}}^N$, sont
        construits à partir du document. Le dernier, un modèle n-gramme,
        $ML_{\text{référence}}^N$, est construit à partir d'un corpus de
        référence. Ce dernier est le modèle de référence, il fournit une vision globale de la
        distribution des n-grammes dans la langue (français, anglais, etc.).
        De ce fait, plus la probabilité d'un terme-clé candidat selon le
        modèle n-gramme du document diverge par rapport à sa probabilité selon
        le modèle de référence, plus il respecte la propriété d'informativité
        (cf. équation~\ref{math:informativeness} et figure~\ref{fig:klml}), et plus la
        probabilité d'un terme-clé candidat selon le modèle n-gramme du
        document diverge par rapport à sa probabilité selon le modèle
        uni-gramme du document, plus il respecte la propriété de
        grammaticalité (cf. équation~\ref{math:phraseness} et figure~\ref{fig:klml}). La divergence est
        exprimée en terme de coût avec la divergence Kullback-Leibler (cf.
        équation \ref{math:kullbackleibler}). Les termes-clés candidats sont
        ordonnés dans l'ordre décroissant de la somme des scores d'informativité
        et de grammaticalité, puis les $k$ termes-clés candidats de meilleur
        rang sont extraits comme termes-clés.
        \begin{align}
          \text{informativité}(\text{\textit{candidat}}) &= KL_{\text{\textit{candidat}}}(ML_{\text{document}}^{N} || ML_{\text{référence}}^{N}) \label{math:informativeness}\\
          \notag\\
          \text{grammaticalité}(\text{\textit{candidat}}) &= KL_{\text{\textit{candidat}}}(ML_{\text{document}}^{N} || ML_{\text{document}}^{1}) \label{math:phraseness}\\
          \notag\\
          KL_{\text{\textit{candidat}}}(ML || ML') &= ML(\text{\textit{candidat}}) \log \frac{ML(\text{\textit{candidat}})}{ML'(\text{\textit{candidat}})} \label{math:kullbackleibler}\\
          \notag\\
          ML(\text{\textit{candidat}} = m_1\ m_2\ \dots\ m_k) &= \prod_{i = 1}^k P(m_i | m_{i - (N - 1)} m_{i - ((N - 1) - 1)} \dots m_{i - 1}) \notag
        \end{align}
        \begin{figure}
          \centering

          \begin{tikzpicture}
            \node [fill=@verticalgreen] (ml_n_ref) {$ML_{\textnormal{référence}}^{N}$};
            \node [fill=@verticalgreen, right=of ml_n_ref, xshift=1em] (ml_n_doc) {$ML_{\textnormal{document}}^{N}$};
            \node [fill=@verticalgreen, below=of ml_n_doc] (ml_1_doc) {$ML_{\textnormal{document}}^{1}$};

            \path [<->] (ml_n_ref) edge node [above, yshift=.75em] {informativité} (ml_n_doc);
            \path [<->] (ml_n_doc) edge node [right, xshift=.75em] {grammaticalité} (ml_1_doc);
          \end{tikzpicture}

          \caption{Illustration des deux propriétés d'informativité et de
                   grammaticalité pouvant être induites entre trois modèles de
                   langues~\cite{tomokiyo2003languagemodel} \REMARK{utile ???}
                   \label{fig:klml}}
        \end{figure}

        \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches:ilp}
        ~\\Tout comme \newcite{tomokiyo2003languagemodel},
        \newcite{ding2011binaryintegerprogramming} tentent de définir des
        propriétés visant à affiner l'extraction de termes-clés, restreinte aux
        mots-clés. Ils expriment leurs propriétés sous la forme de contraintess
        dans un système d'optimization (programmation par les entiers) qui
        explore l'espace des solutions possibles (toutes les combinaisons de
        mots à extraire). Les contraintes sont les suivantes~:
        \begin{itemize}
          \item{taille: les mots-clés extraits ne doivent pas être en nombre
                supérieur à $k$~;}
          \item{couverture : les mots-clés doivent couvrir le plus possible de
                sujets abordés dans le document~;}
          \item{cohérence : les mots-clés doivent être cohérents entre eux.}
        \end{itemize}
        La couverture de chaque sujet d'une solution est calculée avec le modèle
        \textit{Latent Dirichlet Allocation} (LDA) \cite{blei2003lda} qui donne
        la probabilité d'occurrence d'un mot sachant un sujet. Celle-ci ne doit
        pas être inférieur à un certain seuil pour qu'une solution soit retenue.
        La contrainte de cohérence est calculée entre chaque paire de mots d'une
        solution. Si deux mots cooccurrent plus que selon un seuil donné, alors
        ceux-ci peuvent être présents dans la même solution, sinon la solution
        n'est pas retenue. Ces deux contraintes réduisent le champs des
        possibilités. Il faut ensuite trouver quel ensemble de mots-clés parmi
        les solution retenue est le meilleur. Pour cela, un score d'importance
        des mots est calculé et l'ensemble de mots-clés pour lequel la somme du
        score d'importance des mots est la plus élevée est extrait. Ce score est
        une somme pondérée du score TF-IDF du mot, d'un bonus s'il est présent
        dans le titre du document et d'un autre bonus s'il est présent dans la
        première phrase du document.

      \subsubsection{Méthodes par regroupement}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-clustering_approaches}
        Les méthodes par regroupement utilisent des groupes d'unités textuelles
        partageant une ou plusieurs caractéristiques (similarité lexicale,
        similarité sémantique, etc.).

        ~\\Dans leur méthode, \newcite{matsuo2004wordcooccurrence} groupent les
        candidats les plus fréquents selon leur relation de co-occurrences (nous
        parlons abusivement de relation sémantique), puis comparent les
        termes-clés candidats du document avec les groupes de candidats les plus
        fréquents. Faisant l'hypothèse qu'un terme-clé candidat qui co-occurre
        plus que selon toute probabilité avec les candidats fréquents d'un ou
        plusieurs groupes est plus vraisemblablement un terme-clé, Ils utilisent
        la mesure $\chi^2$ pour calculer le biais entre la fréquence de
        co-occurrence attendue et la fréquence de co-occurrence réelle d'un
        terme-clé candidat avec les candidats de chaque groupe~:
        \begin{align}
          \chi^2(\text{\textit{candidat}}) = \sum_{g} \frac{(\text{fréquence}(\text{\textit{candidat}}, g) - n_tp_g)^2}{n_tp_g}
        \end{align}
        où $n_tp_g$ représente la fréquence de co-occurrence attendue entre le
        terme-clé candidat et le groupe $g$, $n_t$ étant le nombre de candidats
        avec lesquels le terme-clé candidat analysé co-occurre et $p_g$ étant la
        probabilité d'occurrence du groupe $g$ avec d'autres candidats.
        
        Lors de leurs expériences, les auteurs se sont aperçus que certains
        candidats peuvent être sémantiquement liées à des candidats fréquents
        dans un domaine plus général que celui du document. En supposant que ces
        cas spéciaux soient ceux ayant le plus fort biais, ils suppriment du
        $\chi^2$ l'argument maximum de la sommation~:
        \begin{align}
          \chi^2{'}(\text{\textit{candidat}}) = \chi^2 - \max_{g}\left\{\frac{(\text{fréquence}(\text{\textit{candidat}}, g) - n_tp_g)^2}{n_tp_g}\right\}
        \end{align}
        Les termes-clés extraits sont les termes-clés candidats ayant le plus
        fort biais mesuré avec la mesure $\chi^2{'}$.

        ~\\Dans l'algorithme KeyCluster, \newcite{liu2009keycluster} utilisent
        aussi un regroupement sémantique, mais dans leur cas ils ne considèrent
        que les mots du document, mots d'un anti-dictionnaire exclus. le mot le
        plus central de chaque groupe est sélectionné comme mot de référence et
        sert à l'extraction des termes-clé: chaque terme-clé candidat contenant
        au moins un mot de référence est extrait comme terme-clé. Cette méthode
        présente l'avantage d'offrir une bonne couverture des sujets abordés
        dans un document, car tous les groupes sémantiques sont représentés par
        au moins un terme-clé. Cependant, les termes-clés extraits ne sont pas
        pondérés. Il n'est donc pas possible de définir un classement de
        ceux-ci dans le but de n'en extraire qu'un sous ensemble. Il est
        toutefois envisageable de définir un système de pondération basé par
        exemple sur le nombre de mots de références contenus dans le terme-clé
        candidat, en  utilisant le nombre de mots du groupe auquel appartiennent
        les mots de référence du terme-clé candidat, etc.

      \subsubsection{Méthodes à base de graphe}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        Les approches à base de graph sont actuellement les plus populaires.
        Utilisés dans de nombreuses applications du
        \textsc{Tal}~\cite{kozareva2013textgraphs}, les graphes ont l'avantage
        de présenter de manière simple et efficace les unités textuelles d'un
        document et les relations qu'elles entretiennent.

        ~\\\newcite{mihalcea2004textrank} proposent TextRank, une méthode
        d'ordonnancement d'unités textuelles à partir d'un graphe pour le résumé
        automatique et l'extraction de termes-clés. Pour faire de l'extraction
        de termes-clés, les n\oe{}uds du graphe sont les mots du document et
        leurs arêtes représentent leurs relations d'adjacence dans le document,
        c'est-à-dire leurs relations de cooccurrences dans une fenêtre de 2
        mots. Un score d'importance est calculé pour chaque mot à partir de
        l'algorithme PageRank~\cite{brin1998pagerank} qui est issu de la mesure
        de centralité des vecteurs propres. Le principe utilisé est celui de la
        recommandation (du vote)~: un mot est d'autant plus important s'il
        cooccurre avec un grand nombre de mots et si les mots avec lesquels il
        cooccurre sont eux aussi importants. Les mots les plus importants sont
        considérés comme des mots-clés, ces mots-clés sont marqués dans le
        document et les plus longues séquences de mots-clés adjacents sont
        extraites en tant que termes-clés.
      
        Soit $G = (N, A)$, le graph non orienté de cooccurrences de mots où les
        n\oe{}uds $N$ représentent les mots du documents, et où les arc $A$ les
        connectent lorsque les mots cooccurrent dans le document. L'importance
        de chaque mot est obtenue récursivement selon la formule suivant~:
        \begin{align}
          S(n_i \in N) &= (1 - \lambda) + \lambda \times \sum_{n_j \in A(n_i)} \frac{S(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} 1} \label{math:textrank}
        \end{align}
        où $\lambda$ est un facteur d'atténuation. Il peur être considéré
        comme la probabilité pour que le n\oe{}ud $n_i$ soit atteint par
        recommandation.

        ~\\\newcite{wan2008expandrank} modifient TextRank et proposent
        SingleRank. Dans un premier temps, leur méthode augmente la précision de
        l'ordonnancement en utilisant une fenêtre de cooccurrences élargie
        (empiriquement) à dix et en pondérant les arêtes par le nombre de
        cooccurrences entre les deux mots qu'elles connectent (cf.
        equation~\ref{math:singlerank}). Dans un second
        temps, les termes-clés ne sont plus générés à partir des séquences de
        mots-clés dans le document, mais ordonnés à partir de
        la somme du score d'importance des mots qui les composent. Cette
        nouvelle méthode donne, dans la majorité des cas, des résultats
        meilleurs que ceux de TextRank. Cependant, il est important de noter que
        faire la somme du score d'importance des mots pour ordonner les
        candidats favorise les plus longues séquences de mots et de fait monter
        dans le classement des candidats redondants (\TODO{exemple de
        redondance}).
        \begin{align}
          S(n_i \in N) &= (1 - \lambda) + \lambda \times \sum_{n_j \in A(n_i)} \frac{\text{poids}_{ji} \times S(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} \text{poids}_{jk}} \label{math:singlerank}
        \end{align}

        ~\\Toujours dans le but d'améliorer l'efficacité de l'ordonnancement
        proposé par \newcite{mihalcea2004textrank}, \newcite{wan2008expandrank}
        étendent SingleRank en utilisant des documents similaires au document
        analysé. Faisant
        l'hypothèse que ces documents similaires, selon la mesure de similarité
        vectorielle cosinus, fournissent des données
        supplémentaires relatives aux mots du document et aux relations
        qu'ils entretiennent, ils utilisent les relations de cooccurrences
        observées dans les documents similaires pour ajouter et renforcer des
        arcs dans le graphe. Cette approche donne des résultats au-delà de ceux
        de SingleRank. Toutefois, ses performances sont fortement liées à la
        disponibilité de documents similaires. L'usage de documents voisins peut
        aussi ajouter et renforcer des liens qui ne devraient pas l'être si le
        document n'est pas suffisement similaire. Pour pallier ce problème, les
        auteurs pondèrent l'impact des documents similaires selon leur degré de
        similarité avec le document.

        ~\\\newcite{tsatsaronis2010semanticrank} tentent eux aussi d'améliorer
        TextRank. Dans leur méthode, ils créent et pondèrent un arc entre deux
        mots si et seulement si ceux-ci sont sémantiquement liés dans
        WordNet~\cite{miller1995wordnet} ou dans
        Wikipedia~\cite{milne2008wikipediasemanticrelatedness} (cf.
        équation~\ref{math:semanticrank}). WordNet est une base de données
        lexicales qui fournit un vecteur de synonymes pour les noms, les verbes,
        les adverbes et les adjectifs. Le vecteur de synonymes est ici considéré
        comme l'ensemble de tous les sens possibles pour un mot, c'est son
        vecteur sémantique. À partir des vecteurs sémantiques, toutes les paires
        sémantiques $P_{i, j}$ possibles entre deux mots $n_i$ et $n_j$, un sens
        de $n_i$ apairé à un sens de $n_j$, ainsi que tous les chemins $C_{i,
        j}$ possible pour atteindre un sens de $n_j$ à partir d'un sens de $n_i$
        sont construits. Le score de similarité sémantique avec WordNet est
        obtenu en trouvant le couple paire sémantique/chemin sémantique pour
        lequel le produit des mesures sémantiques \textit{Semantic Compactness}
        ($SCM$) et \textit{Semantic Path Elaboration} ($SPE$), introduites par
        \newcite{tsatsaronis2010textrelatedness}, est le plus élevé (cf.
        équation \ref{math:wordnetsemanticrelatedness}). Dans le cas où l'un des
        termes-clés candidats n'est pas présent dans WordNet, la similarité
        sémantique est calculée avec les données de Wikipédia.
        \begin{align}
          \text{poids}_{j, i} &= \left\{\begin{array}{ll}
            1 & \text{si $n_i = n_j$}\\
            \text{Sim}_{WN}(n_i, n_j) & \text{sinon, si $n_i, n_j \in \text{WordNet}$}\\
             \text{Sim}_{W}(n_i, n_j) &  \text{sinon, si $n_i, n_j \in \text{Wikipedia}$}\\
            0 & \text{sinon}
          \end{array}\right. \label{math:semanticrank}\\
          \notag\\
          \text{Sim}_{WN}(n_i, n_j) &= \max_{p \in P_{i, j}}\left\{\max_{c \in C_{i, j}}\left\{SCM(p, c) \times SPE(p, c)\right\}\right\} \label{math:wordnetsemanticrelatedness}\\
          \notag\\
          \text{Sim}_{W}(n_i, n_j) &= \frac{\log(\max(|\text{art}(i)|, |\text{art}(j)|)) - \log(|\text{art}(i) \cup \text{art}(j)|)}{\log(|\text{Wikipedia}|) - \log(\min(|\text{art}(i)|, |\text{art}(j)|))} \label{math:wikipediasemanticrelatedness}\\
          \notag\\
          \text{art}(i) &= \left\{\text{\textit{article}} \in \text{Wikipedia} | n_i \in \text{\textit{article}}\right\} \notag
        \end{align}

        Cette modification seule donne de moins bon résultats que TextRank.
        Toutefois, celle-ci améliore les résultats en combinaison avec un
        ordonnancement biasé par le TF-IDF des mots (cf équation~\ref{math:apw})
        ou avec un ordonnancement dont le facteur $\lambda$ est  propre à chaque
        mot (cf équation~\ref{math:ppr}), calculé selon son apparission ou non
        dans le titre du document.
        \begin{align}
          S_{\text{TF-IDF}}(n_i) &= \frac{1}{2} \times \left(\frac{S(n_i)}{\mathlarger{\max}_{n_j \in N}(S(n_j))} + \frac{\text{TF-IDF}(t_i)}{\mathlarger{\max}_{n_j \in N}(\text{TF-IDF}(t_j))}\right) \label{math:apw}\\
          \notag\\
          S_{\lambda}(n_i) &= (1 - \lambda_i) + \lambda_i \times \sum_{n_j \in A_{\text{entrant}}(n_i)} \frac{\text{poids}_{j, i} \times S_{\lambda}(n_j)}{\mathlarger{\sum}_{n_k \in A_{\text{sortant}}(n_j)} p_{j, k}} \label{math:ppr}
        \end{align}

        ~\\\newcite{liu2010topicalpagerank} reprennent SingleRank et proposent
        TopicalPageRank, une méthode qui cherche cette fois-ci à augmenter la
        couverture du document par les termes-clés extraits. Pour ce faire, ils
        détectent les sujets du document et ordonnent les mots en fonction de
        chaque sujets (un ordonnancement par sujet). En utilisant le modèle
        LDA~\cite{blei2003lda}, ils biaisent chaque ordonnancement avec un
        sujets (cf. équation~\ref{math:topicalpagerank}) et donnent le plus
        d'importance aux candidats dont les mots ont un meilleur rang pour le
        plus de sujets (cf. équation~\ref{math:topicalpagerankfinalscore}).
        \begin{align}
          S(n_i, \text{\textit{sujet}}) &= (1 - \lambda) \times p(\text{\textit{sujet}} | n_i) + \lambda \times \sum_{n_j \in A_{\text{entrant}}(n_i)} \frac{p_{j, i} \times S(n_j)}{\mathlarger{\sum}_{N_k \in A_{sortant}(N_j)} p_{j, k}} \label{math:topicalpagerank}\\
          Score(\text{\textit{candidat}}) &= \mathlarger{\sum}_{\text{\textit{sujet}}} p(\text{\textit{sujet}} | \text{\textit{document}}) \times \sum_{n \in \text{\textit{candidat}}} \text{rang}_{\text{\textit{sujet}}}(n) \label{math:topicalpagerankfinalscore}
        \end{align}

        ~\\Dans la continuité du travail de \newcite{liu2010topicalpagerank},
        \newcite{zhang2013wordtopicmultirank} ajoutent les sujets déterminés par
        \textsc{Lda} aux n\oe{}uds du graphe de cooccurrences et n'effectuent
        plus qu'un seul ordonnancement. Mots et sujets sont ordonnés
        simultanément, de sorte qu'un sujet est d'autant plus important
        s'il est connecté à un grand nombre de mots importants et qu'un mot est
        d'autant plus important s'il cooccurre avec un grand nombre de mots
        importants et s'il est connecté à un grand nombre de sujets importants.

    \subsection{Approche supervisée}
    \label{subsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction}
      Les méthodes supervisées apprennent principalement à classer les
      termes-clés en tant que \og{}terme-clés\fg{} ou \og{}non terme-clé\fg{}.
      Leur apprentissage se fait à partir d'un corpus d'apprentissage dont les
      documents sont annotés en termes-clés. Les termes-clés candidats sont
      sélectionnés dans ces documents et servent d'exemples et de
      contres-exemples.

      De nombreuses méthodes ont été proposées, utilisant différents
      classifieurs et présentant de nouveaux traits (caractéristiques)
      discriminants pour l'extraction automatique de termes-clés. Dans la suite,
      nous présentons ces méthodes, regroupés par classifieurs, et soulignons
      les nouveaux traits proposées. Notez qu'il existe aussi une étude
      comparative des performances des différents classifieurs pour la tache
      d'extraction automatique de
      termes-clés~\cite{sarkar2012machinelearningcomparison}.

      \subsubsection{Classifieurs probabilistes}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-probabilistic_models}
        Les classifieurs probabilistes utilisent des distributions de
        probabilités selon divers traits. Pour l'extraction des termes-clés d'un
        document, ces distributions sont combinées pour déterminer le score de
        vraisemblance de chaque terme-clé candidat en tant que termes-clés du
        document.

        ~\\KEA~\cite{witten1999kea} est la méthode d'extraction de termes-clés
        la plus populaire. Elle effectue une classification naïve bayesienne
        pour attribuer le score de vraisemblance de chaque terme-clé candidat.
        Elle combine les distribution probabilistes de deux traits~: la première
        position du candidat dans le document et son poids TF-IDF. L'intuition
        de \newcite{witten1999kea} est que les termes-clés ont une certaine
        importance vis-à-vis du document (leur poids TF-IDF) et qu'ils font leur
        première apparition dans des zones similaires du document.

        ~\\KEA est une approche très simple qui considère tous les traits comme
        indépendants (principe de la classification naïve bayésienne). Sa
        simplicité et ses bonnes performances ont suscitées un grand intéret, il
        en existe de nombreuses variantes. C'est le cas de la méthode de
        \newcite{frank1999keafrequency}, qui utilise comme trait supplémentaire
        le nombre de fois qu'un terme-clé candidat est un exemple dans le corpus
        d'apprentissage. Cette méthode donne un plus fort score de vraisemblance
        aux candidats déjà utilisés comme termes-clés. Elle améliore les
        performances de KEA, mais nécessite plus de données d'apprentissage.
        
        ~\\\newcite{turney2003keacoherence} reprend lui aussi KEA. À l'instar de
        \newcite{ding2011binaryintegerprogramming}, qui estiment que les
        termes-clés d'un document doivent être cohérent entre eux (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches:ilp}),
        il ajoute une deuxième classification naïve bayesienne après celle de
        KEA. La première classification sert à ordonner les candidats selon leur
        vraisemblance et la deuxième attribue un nouveau score de vraissemblance
        aux candidats, de sorte que les $L$ meilleurs candidats montent dans le
        classement s'ils ont un fort lien sémantique avec un ou plusieurs
        candidat(s) parmi les $K$ meilleurs ($K < L$). La force du lien
        sémantique est représenté par deux scores (soit $2 \times K$ traits)~:
        le nombre de pages Web contenant les deux candidats et le nombre de
        titres de pages Web contenant les deux candidats.

        ~\\\newcite{nguyen2007keadocumentstructure} améliorent KEA pour
        l'extraction de termes-clés à partir d'articles scientifiques. Faisant
        l'hypothèse que les termes-clés n'ont pas une répartition homogène dans
        les sections d'un article scientifiques, ils notent les occurrences des
        termes-clés candidats dans les sections génériques d'un article
        scientifique (résumé, introduction, motivations, état de l'art et
        conclusion), puis utilise le vecteur d'occurrences ainsi construit comme
        trait supplémentaire. De cette manière, les termes-clés apparaissant
        dans les sections les plus susceptibles de contenir des termes-clés ont
        un score de vraisemblance plus élevé.
        \newcite{nguyen2007keadocumentstructure} ajoutent aussi des traits
        linguistiques à KEA, les plus utilisés étant les catégories
        grammaticales de chaque mots~\cite{hulth2003keywordextraction}.
        
        ~\\\newcite{caragea2014citationenhancedkeyphraseextraction} utilisent
        eux aussi un classifieur naïf bayesien. Leur méthode repose sur le
        constat de \newcite{wan2008expandrank} que l'extraction de termes-clés
        bénéficie des informations extraites dans des documents en liens avec le
        document dont les termes-clés doivent être extraits (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}).
        Travaillant avec des articles scientifiques,
        \newcite{caragea2014citationenhancedkeyphraseextraction} utilisent le
        réseau de citations des documents afin de déterminer leur influence sur
        les autres documents et inversement. En plus des traits existant, ils
        ajoutent un TF-IDF calculés à partir de la fréquence de chaque candidat
        dans les contextes citationnels, ainsi que deux traits binaires
        indiquant si le candidat apparait dans une phrase du document qui cite
        un autre document ou s'il apparait dans une phrase qui cite le document.
        Bien que leur méthode obtient de meilleures performances que KEA, les
        auteurs mettent en évidence un défaut de leur approche. Concidérant les
        contextes citationnels, un document qui vient d'être publié ne peut pas
        avoir été cité par d'autres articles. Leur extraction de termes-clés
        tant toutefois à s'améliorer dans le temps.

        ~\\Contrairement à \newcite{witten1999kea}, qui utilisent un classifieur
        naïf bayésien et considèrent que tous les traits sont indépendants,
        \newcite{sujian2003maximumentropy} proposent une méthode utilisant un
        classifieur d'entropie maximale. Ce classifieur cherche parmi plusieurs
        distributions, une pour chaque trait, laquelle a la plus forte entropie.
        La distribution ayant la plus forte entropie est par définition celle
        qui contient le moins d'information, ce qui la rend moins arbitraire et
        donc plus appropriée pour l'extraction automatique de termes-clés.
        Chaque trait se voit donc attribuer un poids, de sorte que les traits
        les moins arbitraires aient le plus de poids dans la classification. En
        plus des traits cités pour les méthodes précédentes, et à l'instar de
        \newcite{nguyen2007keadocumentstructure}, ils tirent partie d'autres
        traits liés à la nature des documents qu'ils traitent. Ainsi, pour des
        articles journalistiques ils utilisent leur type (information, sport,
        etc.) et la catégorie d'entité nommée des candidats s'ils en sont une
        (personne, pays, organisme, etc.).

        ~\\Plus récemment, le travail de \newcite{zhang2008crfkeywordextraction}
        montre l'applicapilité d'un \textsc{Crf} (\textit{Conditional Random
        Field}) à la tâche d'extraction de termes-clés. Ce classifieur a
        l'intéressante capacité à prédir des séquences de classes, soit à
        étiqueter tout un document en donnant les classes suivantes pour chaque
        mot~: \og{}terme-clé\fg{}, \og{}début d'un terme-clé\fg{}, \og{}partie
        d'un terme-clé\fg{} et \og{}non terme-clé\fg{} (\TODO{etiqueter
        l'exemple fil rouge}). \newcite{zhang2008crfkeywordextraction}
        reprennent les traits présentés précédemment (TF-IDF, première position,
        section d'article scientifique, etc.) et y ajoutent le contexte de
        chaque mot. Nous trouvons cette notion de contexte dans les méthodes non
        supervisées à base de graphe (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}),
        mais il s'agit de la première fois que nous trouvons celle-ci dans une
        méthode supervisée. Le fonctionnement particulier du \textsc{Crf} se
        prète plus à l'utilisation du contexte que les autres classifieurs.

      \subsubsection{Arbres de décision}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-decision_trees}
        Les arbres de décision sont des classifieurs dont les branches
        représentent des tests sur les
        traits des candidats. Ces tests routent les candidats
        vers les feuilles de l'arbre représentant leur classe respective
        (\og{}terme-clé\fg{} ou \og{}non terme-clé\fg{}).

        ~\\Dans son article sur l'apprentissage pour l'extraction automatique de
        termes-clés, \newcite{turney1999learningalgorithms} entraîne 50 arbres
        de décision (technique \textit{random forest}) et réduit la tâche
        d'extraction de termes-clés à un vote. Les arbres de décision classent
        indépendemment chaque candidat et les candidats majoritairement
        classés \og{}terme-clé\fg{} sont extraits comme termes-clés. Parmi les
        nombreux traits qu'utilise \newcite{turney1999learningalgorithms}, les
        plus novateurs sont des traits binaires qui visent des catégories
        grammaticales précises~: \og{}contient un nom propre~?\fg{},
        \og{}contient un verbe usuel~?\fg{} et \og{}se termine par un
        adjectif~?\fg{}. Contrairement aux autres travaux, celui de
        \newcite{turney1999learningalgorithms} est aussi l'un des seuls à
        décliner les traits à des niveaux de granularité différents. Chaque
        traits concernent le candidats dans son ensemble et ses mots séparément.

        ~\\\newcite{ercan2007lexicalchains} utilisent eux aussi des arbres de
        décision pour extraire les termes-clés, restreints aux mots-clés dans
        leur cas. L'aspect novateur de leur méthode est l'usage de chaînes
        lexicales pour la définition de nouveaux traits discriminants. Une
        chaîne lexicale est un graphe de mots liés entre eux hiérarchiquement
        (cf. figure~\ref{fig:lexical_chain}). \newcite{ercan2007lexicalchains}
        tiennent compte des relations de méronymie/holonymie\footnote{Méronyme~:
        mot dont le signifié est une sous-partie de celui d'un autre mot, son
        holonyme. Par exemple, \og{}bras\fg{} est un méronyme de
        \og{}corps\fg{}.}$^,$\footnote{Holonyme~: mot dont le signifié est
        composé de celui d'un autre mot, son méronyme.},
        d'hyponymie/hyperonymie\footnote{Hyponyme~: mot dont le signifié est
        plus spécifique que celui d'un autre mot, son
        hyperonyme.}$^,$\footnote{Hyperonyme~: mot dont le sygnifié est plus
        général que celui d'un autre mot, son hyponyme.} et de synonymie,
        auxquelles ils donnent un poids (4 pour la méronymie/holonymie, 7 pour
        l'hyponymie/hyperonymie et 10 pour la synonymie). Chaque mot se voit
        attribuer quatre traits correspondant à quatre scores obtenus à partir
        des poids des relations~:
        \begin{enumerate}
          \item{score de la chaîne lexicale~: somme du poids de toutes les
                relations de la chaîne lexicale~;}
          \item{score du mot dans la chaîne lexicale~: somme du poids de toutes
                les relations du mot avec les autres mots de la chaîne
                lexicale~;}
          \item{couverture de la chaîne lexicale~: différence entre la dernière
                occurrence, dans le document, d'un mot de la chaîne lexicale
                avec la première occurrence, dans le document, d'un mots de la
                chaîne lexicale~;}
          \item{couverture du mots et de ses voisins dans la chaîne lexicale~:
                de même que la couverture de la chaîne lexicale, mais en tenant
                compte uniquement du mot et de ses voisins dans la chaîne.}
        \end{enumerate}
        \begin{figure}
          \centering
          \begin{tikzpicture}
            \node (programme) {programme};
            \node [below=of programme] (logiciel) {logiciel};
            \node [right=of logiciel, xshift=2em] (paquetage) {paquetage};
            \node [left=of logiciel, xshift=-2em] (application) {application};
            \node [below=of application] (app) {app};

            \draw (programme) -- (logiciel);
            \draw (programme) -- (application);
            \draw (programme) -- (paquetage);
            \draw (application) -- (logiciel);
            \draw (logiciel) -- (paquetage);
            \draw [dashed] (application) -- (app);

            % legend
            \node [scale=.75, right=of app, xshift=12em, yshift=3em] (legend_title) {\underline{Légende~:}};
            \node [scale=.75, below=of legend_title, xshift=-1.5em, yshift=3em] (begin_hyponym) {};
            \node [scale=.75, right=of begin_hyponym, xshift=-1em] (end_hyponym) {: hyponymie/hyperonymie};
            \node [scale=.75, below=of begin_hyponym, yshift=3em] (begin_synonym) {};
            \node [scale=.75, right=of begin_synonym, xshift=-1em] (end_synonym) {: synonymie};

            \draw (legend_title.north  -| end_hyponym.east) rectangle (end_synonym.south -| legend_title.west);

            \draw (begin_hyponym) -- (end_hyponym);
            \draw [dashed] (begin_synonym) -- (end_synonym);
          \end{tikzpicture}
          \caption{Exemple de chaîne lexicale~\cite{ercan2007lexicalchains}
                   \label{fig:lexical_chain}}
        \end{figure}

        ~\\Tirant aussi profit d'arbres de décision, \newcite{lopez2010humb}
        sont les vainqueurs de la campagne d'évaluation
        SemEval-2010~\cite{kim2010semeval}. Ils extraient les termes-clés en
        deux étapes. Tout d'abord, ils ordonnent les termes-clés candidats avec
        les arbres de décision, puis ils les ré-ordonnent à la manière de
        \newcite{turney2003keacoherence}~: les candidats bien classés
        initialement sont d'autant mieux classés qu'ils ont un fort lien
        sémantique avec d'autres candidats bien classés initialement. Cette
        méthode est actuellement l'une des meilleurs méthodes d'extraction de
        termes-clés.

      \subsubsection{Séparateurs à vastes marges (SVM)}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-svms}
        Les séparateurs à vastes marges projetent les exemples et les
        contres-exemples sur un plan selon la valeur de leurs traits, puis
        construisent l'hyperplan qui sépare exemples et contres-exemples. Pour
        classer les termes-clés candidats d'un document, il suffit ensuite de
        les projeter sur ce même plan et d'utiliser l'hyperplan appris.

        ~\\\newcite{zhang2006svm} font l'usage d'un SVM pour extraire les
        termes-clés en tirant partie de ce qu'ils appellent le contexte global
        et le contexte local des termes-clés candidats. Ils représentent le
        contexte global d'un candidats par son TF-IDF, sa première position et
        ses occurrences dans différentes parties du document, tandis qu'ils
        représentent son contexte local par sa catégorie grammaticale et trois
        traits encore jamais utilisés auparavant. Les deux premiers sont
        déterminés à partir des dépendances entre les mots. À la manière des
        méthodes non supervisées à base de graph (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches})
        l'un des traits dénote le nombre de fois que le candidat modifie un mot
        et l'autre dénote le nombre de fois qu'un mot modifie le candidat. Le
        dernier trait s'appelle le TF-IDF contextuel, il s'agit de la somme du
        TF-IDF de tous les mots qui cooccurrent avec le candidat. Ce dernier
        trait indique si un candidat occurre dans un contexte important
        vis-à-vis du document.

        ~\\\newcite{jiang2009rankingsvm} extraient les termes-clés à partir d'un
        type particulier de SVM, baptisé SVM$^\textnormal{rank}$.
        SVM$^\textnormal{rank}$ construit plusieurs hyperplans qui permettent
        d'ordonner les termes-clés candidats. Utilisant le score TF-IDF des
        candidats, leur taille (en nombre de mots), leur première position, leur
        entropy et bien d'autres traits, le travail de
        \newcite{jiang2009rankingsvm} montre que le classifieur
        SVM$^\textnormal{rank}$ est plus performant qu'un SVM ou qu'un
        classifieur naïf bayesien utilisant avec les mêmes traits.

        ~\\\newcite{eichler2010keywe} extraient eux aussi les termes-clés à
        partir d'un SVM$^\textnormal{rank}$. Ils apprennent le
        SVM$^\textnormal{rank}$ en utilisant trois valeurs pour le rang, la
        valeur maximale étant attribuée aux exemples de chaque document
        d'apprentissage, la valeur minimale a ses contres-exemples et une valeur
        intermédiaire a ses contres-exemples qui sont des exemples pour d'autres
        documents d'apprentissage. Cette approche est intéressante, elle peut
        étre assimilé au trait ajouté à KEA par \newcite{frank1999keafrequency}.
        Quant aux traits utilisés par \newcite{eichler2010keywe}, le plus
        notable fait l'usage de Wikipedia. L'intuition des auteurs est que si un
        terme-clé candidat fait l'objet d'un article Wikipedia, alors il est
        plus vraisemblablement un terme-clé.

      \subsubsection{Perceptrons multicouches}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-neural_network}
        Les perceptrons multicouches sont des classifieurs qui émulent la
        biologie de l'apprentissage des êtres vivants. Ce sont des réseaux de
        neurones constitués d'au moins trois couches. Les neurones de la
        première couche représentent les traits d'un candidat (un neurone par
        trait), ceux des couches centrales (couches cachées) propagent des
        scores obtenus selon la valeur des traits et ceux de la dernière couche
        donnent un score final pour chaque classe \og{}terme-clé\fg{} et
        \og{}non terme-clé\fg{} (un neurone par classe). La classe ayant le plus
        haut score est celle du terme-clé candidat pour lequel correspond la
        valeur des traits.
        
        ~\\\newcite{sarkar2010neuralnetwork} utilisent un perceptron multicouche
        pour classer les termes-clés candidats selon leur TF-IDF, leur position,
        leur taille (en nombre de mots) et celle de leurs mots (en nombre de
        caractères). L'une des principales contributions de leur travail est
        l'apprentissage d'un estimateur capable de donner le degré de confiance
        d'une classification selon le score attribué à chaque classe. Cette
        estimateur permet d'ordonner les termes-clé candidats, ceux classés
        \og{}terme-clé\fg{} en premier dans l'ordre décroissant de leur
        confiance et ceux classés \og{}non terme-clé\fg{} en dernier dans
        l'ordre croissant de leur confiance. Ainsi, la méthode de
        \newcite{sarkar2010neuralnetwork} méthode peut extraire un nombre
        contrôlé de termes-clés, en ajoutant des candidats classés \og{}non
        terme-clé\fg{} si nécessaire.

      \subsubsection{Algorithmes génétiques}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-genex}
        Les algorithmes génétiques sont des algorithmes qui donnent une solution
        approchée à un problème d'optimization. Ce type d'algorithme
        n'effectue pas de classification et n'est pas nécesssairement supervisé.
        \TODO{lien avec les méthodes d'opti non supervisée ?}

        ~\\\newcite{turney1999learningalgorithms} propose une méthode
        supervisée, GenEx, dont les paramètres sont valués par un algorithme
        génétique, appelé \textit{Genitor}. L'algorithme d'extraction de
        termes-clés, appelé \textit{Extractor}, est appliqué sur le corpus
        d'apprentissage avec des paramètres initiaux, puis le Genitor fait
        évoluer la valeur de ces paramètres jusqu'à trouver celle qui maximise
        les performances de l'extraction. L'extraction des termes-clés d'un
        document se fait ensuite avec l'\textit{Extractor} et ses paramètres
        configurés par le \textit{Genitor}. Les paramètres apris sont
        principalement des seuils limitant la taille des candidats, le nombre de
        mots importants à considérer pour filtrer les candidats, ou encore le
        nombre de termes-clés à extraire. Ce sont aussi des facteurs
        multiplicateurs utilisés pour le calcul de l'importance des mots et des
        candidats.

  \section{Assignation automatique de termes-clés}
  \label{sec:main-state_of_the_art-automatic_keyphrase_assignment}
    L'assignation automatique de termes-clés a fait l'objet de moins de travaux
    que l'extraction automatique de termes-clés. Il s'agit aussi d'une tâche
    plus difficile, car elle doit assigné des entrées d'un vocabulaire contrôlé
    en tant que termes-clés d'un document indépendemment de leur apparition dans
    celui-ci.

    ~\\\newcite{medelyan2008smalltrainingset} sont les premiers à proposer une
    méthode capable de faire de l'assignation automatique de termes-clés. Leur
    méthode, KEA++, améliore la méthode supervisée d'extraction de termes-clés
    KEA. Elle utilise un thésaurus\footnote{\TODO{\dots}} du domaine des
    documents à traiter pour affiner la sélection des candidats et ajouter un
    trait au classifieur naïf bayesien.

    Lors de la sélection des candidats, les n-grammes qui ne font pas partie des
    entrées du thésaurus sont jugés mal formés et sont éliminés s'ils ne peuvent
    pas être remplacés par une autre forme. KEA++ accepte les entrées du
    thésaurus qui partagent la racine de leurs mots avec un n-gramme mal formé
    et les entrées du thésaurus qui sont des synonymes d'un n-gramme mal formé.
    De cette manière, l'assignation peut s'effectuer, tous les candidats font
    partie d'un vocabulaire contrôlé et certains d'entre eux n'apparaissent pas
    dans le document.

    \newcite{medelyan2008smalltrainingset} tirent aussi profit du thésaurus lors
    de la classification des candidats. Ils ajoutent un trait indiquant le lien
    qu'entretient chaque candidat avec les autres dans le thésaurus (le nombre
    de liens). De cette manière, ils imitent le travail de
    \newcite{turney2003keacoherence} qui tente d'améliorer la cohérence entre
    les termes-clés extraits par KEA.

    KEA++ obtient des performances une fois supérieures à celles de KEA, sans en
    augmenter grandement sa complexité. Le travail de
    \newcite{medelyan2008smalltrainingset} montre donc l'importance d'utiliser
    une méthode d'assignation de termes-clés lorsque les données requises sont
    disponibles.

    ~\\\TODO{KeaKAT}

    ~\\\newcite{liu2011vocabularygap} ont eux aussi proposé une méthode pouvant
    effectuer de l'assignation de termes-clés. Leur approche consiste à
    transformer le problème d'assignation en un problème de traduction. Leur
    idée est la suivante~: un document et ses termes-clés expriment le même
    contenu dans deux langues différentes, l'une expressive et l'autre plus
    concise et synthétique. Dans leur travail, ils apprennent leur modèle de
    traduction à partir des éléments du titre à la place des termes-clés de
    référence ou d'un vocabulaire contrôlé. Dans leur cas, il ne s'agit donc pas
    rigoureusement d'assignation de termes-clés, leur approche y est toutefois
    appropriée.

  %-----------------------------------------------------------------------------

  \section{Évaluation automatique de l'indexation par termes-clés}
  \label{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation}
    Pour montrer l'apport des nouvelles méthodes d'indexation par termes-clés,
    celles-ci sont comparées aux méthodes existantes dans un processus
    d'évaluation \og{}à la Cranfield\fg{} \citep{voorhees2002philosophy}. Chaque
    méthode est appliquée à un ensemble de documents de test (corpus de test) et
    les termes-clés qu'elle extrait sont comparés à ensemble de termes-clés
    associés manuellement aux documents (jugements de référence). Un jugement de
    référence est supposé unique, la comparaison entre un terme-clé extrait
    et un terme-clé de référence est donc binaire. Le résultat des comparaisons
    pour chaque document est analysé selon différents critères (le moins
    d'erreurs, le plus de bon termes-clés, etc.) et la méthode respectant en
    moyenne le mieux ces critères est jugée la plus performante.

    En indexation par termes-clés, il est courant d'évaluer une méthode en
    termes de précision, de rappel et de f-mesure. La précision capture la
    capacité d'une méthode à minimiser les erreurs (faux positifs, cf.
    tableau~\ref{tab:confusion_matrix} et équation~\ref{math:precision}). En
    opposition, le rappel ne considère pas la quantité d'erreurs et mesure la
    capacité de la méthode à fournir le plus possible de termes-clés correctes
    (vrais positifs, cf tableau~\ref{tab:confusion_matrix} et
    équation~\ref{math:recall}). Quant à la f-mesure, celle-ci mesure le
    compromis entre précision et rappel, soit la capicité de la méthode à
    extraire un maximum de termes-clés correctes en faisant un minimum d'erreurs
    (cf. équation~\ref{math:f_measure}).
    \begin{table}
      \begin{center}
        \begin{tabular}{cc|cc}
          \toprule
          \multicolumn{2}{c|}{} & \multicolumn{2}{c}{\textbf{Jugement de référence}}\\
          \multicolumn{2}{c|}{} & \og{}terme-clé\fg{} & \og{}non terme-clé\fg{}\\
          \hline
          \multirow{2}{*}{\textbf{Résultat}} & \og{}terme-clé\fg{} & vrai positif ($VP$) & faux positif ($FP$)\\
          & \og{}non terme-clé\fg{} & faux negatif ($FN$) & vrai negatif ($VN$)\\
          \bottomrule
        \end{tabular}
        \caption{Matrice de confusion pour l'évaluation des méthodes
                 d'indexation automatique par termes-clés
                \label{tab:confusion_matrix}}
      \end{center}
    \end{table}
    \begin{align}
      \text{précision} &= \frac{\#VP}{\#VP + \#FP} \label{math:precision}\\
      \notag\\
      \text{rappel} &= \frac{\#VP}{\#VP + \#FN} \label{math:recall}\\
      \notag\\
      \text{f-mesure} &= (1 + \beta^2) \times \frac{\text{précision} \times \text{rappel}}{(\beta^2 \times \text{précision}) + \text{rappel}} \label{math:f_measure}
    \end{align}
      
    En \textsc{Ri}, il est courant d'évaluer les méthodes selon la qualité de
    leur ordonnancement. Prenons l'exemple des moteurs de recherche, si deux
    moteurs de recherche doivent fournir dix documents répondant à une requête
    et que les deux systèmes n'ont que deux propositions pertinentes, alors ils
    ont tous les deux la même précision (20~\%) et le même rappel (20~\%).
    Toutefois, si le premier système classe ces documents en premier et que le
    second système les classe en position neuf et dix, alors le premier système
    est le meilleur. Lorsque les méthodes d'indexation par termes-clés le
    permettent, il est intéressant de mesurer leur capacité à classer en premier
    les vrais positifs. Dans la littérature, quatre mesures, dont certaines
    empruntées à la \textsc{Ri}, sont utilisées~: la \textsc{Map} (\textit{Mean
    Average Precision}), la Bpref (\textit{Binary Preference Measure}), la
    R-précision et la \textsc{Mrr} (\textit{Mean
    Reciprocal Rank}). La
    \textsc{Map} mesure pour chaque document la moyenne de la précision à chaque
    rang ($\textnormal{précision}@\textnormal{rang}$) d'un vrai positif (cf.
    équation~\ref{math:average_precision}). Avec la Bpref, c'est la seule mesure
    qui tient compte de tous les vrais positifs. La Bpref est une mesure
    similaire à la \textsc{Map} qui, contrairement à cette dernière, s'abstrait
    de la connaissance de tous les termes-clés de référence (cf.
    équation~\ref{math:bpref}) et qui peut donc,
    par exemple, s'appliquer dans le cadre d'évaluations manuelles où chaque
    terme-clé fourni par la méthode est jugé correcte ou non et où tous les
    termes-clés du document ne sont pas connus. La R-précision est une
    variante de la précision qui mesure cette dernière dans le cas optimal (tous
    les termes-clés sont fourni et il n'y a aucune erreur), soit au rang $R$, où
    $R$ est égale au nombre de termes-clés de référence du document (cf.
    équation~\ref{math:r_precision}). Quant à la \textsc{Mrr}, celle-ci est la
    moins précise, elle ne s'intéresse qu'au meilleur rang obtenu pour un vrai
    positif (cf. équation~\ref{math:reciprocal_rank})
    \begin{align}
      \text{\textit{average\_precision}} &= \frac{\mathlarger{\sum}_{\text{\textit{terme-clé}} = VP}\text{précision}@\text{rang}(\text{\textit{terme-clé}})}{\#VP + \#FN} \label{math:average_precision}\\
      \notag \\
      \text{Bpref} &= \sum_{\text{\textit{terme-clé}} = VP}{1 - \frac{|\text{\textit{terme-clé}'}\ \text{de meilleur rang que}\ \text{\textit{terme-clé}}|}{\#VP + \#FP}} \label{math:bpref}\\
      \notag \\
      \text{R-précision} &= \text{précision}@(\#VP + \#FN) \label{math:r_precision}\\
      \notag \\
      \text{\textit{reciprocal\_rank}} &= \frac{1}{\text{argmin}(\forall \text{\textit{terme-clé}} = VP, \text{rang}(\text{\textit{terme-clé}}))} \label{math:reciprocal_rank}
    \end{align}

    Toutes les mesures présentées précédemment respectent le paradigme de
    l'évaluation \og{}à la Cranfield\fg{}. Cependant, associer des termes-clés à
    un document est une tâche subjective~\cite{hasan2014state_of_the_art}, il
    n'y a donc pas une unique solution. Des travaux proposent d'apporter plus de
    souplesse à la comparaison entre termes-clés résultant d'une méthode et
    termes-clés de référence en tenant compte de leur
    chevauchement~\cite{zesch2009rprecision,kim2010rprecision}. Ces travaux
    n'ont toutefois jamais été utilisés dans des cas réels.

  \section{Conclusion}
  \label{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation-conclusion}
    \begin{itemize}
      \item{synthèse sélection des candidats}
      \item{-> pb}
      \item{-> perspectives (extr. termino FASTR/TermSuite/Acabit)}
      \item{synthèse unsupervised AKE}
      \item{-> pb}
      \item{-> perspectives}
      \item{synthèse supervised AKE}
      \item{-> pb}
      \item{-> perspectives}
      \item{synthèse AKA}
      \item{-> pb}
      \item{-> perspectives (extr. termino FASTR/TermSuite/Acabit)}
      \item{synthèse eval}
      \item{-> pb}
      \item{-> perspectives}
    \end{itemize}

