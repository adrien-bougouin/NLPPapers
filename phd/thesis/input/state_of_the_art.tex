\chapter[Indexation automatique par termes-clés]{Indexation automatique\\par termes-clés}
\label{chap:main-state_of_the_art}
  \chaptercite{
    There is a need for tools that can automatically create keyphrases. Although
    keyphrases are very useful, only a small minority of the many documents that
    are available on-line today have keyphrases.
  }{
    \newcite{turney1999learningalgorithms}
  }

  \section{Introduction}
  \label{sec:main-state_of_the_art-introduction}
    Les termes-clés\index{Terme-cle@Terme-clé \textit{(keyphrase)}|textbf},
    souvent appelés mots-clés\index{Mot-cle@Mot-clé
    \textit{(keyword)}|textbf}\footnote{Un terme-clé est plus communément appelé
    mot-clé. Cependant, un mot-clé n'étant pas uniquement monolexical, nous
    utilisons la notion de terme-clé pour lever toute ambiguïté. Lorsque dans la
    suite nous parlons de mots-clés, cela ne concerne donc que les
    monolexicaux.}, sont les unités textuelles (mots ou expressions) qui
    caractérisent le contenu principal d'un document~: les sujets qu'il aborde,
    ses idées, etc. Associés à un document ceux-ci donnent une description
    précise de ce qu'il contient et peuvent servir à la recherche d'information
    (\textsc{Ri}). Nous parlons donc d'indexation par
    termes-clés\index{Indexation par termes-cles@Indexation par termes-clés
    \textit{(automatic keyphrase annotation)}|textbf}. Cette indexation ne doit
    toutefois pas être confondue avec l'indexation dite \og{}plein texte\fg{} au
    c\oe{}ur de nombreux systèmes de \textsc{Ri}. L'indexation plein texte
    pondère tous les mots d'un document selon leur importance relative à
    celui-ci, tandis que l'indexation par termes-clés fournit un ensemble
    restreint de mots ou expressions qui représentent ses sujets importants,
    explicites ou non.

    Dans la littérature, nous distinguons deux catégories d'indexation
    automatique par termes-clés~: l'une libre, l'autre contrôlée. L'indexation
    libre\index{Indexation libre@Indexation libre \textit{(free indexing)}|see
    {Extraction automatique de termes-clés \textit{(automatic keyphrase
    extraction)}}} consiste à extraire d'un document les unités textuelles
    jugées les plus importantes dans son contexte. Nous parlons
    d'\emph{extraction automatique de termes-clés}\index{Extraction automatique
    de termes-cles@Extraction automatique de termes-clés \textit{(automatic
    keyphrase extraction)}|textbf}. L'indexation contrôlée\index{Indexation
    controlee@Indexation contrôlée \textit{(controlled indexing)}|see
    {Assignement automatique de termes-clés \textit{(automatic keyphrase
    assignment)}}} fournit les termes-clés en se fondant sur un vocabulaire
    contrôlé (une terminologie) et sans se restreindre aux unités textuelles
    présentes dans le document. Nous parlons d'\emph{assignement automatique de
    termes-clés}\index{Assignement automatique de termes-cles@Assignement
    automatique de termes-clés \textit{(automatic keyphrase
    assignment)}|textbf}.

    Dans ce chapitre d'introduction à l'indexation automatique par termes-clés,
    nous commençons par présenter l'étape de sélection des termes-clés
    candidats, qui est une étape commune à la plupart des méthodes d'extraction
    et d'assignement automatique de termes-clés, et qui est un objet d'étude à
    part entière~\cite{wang2014keyphraseextractionpreprocessing}. Ensuite, nous
    présentons les tâches d'extraction automatique de termes-clés et
    d'assignement automatique de termes-clés, puis nous terminons par une
    description du processus d'évaluation des méthodes d'indexation par
    termes-clés.

  %-----------------------------------------------------------------------------

  \section{Sélection des termes-clés candidats}
  \label{sec:main-state_of_the_art-keyphrase_candidate_selection}
    % Quel est l'objectif ?
    La sélection des termes-clés candidats\index{Selection des termes-cles
    candidats@Sélection des termes-clés candidats \textit{Keyphrase candidate
    selection}|textbf}\index{Terme-cle candidat@Terme-clé candidat
    \textit{(keyphrase candidate)}|textbf} consiste à déterminer quelles sont
    les unités textuelles qui sont potentiellement des termes-clés, soit les
    unités textuelles qui ont des particularités similaires à celles des
    termes-clés définis par des humains, telles que la structure
    morphosyntaxique nom-adjectif commune à la majorité des termes-clés
    (\TODO{exemple}). La sélection des termes-clés candidats présente deux
    avantages. Le premier est la réduction du temps de calcul nécessaire à
    l'extraction ou à l'assignement des termes-clés. Le second est la
    suppression d'unités textuelles non pertinentes pouvant affecter
    négativement les performances de l'ordonnancement. Pour distinguer les
    différents candidats sélectionnés, nous définissons deux catégories~: les
    candidats positifs\index{Candidat positif@Candidat positif \textit{(positive
    candidate)}|textbf}, qui correspondent aux termes-clés assignés par des
    humains (termes-clés de référence), et les candidats négatifs\index{Candidat
    negatif@Candidat négatif \textit{(negative candidate)}|textbf}. Parmi les
    candidats négatifs, nous distinguons deux sous-catégories~: les candidats
    porteurs d'indices\index{Candidat porteur d'indices@Candidat porteur
    d'indices \textit{(clue candidate)}|textbf} pouvant influencer l'extraction
    ou l'assignement de candidats positifs (\TODO{exemple}) et les candidats
    erronés\index{Candidat erronés@Candidat erronés \textit{(irrelevant
    candidate)}|textbf} \TODO{exemple}.

    Il existe plusieurs méthodes de sélection de candidats, de la simple
    sélection de n-grammes, de chunks nominaux ou d'unités textuelles
    grammaticalement définies, jusqu'à la sélection à l'aide d'algorithmes
    réduisant le nombre de candidats en supprimant ceux qui sont sémantiquement
    redondants où mal formés.

    ~\\Les n-grammes\index{N-gramme@N-gramme \textit{(n-gram)}|textbf} sont
    toutes les séquences ordonnées de $n$ mots adjacents. La sélection des
    n-grammes est très exhaustive, elle fournit un grand nombre de termes-clés
    candidats, ce qui maximise la quantité de candidats positifs, la quantité de
    candidats porteurs d'indices, mais aussi la quantité de candidats erronés.
    Pour réduire cette dernière, il est courant de filtrer les n-grammes avec un
    antidictionnaire\index{Antidictionnaire@Antidictionnaire
    \textit{(stopwords)}|textbf}, selon le principe suivant~: un n-gramme
    contenant un mot de l'antidictionnaire en début ou en fin n'est pas
    considéré comme un terme-clé candidat. L'antidictionnaire regroupe les mots
    fonctionnels de la langue (conjonctions, prépositions,~etc.) et les mots
    d'usage courant (\og{}particulier\fg{}, \og{}près\fg{}, \og{}beaucoup\fg{},
    etc.).
    
    Malgré son aspect bruité, la sélection des n-grammes est largement utilisée
    pour l'indexation par
    termes-clés~\cite{witten1999kea,hulth2003keywordextraction,medelyan2009humancompetitivetagging}.

    \begin{example}
      \TODO{$\{1..3\}$-grammes à partir d'une phrase de l'exemple fil rouge}
    \end{example}

    ~\\Les \textit{chunks} nominaux\index{NP-chunk@NP-\textit{chunk}|textbf}
    sont des syntagmes\index{Syntagme@Syntagme
    \textit{(syntagm)}|textbf}\footnote{Syntagme~: unité syntaxique
    intermédiaire entre le mot et la phrase. Aussi appelé groupe, le syntagme
    constitue une unité de sens dont chaque constituant conserve sa
    signification et sa syntaxe propre.} non récursifs (ou minimaux) dont la
    tête est un nom, accompagné de ses éventuels déterminants et modifieurs
    usuels. Ils sont linguistiquement définis et leur sélection est donc plus
    fiable que celle des n-grammes. \newcite{hulth2003keywordextraction} le
    montre dans ses expériences consacrées à l'apport de connaissances
    linguistiques pour l'extraction automatique de termes-clés. Cependant, ses
    propos sont nuancés par un autre de ses constats~: tirer profit de la
    catégorie grammaticale des mots des n-grammes permet d'obtenir de meilleures
    performances qu'avec les \textit{chunks} nominaux.

    \begin{example}
      \TODO{NP-\textit{chunks} à partir d'une phrase de l'exemple fil rouge}
    \end{example}

    ~\\La sélection d'unités textuelles qui forment des séquences
    grammaticalement définies\index{Sequence grammaticalement definie@Séquence
    grammaticalement définie \textit{(POS sequence)}|textbf} permet de contrôler
    avec précision la nature et la grammaticalité des candidats sélectionnés.
    Pour cela, il faut définir des patrons grammaticaux tels que \texttt{/(N|A)*/}, qui représente les plus longues séquences de noms et
    d'adjectifs, d'après la syntaxe des expressions rationnelles.

    À l'instar des \textit{chunks} nominaux, la sélection des séquences
    grammaticalement définies est plus fondée linguistiquement que celle des
    n-grammes. Dans ses travaux, \newcite{hulth2003keywordextraction}
    sélectionne les candidats à partir des patrons des termes-clés de référence
    les plus fréquents dans ses données. D'autres chercheurs,
    tels que \newcite{wan2008expandrank}, se contentent des plus longues
    séquences de noms (noms propres inclus) et d'adjectifs.

    \begin{example}
      \TODO{Plus longues séquences de noms et d'adjectifs à partir d'une phrase de l'exemple fil rouge}
    \end{example}

    ~\\En plus des trois précédentes méthodes de sélection de termes-clés
    candidats, des chercheurs, tels que
    \newcite{huang2006semanticnetworkstructureanalysis} proposent un filtrage
    sophistiqué des candidats sélectionnés par la méthode de sélection des
    n-grammes (en anglais). \newcite{huang2006semanticnetworkstructureanalysis}
    filtrent tout d'abord les candidats peu fréquents dans le document, puis
    suppriment les candidats redondants avec d'autres en les mettant en
    compétition. Pour chaque groupe de candidats redondants, un seul candidat
    peut être retenu comme terme-clé candidat, celui le plus fréquent. Un
    candidat peut être en compétition dans différents groupes. Dans ce cas, il
    doit être le \og{}vainqueur\fg{} de chaque groupe pour être retenu.

    Le travail de \newcite{huang2006semanticnetworkstructureanalysis}, sur la
    sélection des termes-clés candidats, fait partie de leur système
    d'extraction de termes-clés. Ce système a fait l'objet d'une évaluation,
    mais aucune étude n'a été conduite pour montrer l'efficacité de leur
    filtrage hors des frontières de leur système.

    ~\\À l'instar de \newcite{huang2006semanticnetworkstructureanalysis},
    \newcite{you2009refinedcandidateset} proposent une méthode de filtrage des
    n-grammes. Dans leur cas, une analyse de leur méthode de sélection des
    candidats est fournie. Leur méthode se divise en deux étapes: sélection de
    candidats préliminaires grâce à une liste de mots-clés, puis réduction de
    cet ensemble de candidats préliminaires à un ensemble non redondant de
    candidats porteurs de sens.

    Dans un premier temps, \newcite{you2009refinedcandidateset} identifient les
    mots-clés et s'en servent pour établir une liste préliminaire de candidats.
    Pour cela, ils extraient les $k$ mots (mots d'un antidictionnaire exclus)
    les plus fréquents du document (mots-clés), puis ils selectionnent un à sept
    candidat(s) préliminaire(s) par occurrence de chaque mot-clé~: le mot-clé
    lui-même et les 2-, 3- et 4-grammes commençant ou se terminant par le
    mot-clé\footnote{La taille maximale de 4 pour les n-grammes est fixée par
    les auteurs après une analyse statistique de leurs données. Cette taille
    peut diverger selon les données, auquel cas les candidats préliminaires
    sélectionnés pour chaque occurrence d'un mots-clés peut excéder sept.}.

    \begin{example}
      \TODO{Un 1-gramme, deux 2-grammes, deux 3-grammes et deux 4-grammes à partir d'une phrase de l'exemple fil rouge}
    \end{example}

    Dans un second temps, \newcite{you2009refinedcandidateset} analysent chaque
    7-uplets de $\{1..4\}$-grammes et choisissent les candidats porteurs de sens
    en limitant les redondances. Pour chaque 7-uplet, ils construisent un arbre
    ayant pour racine le mot-clé du 7-uplet et dont chaque n\oe{}ud fils est un
    mot précédant ou suivant le mot du n\oe{}ud parent, puis ils le parcourent
    en profondeur et utilisent une heuristique pour ne choisir que deux
    candidats.

    \TODO{Exemple de graphe obtenu à partir de l'exemple précédent (faire
    référence à ce graphe dans le paragraphe précédent)}

    Comparée à la sélection des $\{1..3\}$-grammes, utilisée dans plusieurs
    travaux, la méthode de \newcite{you2009refinedcandidateset} réduit
    significativement le nombre de candidats (d'environ 75~\%). Leurs
    expériences montrent cependant que leur méthode de sélection n'améliore pas
    significativement les performances des méthodes d'indexation par
    termes-clés.

    ~\\La sélection des termes-clés candidats est une étape quasi-systématique
    en indexation automatique par termes-clés~\cite{hasan2014state_of_the_art}.
    Parce qu'il ne s'agit pas du c\oe{}ur de la tâche, cette étape est encore
    très peu étudiée et donc très souvent réalisée par des méthodes très simples
    (n-grammes, \textit{chunks} nominaux et séquences noms-adjectifs).
    Toutefois, les travaux s'y intéressant s'accordent à dire que cette étape
    est critique et que l'enjeux réside dans la capacité à extraire un minimum
    de candidats sans dégrader la performance maximale pouvant être atteinte par
    une méthode d'indexation par termes-clés.

  %-----------------------------------------------------------------------------

  \section{Extraction automatique de termes-clés}
  \label{sec:main-state_of_the_art-automatic_keyphrase_extraction}
    L'extraction automatique de termes-clés est la tâche la plus utilisée pour
    faire de l'indexation par termes-clés. Contrairement à l'assignement de
    termes-clés, elle ne nécessite pas de vocabulaire contrôlé et requiert donc
    moins d'effort manuel de production de ressources. Les méthodes d'extraction
    automatique de termes-clés effectuent soit un ordonnancement par importance
    des termes-clés candidats vis-à-vis du contenu du document, soit une
    classification des termes-clés candidats entre les classes
    \og{}terme-clé\fg{} et \og{}non terme-clé\fg{}, puis extraient les $k$
    candidats jugés les meilleurs. L'ordonnancement est principalement réalisé
    avec une approche non supervisée et la classification est réalisée avec une
    approche supervisée qui requiert des données d'entraînement manuellement
    annotés en termes-clés.

    \subsection{Approche non supervisée}
    \label{subsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction}
      La plupart des méthodes non supervisées d'extraction de termes-clés
      ordonnent les termes-clés candidats d'après leur importance vis-à-vis du
      contenu du document (\TODO{exemple: l'expression PLOP est importante
      vis-à-vis d'un doc. parlant de BLABLABLA}). Du fait qu'elles
      ne requièrent pas de données d'entraînement, elles ont la particularité de
      s'abstraire du domaine et de la langue des documents qu'elles traitent.
      Les termes-clés candidats sont analysés avec des règles simples fondées
      sur des traits statistiques extraits du document ou d'un corpus de
      référence non annoté.

      De nombreuses méthodes sont proposées. Certaines se fondent uniquement
      sur des statistiques et d'autres les combinent avec des représentations
      plus complexes du document~: des groupes sémantiques et des
      graphes de cooccurrences de mots.

      Nous présentons ces différentes méthodes. Lorsque celles-ci ont été
      évaluées sur des données disponibles, nous comparons leur performance aux
      autres dans le
      tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison}. Les
      performances sont exprimées en terme de f1-mesure. Décrite dans la
      section~\ref{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation}
      (page~\pageref{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation}),
      cette mesure est exprimée entre 0 et 100 et est d'autant plus élevée si
      la méthode évaluée extrait un grand nombre de termes-clés positifs et très
      peu de termes-clés erronés.
      \begin{table}
        \resizebox{\linewidth}{!}{
          \begin{tabular}{l|c|c|c|c}
            \toprule
            \textbf{Méthode} & \textbf{\textsc{Duc}}~\textit{\cite{wan2008expandrank}} & \textbf{Inspec}~\textit{\cite{hulth2003keywordextraction}} & \textbf{\textsc{Nus}}~\textit{\cite{nguyen2007keadocumentstructure}} & \textbf{\textsc{Icsi}}~\textit{\cite{adam2003icsi}}\\
            \hline
            \textsc{Tf-Idf}$^*$ & 27,0 & 36,3 & \textbf{6,6} & \textbf{12,1}\\
            KeyCluster$^*$ & 14,0 & 40,6 & 1,7 & $~~$3,2\\
            TextRank$^*$ & $~~$9,7 & 33,0 & 3,2 & $~~$2,7\\
            SingleRank$^*$ & 25,6 & 35,3 & 3,8 & $~~$4,4\\
            ExpandRank$^*$ & 26,9 & 35,3 & 3,8 & $~~$4,3\\
            TopicalPageRank & 31,2 & --- & --- & ---\\
            WordTopic-MultiRank & \textbf{34,0} & \textbf{48,2} & --- & ---\\
            \bottomrule
          \end{tabular}
        }
        \caption[
          Comparaison des méthodes d'extraction automatique de termes-clés de la
          littérature, lorsque dix termes-clés sont extraits
        ]{
          Comparaison des méthodes d'extraction automatique de termes-clés de la
          littérature, lorsque dix termes-clés sont extraits. Les performances
          sont exprimées en terme de f1-mesure. \textsc{Duc} est
          une collection d'articles journalistiques, Inspec est une collection
          de résumés d'articles scientifiques, \textsc{Nus} est une collection
          d'articles scientifiques et \textsc{Icsi} est une collections de
          transcriptions textuelles de réunions. $^*$ indique que les résultats
          ont été reportés par \newcite{hassan2010conundrums}.
          \label{tab:state_of_the_art-unsupervised_methods_comparison}
        }
      \end{table}

      \subsubsection{Méthodes statistiques}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches}
        Les méthodes statistiques se fondent majoritairement sur le nombre de
        cooccurrences des termes-clés candidats (souvent assimilé à leur
        fréquence) ou sur le nombre de mots qui les composent, soit dans le
        document, soit dans un corpus de référence, ou bien les deux.

        ~\\\textsc{Tf-Idf}~\cite{jones1972tfidf} et Likey~\cite{paukkeri2010likey}
        sont deux méthodes similaires qui comparent le comportement d'une unité
        textuelle dans le document avec son comportement dans un corpus de
        référence. Elles font l'hypothèse qu'une unité textuelle a une forte
        importance vis-à-vis du document si elle y est très fréquente et si elle
        l'est peu dans le corpus de référence (\TODO{figure}), auquel cas elle
        est spécifique au document~:
        \begin{align}
          \text{\textsc{Tf-Idf}}(\text{\textit{ut}}) &= \textsc{Tf}(\text{\textit{ut}}) \times \log\left(\frac{N}{\textsc{Df}(\text{\textit{ut}})}\right) \label{math:tfidf}\\
          \notag\\
          \text{Likey}(\text{\textit{ut}}) &= \frac{\text{rang}_{\text{document}}(\text{\textit{ut}})}{\text{rang}_{\text{corpus}}(\text{\textit{ut}})} \label{math:likey}
        \end{align}\\
        Dans \textsc{Tf-Idf}, $\textsc{Tf}$ (\textit{Term Frequency}) représente
        le nombre d'occurrences d'une unité textuelle \textit{ut} dans le
        document, $\textsc{Df}$ (\textit{Document Frequency}) représente le
        nombre de documents du corpus de référence dans lesquels elle occure
        et $N$ est le nombre total de documents du corpus de référence. Plus le
        score \textsc{Tf-Idf} d'une unité textuelle est élevé, plus celle-ci est
        importante vis-à-vis du document. Dans Likey, le rang d'une unité
        textuelle dans le document et dans le corpus est obtenu à partir de son
        nombre d'occurrences, respectivement dans le document et dans le corpus.
        Plus le rapport entre ces deux rangs est faible, plus l'unité textuelle
        évaluée est importante dans le document.

        La nature linguistique de l'unité textuelle peut être fixée au mot ou au
        terme-clé candidat. Si la granularité fixée est le mot, il est courant
        de déterminer le score d'importance des termes-clés candidat en faisant
        la somme du score \textsc{Tf-Idf} ou Likey des mots qui les composent.
        Cependant, faire cette somme favorise les plus longues séquences de mots
        et fait monter dans le classement des candidats redondants qui possède
        un même mot important en commun (\TODO{exemple de redondance}).

        Méthode de pondération historique de \textsc{Ri}, \textsc{Tf-Idf} reste
        encore aujourd'hui l'une des méthodes de référence à laquelle il faut se
        comparer pour montrer la validité d'une nouvelle méthode non supervisée
        d'extraction de termes-clés. Les résultats du
        tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison}
        (page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison})
        montrent que \textsc{Tf-Idf} est encore compétitive vis-à-vis méthodes
        récentes.

        ~\\Okapi (ou \textsc{Bm}25) \cite{robertson1999okapi} est une mesure
        alternative à \textsc{Tf-Idf}. En Recherche d'Information (\textsc{Ri}),
        celle-ci est préférée à \textsc{Tf-Idf}. Bien que l'extraction
        automatique de termes-clés soit une discipline à la frontière entre le
        \textsc{Tal} et la \textsc{Ri}, la méthode de pondération Okapi n'a, à
        notre connaissance, pas été appliquée pour l'extraction de termes-clés.
        \newcite{claveau2012vectorisation} décrit Okapi comme un \textsc{Tf-Idf}
        prenant mieux en compte la longueur des documents. Cette dernière est
        utilisée pour normaliser le $\textsc{Tf}$
        ($\textsc{Tf}_{\textsc{Bm}25}$)~:
        \begin{align}
          \text{Okapi}(\text{\textit{ut}}) &= \textsc{Tf}_{\textsc{Bm}25}(\text{\textit{ut}}) \times \log\left(\frac{N - \textsc{Df}(\text{\textit{ut}}) + 0,5}{\textsc{Df}(\text{\textit{ut}}) + 0,5}\right) \label{math:okapi}\\
          \notag\\
          \textsc{Tf}_{\textsc{Bm}25}(\text{\textit{ut}}) &= \frac{\textsc{Tf}(\text{\textit{ut}}) \times (k_1 + 1)}{\textsc{Tf}(\text{\textit{ut}}) + k_1 \times \left(1 - b + b \times \frac{\textsc{Dl}}{\textsc{Dl}_{\text{moyenne}}}\right)} \label{math:tf_bm25}
        \end{align}\\
        où $k_1$ est une constante fixée à 2, où $b$ est une constante fixée à
        $0,75$, où $\textsc{Dl}$ (\textit{Document Length}) représente la
        longueur du document et où $\textsc{Dl}_{moyenne}$ représente la
        longueur moyenne des documents du corpus de référence.

        ~\\Le travail de \newcite{barker2000nounphrasehead} est un autre exemple
        d'utilisation de la fréquence pour extraire les termes-clés. Se reposant
        sur des fondements plus linguistiques, ils utilisent des groupes
        nominaux comme termes-clés candidats et tiennent compte à la fois de
        leur fréquence et de celle de leur tête nominale pour déterminer leur
        importance. Ils définissent un candidat important comme étant un
        candidat informatif et fréquent. L'informativité est ici assimilée à sa
        taille, en nombre de mots~: plus il contient de mots, plus il est
        informatif. Pour éviter les répétitions, jugées inesthétiques, de tels
        candidats informatifs sont parfois abrégés et leur fréquence réelle ne
        reflète pas leur usage. C'est pourquoi
        \newcite{barker2000nounphrasehead} proposent d'utiliser la fréquence de
        la tête des candidats pour décider s'ils doivent être extraits ou non.
        Leur méthode fonctionne en quatre étapes. Ils extraient tout d'abord les
        $n$ noms les plus fréquents, ils gardent uniquement les groupes nominaux
        contenant un de ces noms, puis les ordonnent selon le produit de leur
        taille et de leur fréquence réelle. Enfin, ils extraient les $k$ groupes
        nominaux de meilleur rang.

        ~\\\newcite{tomokiyo2003languagemodel} tentent aussi de vérifier
        statistiquement deux propriétés que doit respecter un terme-clé candidat
        pour être extrait~:
        \begin{itemize}
          \item{informativité : un terme-clé doit capturer au moins une des
                idées essentielles exprimées dans le document analysé;}
          \item{grammaticalité : un terme-clé doit être bien formé
                syntaxiquement.}
        \end{itemize}
        Pour vérifier ces deux propriétés, trois modèles de langue
        ($\textsc{Ml}$) sont utilisés (cf. figure~\ref{fig:klml}). Les deux
        premiers modèles, l'un uni-gramme, $\textsc{Ml}_{\text{document}}^1$,
        l'un n-gramme, $\textsc{Ml}_{\text{document}}^N$, sont construits à
        partir du document. Le dernier, un modèle n-gramme,
        $\textsc{Ml}_{\text{référence}}^N$, est construit à partir d'un corpus
        de référence, c'est le modèle de référence. Il fournit une vision
        globale de la distribution des n-grammes dans la langue (français,
        anglais, etc.). De ce fait, plus la probabilité d'un terme-clé candidat
        selon le modèle n-gramme du document diverge positivement par rapport à
        sa probabilité selon le modèle de référence, plus il respecte la
        propriété d'informativité (cf. équation~\ref{math:informativeness}). De
        manière similaire, plus la probabilité d'un terme-clé candidat selon le
        modèle n-gramme du document diverge positivement par rapport à sa
        probabilité selon le modèle uni-gramme du document, plus il respecte la
        propriété de grammaticalité (cf. équation~\ref{math:phraseness}). La
        divergence est exprimée en terme de coût avec la divergence
        Kullback-Leibler (cf. équation \ref{math:kullbackleibler}). Les
        termes-clés candidats sont ordonnés dans l'ordre décroissant de la somme
        des scores d'informativité et de grammaticalité, puis les $k$
        termes-clés candidats de meilleur rang sont extraits comme termes-clés.
        \begin{align}
          \text{informativité}(\text{\textit{candidat}}) &= \textsc{Kl}_{\text{\textit{candidat}}}(\textsc{Ml}_{\text{document}}^{N} \| \textsc{Ml}_{\text{référence}}^{N}) \label{math:informativeness}\\
          \notag\\
          \text{grammaticalité}(\text{\textit{candidat}}) &= \textsc{Kl}_{\text{\textit{candidat}}}(\textsc{Ml}_{\text{document}}^{N} \| \textsc{Ml}_{\text{document}}^{1}) \label{math:phraseness}\\
          \notag\\
          \textsc{Kl}_{\text{\textit{candidat}}}(\textsc{Ml} \| \textsc{Ml}') &= \textsc{Ml}(\text{\textit{candidat}}) \log \frac{\textsc{Ml}(\text{\textit{candidat}})}{\textsc{Ml}'(\text{\textit{candidat}})} \label{math:kullbackleibler}\\
          \notag\\
          \textsc{Ml}(\text{\textit{candidat}} = m_1\ m_2\ \dots\ m_k) &= \prod_{i = 1}^k P(m_i | m_{i - (N - 1)} m_{i - ((N - 1) - 1)} \dots m_{i - 1}) \notag
        \end{align}
        \begin{figure}
          \centering

          \begin{tikzpicture}
            \node [fill=@verticalgreen] (ml_n_ref) {$\textsc{Ml}_{\textnormal{référence}}^{N}$};
            \node [fill=@verticalgreen, right=of ml_n_ref, xshift=1em] (ml_n_doc) {$\textsc{Ml}_{\textnormal{document}}^{N}$};
            \node [fill=@verticalgreen, below=of ml_n_doc] (ml_1_doc) {$\textsc{Ml}_{\textnormal{document}}^{1}$};

            \path [<->] (ml_n_ref) edge node [above, yshift=.75em] {informativité} (ml_n_doc);
            \path [<->] (ml_n_doc) edge node [right, xshift=.75em] {grammaticalité} (ml_1_doc);
          \end{tikzpicture}

          \caption{Illustration des deux propriétés d'informativité et de
                   grammaticalité induites entre trois modèles de
                   langues~\cite{tomokiyo2003languagemodel}
                   \label{fig:klml}}
        \end{figure}

        \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches:ilp}
        ~\\Tout comme \newcite{tomokiyo2003languagemodel},
        \newcite{ding2011binaryintegerprogramming} tentent de définir des
        propriétés visant à affiner l'extraction de termes-clés. Ils expriment leurs propriétés sous
        la forme de contraintes dans un système d'optimisation (programmation
        par les entiers) qui explore l'espace des solutions possibles (toutes
        les combinaisons de mots à extraire). Les contraintes sont les
        suivantes~:
        \begin{itemize}
          \item{taille: les termes-clés extraits ne doivent pas être en nombre
                supérieur à $k$~;}
          \item{couverture : les termes-clés doivent couvrir le plus possible de
                sujets abordés dans le document~;}
          \item{cohérence : les mots des termes-clés doivent être cohérents
                entre eux.}
        \end{itemize}
        La couverture de chaque sujet d'une solution est calculée avec le modèle
        \textit{Latent Dirichlet Allocation} (\textsc{Lda})~\cite{blei2003lda}.
        \textsc{Lda} est un modèle probabiliste qui permet d'expliquer des
        ensembles d'observations (ici, des mots) avec des ensembles non observés
        (ici, des sujets), eux-mêmes définis par des distributions de
        probabilités calculées à partir de données (ici, des documents). Depuis
        le modèle \textsc{Lda}, \newcite{ding2011binaryintegerprogramming}
        extraient la probabilité conditionnelle des mots des termes-clés d'une
        solution sachant chaque sujet, ce qui indique quels mots de la solution
        sont importants pour chaque sujet. L'importance des mots des termes-clés
        doit excéder un seuil donné pour chaque sujet afin que la contrainte de
        couverture soit respéctée pour la solution. La contrainte de cohérence
        est calculée entre chaque paire de mots de la solution. Si deux mots
        cooccurrent plus que selon un seuil donné, alors ceux-ci peuvent être
        présents dans la même solution, sinon la solution n'est pas
        satisfaisante. Ces deux contraintes réduisent le champ des possibilités.
        Il faut ensuite trouver quel ensemble de termes-clés parmi les solutions
        satisfaisantes est le meilleur. Pour cela, un score d'importance des
        mots est calculé et l'ensemble de termes-clés pour lequel la somme du
        score d'importance des mots est la plus élevée est extrait. Ce score est
        obtenue avec une combinaison linéaire du score \textsc{Tf-Idf} du mot,
        d'un \og{}bonus\fg{} s'il occure dans le titre du document et d'un autre
        \og{}bonus\fg{} s'il occurre dans sa première phrase~:
        \begin{align}
          \textnormal{importance}(\textnormal{mot}) &= \alpha \times\frac{\mathlarger\sum_{d \in D} \textnormal{\textsc{Tf-Idf}}_d(\textnormal{mot})}{|D|} + \beta \times \mu_\textnormal{mot} + \gamma \times \nu_\textnormal{mot}\\
          \mu_\textnormal{mot} &=\left\{\begin{array}{ll}\mu, & \textnormal{si mot} \in T\\0, & \textnormal{sinon}\end{array}\right.\notag\\
          \nu_\textnormal{mot} &=\left\{\begin{array}{ll}\nu, & \textnormal{si mot} \in P\\0, & \textnormal{sinon}\end{array}\right.\notag
        \end{align}
        où $\alpha$, $\beta$ et $\gamma$ sont les coefficients associés à chaque
        score ($\alpha + \beta + \gamma = 1$) et où $\mu$ et $\nu$ sont les
        \og{}bonus\fg{} attribués si le mot occurre dans le titre $T$ ou dans la
        première phrase $P$ du document, respectivement.

        Paramétrée à l'aide de 50 articles journalistiques et évaluée sur 100
        autres, la méthode de \newcite{ding2011binaryintegerprogramming} atteint
        environ 70~\% de précision en moyenne, c'est-à-dire en moyenne quatre
        termes-clés corrects sur les six demandés, soit une performance très
        satisfaisante.

      \subsubsection{Méthodes par groupement}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-clustering_approaches}
        Les méthodes par groupement utilisent des groupes d'unités textuelles
        partageant une ou plusieurs caractéristiques (similarité lexicale,
        similarité sémantique, etc.).

        ~\\\newcite{matsuo2004wordcooccurrence} groupent les termes-clés
        candidats les plus fréquents qui cooccurrent (dans la phrase) avec les
        mêmes autres candidats avec une fréquence comparable (nous parlons
        abusivement de lien sémantique) et extraient les termes-clés en
        analysant la fréquence de cooccurrences des candidats avec ces groupes.
        Leur hypothèse est qu'un terme-clé candidat est plus vraisemblemant un
        terme-clé si sa fréquence de cooccurrence avec les candidats de chaque
        groupe est plus importante que selon toute probabilité. Dans un premier
        temps, ils estiment la fréquence de cooccurrence de chaque candidat avec
        chaque groupe, puis, dans un second temps, ils mesurent le biais
        statistique $\chi^2$ entre leur estimation et la fréquence réelle
        observée (cf équation~\ref{math:chi2}). Pour estimer la fréquence de
        cooccurrences d'un candidat avec ceux d'un groupe, ils supposent qu'un
        terme-clé candidat apparaissant dans de longues phrases à le plus de
        chance de cooccurrer avec un candidat d'un des groupes. Ainsi, soit
        $n_t$ le nombre de termes-clés candidats présents dans les phrases où le
        candidat étudié apparait et $p_g$ le nombre de candidats présents dans
        les phrases ou un candidat du groupe $g$ apparaît, alors la fréquence
        attendue entre le candidat étudié et le groupe $g$ est représenté par le
        produit $n_tp_g$.
        \begin{align}
          \chi^2(\text{\textit{candidat}}) = \sum_{g} \frac{(\text{fréquence}(\text{\textit{candidat}}, g) - n_tp_g)^2}{n_tp_g} \label{math:chi2}
        \end{align}
        
        Lors de leurs expériences, les auteurs se sont aperçus que certains
        candidats peuvent être sémantiquement liées à des candidats fréquents
        dans un domaine plus général que celui du document. En supposant que ces
        cas spéciaux soient ceux ayant le plus fort biais statistique, ils
        suppriment du $\chi^2$ l'argument maximum de la sommation~:
        \begin{align}
          \chi^2{'}(\text{\textit{candidat}}) = \chi^2 - \max_{g}\left\{\frac{(\text{fréquence}(\text{\textit{candidat}}, g) - n_tp_g)^2}{n_tp_g}\right\}
        \end{align}
        Les termes-clés extraits sont les $k$ termes-clés candidats ayant le
        plus fort biais statistique mesuré par $\chi^2{'}$.

        ~\\Dans l'algorithme KeyCluster, \newcite{liu2009keycluster} utilisent
        aussi un groupement sémantique, mais dans leur cas, ils ne considèrent
        que les mots du document, mots d'un antidictionnaire exclus. Le mot le
        plus central de chaque groupe est sélectionné comme mot de référence et
        sert à l'extraction des termes-clés: chaque terme-clé candidat contenant
        au moins un mot de référence est extrait comme terme-clé. Cette méthode
        présente l'avantage d'offrir une bonne couverture des sujets abordés
        dans un document, car tous les groupes sémantiques sont représentés par
        au moins un terme-clé. Cependant, aucune pondération n'est proposée pour
        ordonner les termes-clés. De plus, \newcite{hassan2010conundrums} ont
        montré que KeyCluster est moins performant que \textsc{Tf-Idf}
        (cf tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).

      \subsubsection{Méthodes à base de graphe}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        Les approches à base de graphe sont actuellement les plus populaires.
        Utilisés dans de nombreuses applications du
        \textsc{Tal}~\cite{kozareva2013textgraphs}, les graphes ont l'avantage
        de présenter de manière simple et efficace le document, par ses unités
        textuelles et les relations qu'elles entretiennent.

        ~\\\newcite{mihalcea2004textrank} proposent TextRank, une méthode
        d'ordonnancement d'unités textuelles à partir d'un graphe pour le résumé
        automatique et l'extraction de termes-clés. Pour l'extraction de
        termes-clés, les n\oe{}uds du graphe sont les mots du document et les
        arêtes qui les connectent représentent leurs relations d'adjacence dans
        le document, dans une fenêtre de deux mots (\TODO{figure}). Un score
        d'importance est calculé pour chaque mot à partir de l'algorithme
        PageRank~\cite{brin1998pagerank}. PageRank est un algorithme de marche
        aléatoire (\textit{random walk})~: un marcheur aléatoire parcours le
        graphe de mot en mot en se déplaçant toujours sur un mot qui cooccurre
        avec le mot courant. Le résultat du parcours du marcheur permet de
        déduire l'importance de chaque mot d'après le principe de la
        recommandation (du vote)~:  un mot est d'autant plus important s'il
        cooccurre avec un grand nombre de mots (parce qu'il est beaucoup visité
        par le marcheur) et si les mots avec lesquels il cooccurre sont eux
        aussi importants (parce qu'il a plus de chance d'être visité par le
        marcheur). Les mots les plus importants sont considérés comme des
        mots-clés, ils sont marqués dans le document et les plus longues
        séquences de mots-clés adjacents sont extraites en tant que termes-clés.
      
        Soit le graphe de cooccurrences de mots non orienté $G = (N, A)$, où les
        n\oe{}uds $N$ représentent les mots du documents, et où les arêtes $A$
        les connectent lorsqu'ils cooccurrent dans le document. L'importance de
        chaque mot $n_i$ est obtenue itérativement selon la formule TextRank
        suivante~:
        \begin{align}
          S(n_i) &= (1 - \lambda) + \lambda \times \sum_{n_j \in A(n_i)} \frac{S(n_j)}{|A(n_j)|} \label{math:textrank}
        \end{align}
        où $A(n_i)$ est l'ensemble des n\oe{}uds connectés au n\oe{}ud $n_i$ et
        où $\lambda$ est un facteur d'atténuation. Nombre réel défini entre 0 et
        1, ce dernier peut être considéré comme la probabilité pour que le
        n\oe{}ud $n_i$ soit important d'après le principe de la recommandation.
        \newcite{brin1998pagerank} suggèrent 0,85 comme valeur par défaut de
        $\lambda$. Selon eux, cette valeur est un bon compromis entre la
        précision des résultats et la vitesse de convergence de l'algorithme.

        Bien qu'intéressant, de par son intuitivité,
        \newcite{hassan2010conundrums} ont montré que TextRank est moins
        performant que \textsc{Tf-Idf} (cf
        tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).

        ~\\\newcite{wan2008expandrank} modifient TextRank et proposent
        SingleRank. Dans un premier temps, leur méthode augmente la précision de
        l'ordonnancement en utilisant une fenêtre de cooccurrences élargie
        empiriquement à dix mots et en pondérant les arêtes par le nombre de
        cooccurrences entre les deux mots qu'elles connectent. La pondération,
        notée $\textnormal{poids}(n_j, n_i)$, sert à ajuster l'importance du mot
        $n_i$ acquise à partir de sa recommandation par le mot $n_j$ (cf.
        équation~\ref{math:singlerank}). Dans un second temps, les termes-clés
        ne sont plus générés à partir des séquences de mots-clés dans le
        document, mais ordonnés à partir de la somme du score d'importance des
        mots qui les composent. Comparé à TextRank dans les expériences de
        \newcite{hassan2010conundrums} réalisées avec quatre collections de
        données différentes, SingleRank donne de meilleurs résultats
        (cf tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison}).
        Ils restent cependant plus faibles que ceux de
        \textsc{Tf-Idf}.
        \begin{align}
          S(n_i) &= (1 - \lambda) + \lambda \times \sum_{n_j \in A(n_i)} \frac{\text{poids}(n_j, n_i) \times S(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} \text{poids}(n_j, n_k)} \label{math:singlerank}
        \end{align}

        ~\\Toujours dans le but d'améliorer l'efficacité de l'ordonnancement
        proposé par \newcite{mihalcea2004textrank}, \newcite{wan2008expandrank}
        proposent ExpandRank. ExpandRank étend SingleRank en utilisant des
        documents similaires au document analysé d'après la mesure de similarité
        vectorielle cosinus. Faisant l'hypothèse que ces documents similaires
        fournissent des informations supplémentaires relatives aux mots du
        document et aux relations qu'ils entretiennent, ExpandRank utilise les
        relations de cooccurrences observées dans les documents similaires pour
        ajouter et renforcer des arêtes dans le graphe. Dans leurs expériences
        réalisée avec une collection de 308 articles journalistiques,
        \newcite{wan2008expandrank} obtiennent des résultats au-delà de ceux de
        SingleRank. Ces résultats n'ont cependant jamais pu être reproduit et
        les expériences de \newcite{hassan2010conundrums} ne montrent
        globalement pas d'amélioration vis-à-vis de SingleRank (cf
        tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).
        %Toutefois, ses performances sont fortement liées à la
        %disponibilité de documents similaires. Leur usage peut aussi ajouter et
        %renforcer des connexions qui ne devraient pas l'être s'ils ne sont pas
        %suffisamment similaires. Pour pallier ce problème, les auteurs pondèrent
        %l'impact des documents similaires à partir leur degré de similarité avec
        %le document.

%        ~\\\newcite{tsatsaronis2010semanticrank} tentent eux aussi d'améliorer
%        TextRank. Dans leur méthode, ils créent et pondèrent une arête entre
%        deux mots si et seulement si ceux-ci sont sémantiquement liés dans
%        WordNet~\cite{miller1995wordnet} ou dans
%        Wikipedia~\cite{milne2008wikipediasemanticrelatedness} (cf.
%        équation~\ref{math:semanticrank}). WordNet est une base de données
%        lexicale représentée par un graphe de mots connectés à leurs synonymes.
%        Chaque mot connecté à un autre est considéré comme un des sens possibles
%        de ce dernier. À partir de cette représentation,
%        \newcite{tsatsaronis2010semanticrank} déterminent toutes les paires de
%        sens $P_{ij}$ possibles, ainsi que tous les chemins $C_{i, j}$ possible
%        pour atteindre un sens du mot $n_j$ à partir d'un sens du mot $n_i$. Le
%        score de similarité sémantique avec WordNet est obtenu en trouvant le
%        couple paire sémantique/chemin sémantique pour lequel le produit des
%        mesures sémantiques \textit{Semantic Compactness Measure}
%        ($\textsc{Scm}$) et \textit{Semantic Path Elaboration} ($\textsc{Spe}$),
%        introduites par \newcite{tsatsaronis2010textrelatedness}, est le plus
%        élevé (cf. équation \ref{math:wordnetsemanticrelatedness}). Dans le cas
%        où l'un des termes-clés candidats n'est pas présent dans WordNet, la
%        similarité sémantique est calculée avec les données de Wikipédia (cf.
%        équation~\ref{math:wikipediasemanticrelatedness}).
%        \begin{align}
%          \text{poids}_{j, i} &= \left\{\begin{array}{ll}
%            1 & \text{si $n_i = n_j$}\\
%            \text{Sim}_{WN}(n_i, n_j) & \text{sinon, si $n_i, n_j \in \text{WordNet}$}\\
%             \text{Sim}_{W}(n_i, n_j) &  \text{sinon, si $n_i, n_j \in \text{Wikipedia}$}\\
%            0 & \text{sinon}
%          \end{array}\right. \label{math:semanticrank}\\
%          \notag\\
%          \text{Sim}_{WN}(n_i, n_j) &= \max_{p \in P_{i, j}}\left\{\max_{c \in C_{i, j}}\left\{\textsc{Scm}(p, c) \times \textsc{Spe}(p, c)\right\}\right\} \label{math:wordnetsemanticrelatedness}\\
%          \notag\\
%          \text{Sim}_{W}(n_i, n_j) &= \frac{\log(\max(|\text{art}(i)|, |\text{art}(j)|)) - \log(|\text{art}(i) \cup \text{art}(j)|)}{\log(|\text{Wikipedia}|) - \log(\min(|\text{art}(i)|, |\text{art}(j)|))} \label{math:wikipediasemanticrelatedness}\\
%          \notag\\
%          \text{art}(i) &= \left\{\text{\textit{article}} \in \text{Wikipedia}\ |\ n_i \in \text{\textit{article}}\right\} \notag
%        \end{align}
%
%        Cette modification seule donne de moins bons résultats que TextRank.
%        Toutefois, elle améliore les résultats en combinaison avec un
%        ordonnancement biaisé par le \textsc{Tf-Idf} des mots (cf
%        équation~\ref{math:apw}) ou avec un ordonnancement dont le facteur
%        $\lambda$ est  propre à chaque mot (cf équation~\ref{math:ppr}). Ce
%        dernier est calculé selon l'apparition ou non du mot dans le titre du
%        document.
%        \begin{align}
%          S_{\text{\textsc{Tf-Idf}}}(n_i) &= \frac{1}{2} \times \left(\frac{S(n_i)}{\mathlarger{\max}_{n_j \in N}(S(n_j))} + \frac{\text{\textsc{Tf-Idf}}(t_i)}{\mathlarger{\max}_{n_j \in N}(\text{\textsc{Tf-Idf}}(t_j))}\right) \label{math:apw}\\
%          \notag\\
%          S_{\lambda}(n_i) &= (1 - \lambda_i) + \lambda_i \times \sum_{n_j \in A(n_i)} \frac{\text{poids}_{j, i} \times S_{\lambda}(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} p_{j, k}} \label{math:ppr}
%        \end{align}

        ~\\\newcite{liu2010topicalpagerank} tentent aussi d'améliorer
        SingleRank. Ils proposent
        TopicalPageRank (\textsc{Tpr}), une méthode qui cherche cette fois-ci à augmenter
        la couverture du document par les termes-clés extraits. Pour ce faire,
        ils détectent les sujets du document et ordonnent les mots en fonction
        de chaque sujet (\TODO{figure}). À l'aide du modèle
        \textsc{Lda}~\cite{blei2003lda}, ils ajustent chaque ordonnancement avec
        la probabilité conditionnelle d'un sujet donné sachant chaque mot
        (cf. équation~\ref{math:topicalpagerank}), puis donnent plus
        d'importance aux candidats dont les mots ont la plus forte importance
        (le meilleur rang) selon les sujets les plus probables dans le document
        (cf. équation~\ref{math:topicalpagerankfinalscore}).
        \begin{align}
          S(n_i, \text{\textit{sujet}}) &= (1 - \lambda) \times p(\text{\textit{sujet}} | n_i) + \lambda \times \sum_{n_j \in A(n_i)} \frac{\textnormal{poids}(n_j, n_i) \times S(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} \textnormal{poids}(n_j, n_k)} \label{math:topicalpagerank}\\
          \textsc{Tpr}(\text{\textit{candidat}}) &= \mathlarger{\sum}_{\text{\textit{sujet}}} \left[p(\text{\textit{sujet}} | \text{\textit{document}}) \times \sum_{n \in \text{\textit{candidat}}} \text{rang}_{\text{\textit{sujet}}}(n)\right] \label{math:topicalpagerankfinalscore}
        \end{align}

        Contrairement aux précédentes méthodes à base de graphe que nous avons
        présenté, TopicalPageRank améliore \textsc{Tf-Idf} (cf
        tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).
        Cette amélioration est significative avec un taux de confiance de 95~\%,
        ce qui signifie qu'elle n'est pas due à un choix des données
        d'évaluation favorable à TopicalPageRank.

        ~\\Dans la continuité du travail de \newcite{liu2010topicalpagerank},
        \newcite{zhang2013wordtopicmultirank} proposent WordTopic-MultiRank.
        WordTopic-MultiRank ajoute les sujets de \textsc{Lda} aux n\oe{}uds du
        graphe de cooccurrences et effectue un seul ordonnancement, qui tient
        compte de tous les sujets en même temps. Cet ordonnancement est réalisé
        conjointement entre les mots et les sujets, de sorte que~:
        \begin{itemize}
          \item{un sujet est d'autant plus important s'il est connecté à un
                grand nombre de mots importants~;}
          \item{un mot est d'autant plus important s'il cooccurre avec un grand
                nombre de mots importants et s'il est connecté à un grand nombre
                de sujets importants.}
        \end{itemize}
        Comme pour SingleRank et TopicalPageRank, les termes-clés candidats sont
        ensuite ordonnés d'après le score d'importance des mots qu'ils
        contiennent.

        L'ordonnancement conjoint (\textit{co-ranking}) à patir de modèles à
        base de graphe est une technique qui commence à susciter de l'intéret en
        \textsc{Tal}~\cite{wan2011corankingsummarization,yan2012corankingtweetrecommendation,liu2014corankingopinionmining}.
        \newcite{zhang2013wordtopicmultirank} sont les premiers à l'appliquer à
        l'extraction de termes-clés. Cette approche est intéressante, car elle
        tient compte à la fois du contexte local du mot (le document) et de son
        contexte global (la collection de données utilisée par \textsc{Lda}).

        Comparés aux résultats de TopicalPageRank,
        \newcite{zhang2013wordtopicmultirank} montrent que l'ordonnancement
        conjoint des mots et des sujets est légèrement plus performant que la
        combinaison de multiples ordonnancements influencés par chaque sujet
        (cf tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).

      \subsubsection{Bilan des méthodes non supervisées}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-bilan}
        Les méthodes non supervisées d'extraction de termes-clés utilisent des
        techniques très différentes, mais reposent toutes sur des statistiques
        simples~: la fréquence d'occurrence des mots dans le document, leur
        fréquence documentaire et la fréquence de cooccurrence entre eux. Les
        méthodes puremenet statistiques mises à part, c'est le mode de
        représentation du document et son analyse qui différencie les méthodes
        non-supervisées.
        
        Le graphe est le mode de représentation le plus utilisé actuellement.
        Représentant les relations de cooccurrence entre les mots du document,
        il est analysé à l'aide d'un algorithme de marche aléatoire qui attribue
        un score d'importance à chaque n\oe{}ud (mot). Ce graphe et la manière
        dont il est analysé sont très intuitifs, mais nous notons quelques
        défauts. Nous reprochons aux méthodes actuelles de
        modéliser le document par ses mots et leurs relations, et donc de
        déterminer l'importance des mots uniquement, au lieu de celle des
        termes-clés candidats. Par ailleurs, la question de la dispersion
        d'information dans le graphe n'est jamais abordée. Certains mots du
        documents ne sont-ils pas des synonymes ou ne représentent-ils pas le
        même sujet~? Ne faut-il pas mutualiser certains n\oe{}uds afin d'éviter
        de disperser des informations relatives à un même sujet~?

    \subsection{Approche supervisée}
    \label{subsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction}
      Les méthodes supervisées apprennent principalement à classer les
      termes-clés en tant que \og{}terme-clé\fg{} ou \og{}non terme-clé\fg{}.
      Leur apprentissage se fait à partir d'une collection d'apprentissage, ou
      d'entraînement, dont les documents sont manuellement indexés par des
      termes-clés. Les termes-clés candidats sont sélectionnés dans ces
      documents et servent d'exemples, lorsqu'il font partie de l'indexation
      manuelle (de référence), sinon, de contre-exemples.

      Les méthodes proposées emploient des classifieurs. Elles diffèrent
      selon ces classifieurs et les caractéristiques discriminantes (traits)
      qu'elles utilisent. Nous présentons ces différentes méthodes en les
      groupant par classifieur et les présentons en soulignant les traits
      choisis.

      \subsubsection{Classifieurs probabilistes}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-probabilistic_models}
        Les classifieurs probabilistes utilisent des distributions de
        probabilités de divers traits. Pour l'extraction des termes-clés d'un
        document, ces distributions sont combinées pour déterminer un score de
        vraisemblance de chaque terme-clé candidat en tant que
        \og{}terme-clé\fg{}.

        ~\\\textsc{Kea}~\cite{witten1999kea} est la méthode d'extraction de
        termes-clés la plus populaire. Elle effectue une classification naïve
        bayesienne pour attribuer le score de vraisemblance de chaque terme-clé
        candidat. Elle combine les distributions probabilistes de deux traits~:
        la première position du candidat dans le document et son poids
        \textsc{Tf-Idf}. L'intuition de \newcite{witten1999kea} est que les
        termes-clés ont une certaine importance vis-à-vis du document (leur
        poids \textsc{Tf-Idf}) et qu'ils font leur première apparition dans des
        zones similaires du document.
          Appris sur une collection de

        ~\\\textsc{Kea} est une approche très simple qui considère tous les
        traits comme indépendants (principe de la classification naïve
        bayésienne). Sa simplicité et ses bonnes performances ont suscité un
        grand intéret, il en existe de nombreuses variantes. C'est le cas de la
        méthode de \newcite{frank1999keafrequency}, qui utilise comme trait
        supplémentaire le nombre de fois qu'un terme-clé candidat est un
        exemple, c'est-à-dire un terme-clé de l'indexation manuelle d'un
        document, parmi les documents de la collection d'entraînement. Cette
        méthode donne un plus fort score de vraisemblance aux candidats déjà
        utilisés comme termes-clés. Elle améliore les performances de
        \textsc{Kea}, mais nécessite plus de données d'apprentissage.
        
        ~\\\newcite{turney2003keacoherence} reprend lui aussi \textsc{Kea}.
        Estimant, comme \newcite{ding2011binaryintegerprogramming}, que les
        termes-clés d'un document doivent être cohérent entre eux (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches:ilp}),
        il ajoute une deuxième classification naïve bayesienne après celle de
        \textsc{Kea}. La première classification sert à ordonner les candidats
        selon leur vraisemblance et la deuxième attribue un nouveau score de
        vraisemblance aux candidats, de sorte que les $L$ meilleurs candidats
        aient un meilleur score de vraisemblance s'ils ont un fort lien
        sémantique avec un ou plusieurs candidat(s) parmi les $K$ meilleurs ($K
        < L$). La force du lien sémantique est représenté par deux scores (soit
        $2 \times K$ traits)~: le nombre de pages Web contenant les deux
        candidats et le nombre de titres de pages Web contenant les deux
        candidats.

        ~\\\newcite{nguyen2007keadocumentstructure} améliorent \textsc{Kea} pour
        l'extraction de termes-clés à partir d'articles scientifiques. Faisant
        l'hypothèse que les termes-clés n'ont pas une répartition homogène dans
        les sections d'un article scientifique, ils notent les occurrences des
        termes-clés candidats dans les sections génériques d'un article
        scientifique (résumé, introduction, motivations, état de l'art et
        conclusion), puis utilisent le vecteur d'occurrences ainsi construit
        comme trait supplémentaire. De cette manière, les termes-clés
        apparaissant dans les sections les plus susceptibles de contenir des
        termes-clés ont un score de vraisemblance plus élevé.
        
        ~\\\newcite{caragea2014citationenhancedkeyphraseextraction} utilisent
        eux aussi un classifieur naïf bayesien. Leur méthode repose sur le même
        constat que \newcite{wan2008expandrank}~: l'extraction de termes-clés
        peut bénéficier des informations extraites dans des documents en liens
        avec le document à partir duquel les termes-clés doivent être extraits
        (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}).
        Travaillant avec des articles scientifiques,
        \newcite{caragea2014citationenhancedkeyphraseextraction} utilisent le
        réseau de citations des documents afin de déterminer leur influence sur
        les autres documents et inversement. En plus des traits existant, ils
        ajoutent un \textsc{Tf-Idf} calculés à partir de la fréquence de chaque
        candidat dans les contextes citationnels, ainsi que deux traits binaires
        indiquant si le candidat apparait dans une phrase du document qui cite
        un autre document ou s'il apparait dans une phrase, d'un autre document,
        qui cite le document. Bien que leur méthode obtient de meilleures
        performances que \textsc{Kea}, les auteurs mettent en évidence un défaut
        de leur approche. Considérant les contextes citationnels, un document
        qui vient d'être publié ne peut pas avoir été cité par d'autres articles
        et leur extraction de termes-clés pour un document tend à s'améliorer
        dans le temps.

        ~\\Contrairement à \newcite{witten1999kea}, qui utilisent un classifieur
        naïf bayésien et considèrent que tous les traits sont indépendants,
        \newcite{sujian2003maximumentropy} proposent une méthode utilisant un
        classifieur d'entropie maximale. Ce classifieur cherche parmi plusieurs
        distributions (une pour chaque trait) laquelle a la plus forte entropie.
        La distribution ayant la plus forte entropie est par définition celle
        qui contient le moins d'informations, ce qui la rend moins arbitraire et
        donc plus appropriée pour l'extraction automatique de termes-clés.
        Chaque trait se voit donc attribuer un poids, de sorte que les traits
        les moins arbitraires ont le plus de poids dans la classification. En
        plus des traits cités pour les méthodes précédentes, et à l'instar de
        \newcite{nguyen2007keadocumentstructure}, ils tirent parti d'autres
        traits liés à la nature des documents qu'ils traitent. Ainsi, pour des
        articles journalistiques ils utilisent leur type (information, sport,
        etc.) et la catégorie d'entité nommée des candidats s'ils en sont une
        (personne, pays, organisme, etc.).

        ~\\Plus récemment, le travail de \newcite{zhang2008crfkeywordextraction}
        montre l'applicapilité d'un \textsc{Crf} (\textit{Conditional Random
        Field}) à la tâche d'extraction de termes-clés. Ce classifieur a
        l'intéressante capacité à prédire des séquences de classes, soit à
        étiqueter tout un document en donnant les classes suivantes pour chaque
        mot~: \og{}terme-clé\fg{}, \og{}début d'un terme-clé\fg{}, \og{}partie
        d'un terme-clé\fg{} et \og{}non terme-clé\fg{} (\TODO{etiqueter
        l'exemple fil rouge}). \newcite{zhang2008crfkeywordextraction}
        reprend les traits présentés précédemment (\textsc{Tf-Idf}, première position,
        section d'article scientifique, etc.) et y ajoute le contexte de
        chaque mot. Nous trouvons cette notion de contexte dans les méthodes non
        supervisées à base de graphe (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}),
        mais il s'agit de la première fois que nous trouvons celle-ci dans une
        méthode supervisée. Le fonctionnement particulier du \textsc{Crf} se
        prête plus à l'utilisation du contexte que les autres classifieurs.

      \subsubsection{Arbres de décision}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-decision_trees}
        Les arbres de décision sont des classifieurs dont les branches
        représentent des tests sur des traits des candidats. Ces tests routent
        les candidats vers les feuilles de l'arbre représentant leur classe
        respective (\og{}terme-clé\fg{} ou \og{}non terme-clé\fg{}).

        ~\\Dans son article sur l'apprentissage pour l'extraction automatique de
        termes-clés, \newcite{turney1999learningalgorithms} entraîne plusieurs
        arbres de décision (technique de \textit{random forest}) et réduit la
        tâche d'extraction de termes-clés à un vote. Les arbres de décision
        classent indépendemment chaque candidat et les candidats majoritairement
        classés \og{}terme-clé\fg{} sont extraits comme termes-clés. Parmi les
        nombreux traits qu'utilise \newcite{turney1999learningalgorithms}, les
        plus novateurs sont des traits binaires qui visent des catégories
        grammaticales précises~: \og{}contient un nom propre~?\fg{},
        \og{}contient un verbe usuel~?\fg{} et \og{}se termine par un
        adjectif~?\fg{}. Contrairement aux autres travaux, celui de
        \newcite{turney1999learningalgorithms} est aussi l'un des seuls à
        décliner les traits sur deux niveaux de granularité~: le candidat (grain
        expression) et chacun de ses mots (grain mot).

        ~\\\newcite{ercan2007lexicalchains} utilisent eux aussi des arbres de
        décision pour extraire les termes-clés. Les termes-clés sont ici
        restreints aux mots-clés. L'aspect novateur de leur méthode est l'usage
        de chaînes lexicales pour la définition de nouveaux traits
        discriminants. Une chaîne lexicale est un graphe de mots liés entre eux
        hiérarchiquement (cf. figure~\ref{fig:lexical_chain}).
        \newcite{ercan2007lexicalchains} tiennent compte des relations
        hiérarchiques de méronymie\footnote{Méronyme~: mot dont le signifié est
        une sous-partie de celui d'un autre mot, son holonyme. Par exemple,
        \og{}bras\fg{} est un méronyme de
        \og{}corps\fg{}.}/holonymie\footnote{Holonyme~: mot dont le signifié est
        composé de celui d'un autre mot, son méronyme.},
        d'hyponymie\footnote{Hyponyme~: mot dont le signifié est
        plus spécifique que celui d'un autre mot, son
        hyperonyme.}/hyperonymie\footnote{Hyperonyme~: mot dont le sygnifié est
        plus général que celui d'un autre mot, son hyponyme.} et de synonymie,
        auxquelles ils donnent un poids (4 pour la méronymie/holonymie, 7 pour
        l'hyponymie/hyperonymie et 10 pour la synonymie). Chaque mot se voit
        attribuer quatre traits correspondant à quatre scores obtenus à partir
        des poids des relations~:
        \begin{enumerate}
          \item{Score de la chaîne lexicale~: somme du poids de toutes les
                relations de la chaîne lexicale~;}
          \item{Score du mot dans la chaîne lexicale~: somme du poids de toutes
                les relations du mot avec les autres mots de la chaîne
                lexicale~;}
          \item{Couverture de la chaîne lexicale~: différence entre la dernière
                occurrence, dans le document, d'un mot de la chaîne lexicale
                avec la première occurrence, dans le document, d'un mot de la
                chaîne lexicale~;}
          \item{Couverture du mot et de ses voisins dans la chaîne lexicale~:
                identique à la couverture de la chaîne lexicale, mais en tenant
                compte uniquement du mot et de ses voisins dans la chaîne.}
        \end{enumerate}
        \begin{figure}
          \centering
          \begin{tikzpicture}
            \node (programme) {programme};
            \node [below=of programme] (logiciel) {logiciel};
            \node [right=of logiciel, xshift=2em] (paquetage) {paquetage};
            \node [left=of logiciel, xshift=-2em] (application) {application};
            \node [below=of application] (app) {app};

            \draw (programme) -- (logiciel);
            \draw (programme) -- (application);
            \draw (programme) -- (paquetage);
            \draw (application) -- (logiciel);
            \draw (logiciel) -- (paquetage);
            \draw [dashed] (application) -- (app);

            % legend
            \node [scale=.75, right=of app, xshift=12em, yshift=3em] (legend_title) {\underline{Légende~:}};
            \node [scale=.75, below=of legend_title, xshift=-1.5em, yshift=3em] (begin_hyponym) {};
            \node [scale=.75, right=of begin_hyponym, xshift=-1em] (end_hyponym) {: hyponymie/hyperonymie};
            \node [scale=.75, below=of begin_hyponym, yshift=3em] (begin_synonym) {};
            \node [scale=.75, right=of begin_synonym, xshift=-1em] (end_synonym) {: synonymie};

            \draw (legend_title.north  -| end_hyponym.east) rectangle (end_synonym.south -| legend_title.west);

            \draw (begin_hyponym) -- (end_hyponym);
            \draw [dashed] (begin_synonym) -- (end_synonym);
          \end{tikzpicture}
          \caption{Exemple de chaîne lexicale~\cite{ercan2007lexicalchains}
                   \label{fig:lexical_chain}}
        \end{figure}

        ~\\Tirant aussi profit d'arbres de décision, \newcite{lopez2010humb}
        sont les vainqueurs de la campagne d'évaluation
        SemEval-2010~\cite{kim2010semeval}. Ils extraient les termes-clés en
        deux étapes. Tout d'abord, ils ordonnent les termes-clés candidats avec
        les arbres de décision, puis ils les ré-ordonnent à la manière de
        \newcite{turney2003keacoherence}~: les candidats bien classés
        initialement sont d'autant mieux classés qu'ils ont un fort lien
        sémantique avec d'autres candidats bien classés initialement.

      \subsubsection{Séparateurs à vastes marges}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-svms}
        Les séparateurs à vastes marges (\textsc{Svm}) projettent les exemples
        et les contre-exemples du corpus d'entraînement sur un plan selon la
        valeur de leurs traits, puis construisent l'hyperplan qui les sépare.
        Pour classer les termes-clés candidats d'un document, il suffit ensuite
        de les projeter sur ce même plan et d'utiliser l'hyperplan appris.

        ~\\\newcite{zhang2006svm} utilisent un \textsc{Svm} pour extraire les
        termes-clés à partir de ce qu'ils appellent le contexte global et le
        contexte local des termes-clés candidats. Ils représentent le contexte
        global d'un candidats par son \textsc{Tf-Idf}, sa première position et
        ses occurrences dans différentes parties du document, tandis qu'ils
        représentent son contexte local par sa catégorie grammaticale et trois
        traits encore jamais utilisés auparavant. Les deux premiers traits sont
        déterminés à partir des dépendances entre les mots. À la manière des
        méthodes non supervisées à base de graphe (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches})
        l'un des traits dénote le nombre de fois que le candidat modifie un mot
        et l'autre dénote le nombre de fois qu'un mot modifie le candidat. Le
        dernier trait s'appelle le \textsc{Tf-Idf} contextuel, il s'agit de la
        somme du \textsc{Tf-Idf} de tous les mots qui cooccurrent avec le
        candidat. Ce dernier trait indique si un candidat occurre dans un
        contexte important vis-à-vis du document.

        ~\\\newcite{jiang2009rankingsvm} extraient les termes-clés à partir d'un
        type particulier de \textsc{Svm}, baptisé
        \textsc{Svm}$^\textnormal{rank}$. \textsc{Svm}$^\textnormal{rank}$
        construit plusieurs hyperplans qui permettent d'ordonner les termes-clés
        candidats. Utilisant le score \textsc{Tf-Idf} des candidats, leur taille
        (en nombre de mots), leur première position, leur entropie et d'autres
        traits, le travail de \newcite{jiang2009rankingsvm} montre que le
        classifieur \textsc{Svm}$^\textnormal{rank}$ est plus performant qu'un
        \textsc{Svm} ou qu'un classifieur naïf bayesien utilisant les mêmes
        traits.

        ~\\\newcite{eichler2010keywe} extraient eux aussi les termes-clés à
        partir d'un \textsc{Svm}$^\textnormal{rank}$. Ils apprennent le
        \textsc{Svm}$^\textnormal{rank}$ avec trois valeurs pour le rang. La
        valeur maximale est attribuée aux exemples d'un document
        d'apprentissage, la valeur minimale aux contre-exemples du document et
        une valeur intermédiaire à ses contre-exemples qui sont des exemples
        d'autres documents d'apprentissage. Cette approche peut être assimilé à
        celle de \newcite{frank1999keafrequency}, qui estime qu'un terme-clé
        candidat fréquemment annoté comme terme-clé dans le corpus
        d'apprentissage est plus vraisemblablement un terme-clé. Quant aux
        traits utilisés pour entraîner le \textsc{Svm}$^\text{rank}$, le plus
        notable se réfère à Wikipedia. L'intuition des auteurs est que si un
        terme-clé candidat fait l'objet d'un article Wikipedia, alors il est
        plus vraisemblablement un terme-clé.

      \subsubsection{Perceptrons multicouches}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-neural_network}
        Les perceptrons multicouches sont des classifieurs qui émulent la
        biologie de l'apprentissage des êtres vivants. Ce sont des réseaux de
        neurones répartis sur au moins trois couches. Les neurones de la
        première couche représentent les traits d'un candidat (un neurone par
        trait), ceux des couches intermédiaires (couches cachées) propagent des
        scores obtenus selon la valeur des traits et ceux de la dernière couche
        donnent un score final pour chaque classe \og{}terme-clé\fg{} et
        \og{}non terme-clé\fg{} (un neurone par classe). La classe ayant le plus
        haut score est celle du terme-clé candidat pour lequel correspond la
        valeur des traits.
        
        ~\\\newcite{sarkar2010neuralnetwork} utilisent un perceptron multicouche
        pour classer les termes-clés candidats selon leur \textsc{Tf-Idf}, leur
        position, leur taille (en nombre de mots) et celle de leurs mots (en
        nombre de caractères). Contrairement à certain classifieurs présentés
        ci-avant, les perceptrons multi-couches ne fournissent pas de
        probabilité indiquant la vraisemblance d'un candidat en tant que
        \og{}terme-clé\fg{} ou \og{}non terme-clé\fg{}. L'une des contributions
        du travail de \newcite{sarkar2010neuralnetwork} est l'apprentissage d'un
        estimateur capable de donner le degré de confiance d'une classification
        selon le score attribué à chaque classe. Cet estimateur permet
        d'ordonner les termes-clés candidats, ceux classés \og{}terme-clé\fg{}
        en premier dans l'ordre décroissant de leur confiance et ceux classés
        \og{}non terme-clé\fg{} en dernier dans l'ordre croissant de leur
        confiance. Ainsi, la méthode de \newcite{sarkar2010neuralnetwork} peut
        extraire un nombre donné de termes-clés, en ajoutant des candidats
        classés \og{}non terme-clé\fg{} avec une faible confiance si nécessaire.

      \subsubsection{Algorithmes génétiques}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-genex}
        Les algorithmes génétiques sont des algorithmes qui donnent une solution
        approchée à un problème d'optimisation. Ce type d'algorithme
        n'effectue pas de classification et n'est pas nécessairement supervisé.

        ~\\\newcite{turney1999learningalgorithms} propose une méthode
        supervisée, GenEx, dont les paramètres sont valués par un algorithme
        génétique, appelé \textit{Genitor}. Un algorithme d'extraction de
        termes-clés, appelé \textit{Extractor}, est appliqué sur le corpus
        d'apprentissage avec des paramètres initiaux, puis le \textit{Genitor}
        fait évoluer la valeur de ses paramètres jusqu'à trouver celle qui
        maximise les performances de l'extraction. L'extraction des termes-clés
        d'un document se fait ensuite avec l'\textit{Extractor} et ses
        paramètres configurés par le \textit{Genitor}. Les paramètres appris
        sont principalement des seuils limitant la taille des candidats, le
        nombre de mots importants à considérer pour filtrer les candidats, ou
        encore le nombre de termes-clés à extraire. Ce sont aussi des facteurs
        multiplicateurs utilisés notamment pour le calcul de l'importance des
        mots et des candidats.

      \subsubsection{Bilan des méthodes supervisées}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-conclusion}
        Les méthodes supervisées reformulent la tâche d'extraction de
        termes-clés en une tâche de classification des termes-clés candidats en
        tant que \og{}terme-clé\fg{} ou \og{}non terme-clé\fg{}. Pour cela,
        elles utilisent des classifieurs et proposent divers traits pour
        discriminer les candidats. D'un point de vue recherche, c'est par les
        traits qu'elles proposent que les méthodes supervisées rivalisent.
        Certains traits sont génériques et communs à la majorité des méthodes.
        C'est le cas de la position de la première occurrence du candidat et de
        son score \textsc{Tf-Idf}. D'autres traits sont spécifiques à certains
        types de documents. Par exemple, la section dans laquelle occurre un
        terme-clé est un trait discriminant pour l'extraction de termes-clés à
        partir d'articles journalistiques.

  \section{Assignement automatique de termes-clés}
  \label{sec:main-state_of_the_art-automatic_keyphrase_assignment}
    L'assignement automatique de termes-clés fait l'objet de moins de travaux
    que l'extraction. Il s'agit aussi d'une tâche plus difficile, car elle doit
    assigner des entrées d'un vocabulaire contrôlé en tant que termes-clés d'un
    document indépendemment de leur apparition dans celui-ci.

    ~\\\newcite{medelyan2006kea++} sont les premiers à proposer une
    méthode capable de faire de l'assignement de termes-clés. Celle-ci,
    \textsc{Kea}++, améliore la méthode d'extraction \textsc{Kea}. Pour cela,
    elle utilise un thésaurus\footnote{Thésaurus~: liste de termes regroupés
    selon les concepts d'un domaine de connaissance qu'ils représentent.} du
    domaine de spécialités à traiter. Il est mis à profit de deux manière~:
    d'abord pour sélectionner les termes-clés candidats, puis pour améliorer le
    classifieur naïf bayesien à l'aide d'un nouveau trait.

    \newcite{medelyan2006kea++} décident de réaliser l'assignement en se
    limitant aux termes-clés qui occurrent dans le document. Ils sélectionnent
    donc toutes les unités textuelles qui correspondent à une entrée du
    thésaurus. À l'instar des candidats de \textsc{Kea}, ceux de \textsc{Kea++}
    sont ensuite classés en tant que \og{}terme-clé\fg{} ou \og{}non
    terme-clé\fg{} par un classifieur naïf bayesien. Ce classifieur est le même
    que celui de \textsc{Kea}, à l'exception d'un trait supplémentaire~: le
    nombre de relations sémantiques qu'entretient le candidat avec les autres
    dans le thésaurus. De cette manière, ils imitent le travail de
    \newcite{turney2003keacoherence} qui tente d'améliorer la cohérence entre
    les termes-clés extraits.

    Évalué avec des documents du domaine agroalimentaire et le thésaurus
    Agrovoc\footnote{\url{http://aims.fao.org/vest-registry/vocabularies/agrovoc-multilingual-agricultural-thesaurus}},
    \textsc{Kea}++ double les performances de \textsc{Kea}. Le travail de
    \newcite{medelyan2006kea++} montre donc l'efficacité d'une méthode
    d'assignement de termes-clés, même limitée.

    ~\\\newcite{liu2011vocabularygap} proposent une méthode que nous assimilons
    à de l'assignement de termes-clés. Ils font l'hypothèse qu'un document et
    ses termes-clés expriment le même contenu, mais dans deux langues
    différentes~: l'une expressive et l'autre synthétique. Ils reformulent donc
    la tâche d'indexation par termes-clés en une tâche de traduction du langage
    naturel vers celui des termes-clés.
    
    \newcite{liu2011vocabularygap} apprennent un modèle de traduction à l'aide
    de paires de mots~: l'un dans le langage naturel, l'autre dans le langage
    synthétique des termes-clés. Les mots du langage naturel sont extraits du document et les
    mots du langage synthétique sont extrait soit de son titre, soit de son
    résumé. Le modèle de traduction peut ensuite être appliqué aux termes-clés
    candidats, pour réaliser de l'extraction de termes-clés à la manière des
    classifieurs probabilistes présentés dans la
    section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-probabilistic_models}
    (page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-probabilistic_models}),
    ou être utilisé pour générer une traduction, c'est-à-dire des termes-clés.

    Parce qu'elle est capable de générer des termes-clés, cette méthode est très
    intéressante. Cependant, il ne s'agit là que d'un premier pas vers
    l'assignement de termes-clés, car aucun vocabulaire n'est utilisé pour
    contrôler la génération.

    ~\\Alors que l'assignement attribue des termes-clés d'une qualité certifiée
    par l'usage d'un vocabulaire contrôlé, cette tâche n'est encore que très peu
    étudiée. Seulement deux travaux originaux s'en rapprochent. L'un se fonde
    sur un vocabulaire contrôlé (un thésaurus), mais ne va pas au-delà du
    contenu du document~; l'autre génère des termes-clés qui n'occurrent pas
    nécessairement dans le document, mais ne se fonde pas sur vocabulaire
    contrôlé.

  %-----------------------------------------------------------------------------

  \section{Évaluation automatique de l'indexation par termes-clés}
  \label{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation}
    Pour montrer l'apport des nouvelles méthodes d'indexation par termes-clés,
    celles-ci sont comparées automatiquement aux méthodes existantes dans un
    processus d'évaluation \og{}à la Cranfield\fg{}
    \citep{voorhees2002philosophy}~: chaque méthode est appliquée à un ensemble
    de documents de test (corpus de test) et les termes-clés qu'elle extrait
    pour chaque document sont comparés à un ensemble de termes-clés associés
    manuellement aux documents, nous parlons de jugements de référence. Un
    jugement de référence est supposé unique, la comparaison entre un terme-clé
    extrait et un terme-clé de référence est donc binaire. Le résultat des
    comparaisons pour chaque document est analysé selon différents critères (le
    moins d'erreurs, le plus de termes-clés corrects, etc.) et la méthode
    respectant en moyenne le mieux ces critères est supposée la meilleure.

    En indexation par termes-clés, il est courant d'évaluer une méthode en
    termes de précision, de rappel et de f1-mesure. La précision capture la
    capacité d'une méthode à minimiser les erreurs (faux positifs, cf.
    tableau~\ref{tab:confusion_matrix} et équation~\ref{math:precision}). En
    opposition, le rappel ne considère pas la quantité d'erreurs et mesure la
    capacité de la méthode à fournir le plus possible de termes-clés corrects
    (vrais positifs, cf tableau~\ref{tab:confusion_matrix} et
    équation~\ref{math:recall}). Quant à la f1-mesure, elle évalue le
    compromis entre précision et rappel, soit la capacité de la méthode à
    extraire un maximum de termes-clés corrects tout en faisant un minimum
    d'erreurs (cf. équation~\ref{math:f1_measure}).
    \begin{table}
      \begin{center}
        \begin{tabular}{cc|cc}
          \toprule
          \multicolumn{2}{c|}{} & \multicolumn{2}{c}{\textbf{Jugement de référence}}\\
          \multicolumn{2}{c|}{} & \og{}terme-clé\fg{} & \og{}non terme-clé\fg{}\\
          \hline
          \multirow{2}{*}{\textbf{Résultat}} & \og{}terme-clé\fg{} & vrai positif ($\textsc{Vp}$) & faux positif ($\textsc{Fp}$)\\
          & \og{}non terme-clé\fg{} & faux negatif ($\textsc{Fn}$) & vrai negatif ($\textsc{Vn}$)\\
          \bottomrule
        \end{tabular}
        \caption{Matrice de confusion pour l'évaluation des méthodes
                 d'indexation automatique par termes-clés
                \label{tab:confusion_matrix}}
      \end{center}
    \end{table}
    \begin{align}
      \text{précision} &= \frac{\#\textsc{Vp}}{\#\textsc{Vp} + \#\textsc{Fp}} \label{math:precision}\\
      \text{rappel} &= \frac{\#\textsc{Vp}}{\#\textsc{Vp} + \#\textsc{Fn}} \label{math:recall}\\
      \text{f-mesure} &= (1 + \beta^2) \times \frac{\text{précision} \times \text{rappel}}{(\beta^2 \times \text{précision}) + \text{rappel}} \label{math:f_measure}\\
      \text{f1-mesure} &= 2 \times \frac{\text{précision} \times \text{rappel}}{\text{précision} + \text{rappel}} \label{math:f1_measure}
    \end{align}
      
%    En \textsc{Ri}, il est courant d'évaluer les méthodes selon la qualité de
%    leur ordonnancement. Prenons l'exemple des moteurs de recherche, si deux
%    moteurs de recherche doivent fournir dix documents répondant à une requête
%    et que les deux systèmes n'ont que deux propositions pertinentes, alors ils
%    ont tous les deux la même précision (20~\%) et le même rappel (20~\%).
%    Toutefois, si le premier système classe ces documents en premier et que le
%    second système les classe aux positions neuf et dix, alors le premier
%    système est le meilleur. Lorsque les méthodes d'indexation par termes-clés
%    le permettent, il est intéressant de mesurer leur capacité à classer en
%    premier les vrais positifs. Dans la littérature, quatre mesures, dont
%    certaines empruntées à la \textsc{Ri}, sont utilisées~: la \textsc{Map}
%    (\textit{Mean Average Precision}), la Bpref (\textit{Binary Preference
%    Measure}), la R-précision et la \textsc{Mrr} (\textit{Mean Reciprocal
%    Rank}). La \textsc{Map} mesure pour chaque document la moyenne de la
%    précision à chaque rang ($\textnormal{précision}@\textnormal{rang}$) d'un
%    vrai positif (cf. équation~\ref{math:average_precision}). Avec la Bpref, la
%    \textsc{Map} est la seule mesure qui tient compte de tous les vrais
%    positifs. La Bpref est une mesure similaire à la \textsc{Map} qui,
%    contrairement à cette dernière, s'abstrait de la connaissance de tous les
%    termes-clés de référence (cf. équation~\ref{math:bpref}). Elle peut donc,
%    par exemple, s'appliquer dans le cadre d'évaluations manuelles où chaque
%    terme-clé fourni par la méthode est jugé correct ou non par un évaluateur
%    humain et où tous les termes-clés du document ne sont pas connus. La
%    R-précision est une variante de la précision. Elle mesure cette dernière
%    dans le cas optimal (tous les termes-clés sont fournis et il n'y a aucune
%    erreur), soit au rang $R$, où $R$ est égal au nombre de termes-clés de
%    référence du document (cf. équation~\ref{math:r_precision}). Quant à la
%    \textsc{Mrr}, celle-ci est la moins précise, elle ne s'intéresse qu'au
%    meilleur rang obtenu pour un vrai positif (cf.
%    équation~\ref{math:reciprocal_rank}).
%    \begin{align}
%      \textsc{Map} &= \frac{\mathlarger{\sum}_{\text{\textit{terme-clé}} = \textsc{Vp}}\text{précision}@\text{rang}(\text{\textit{terme-clé}})}{\#\textsc{Vp} + \#\textsc{Fn}} \label{math:average_precision}\\
%      \notag \\
%      \text{Bpref} &= \sum_{\text{\textit{terme-clé}} = \textsc{Vp}}{1 - \frac{|\text{\textit{terme-clé}'}\ \text{de meilleur rang que}\ \text{\textit{terme-clé}}|}{\#\textsc{Vp} + \#\textsc{Fp}}} \label{math:bpref}\\
%      \notag \\
%      \text{R-précision} &= \text{précision}@(\#\textsc{Vp} + \#\textsc{Fn}) \label{math:r_precision}\\
%      \notag \\
%      \textsc{Mrr} &= \frac{1}{\text{argmin}(\forall \text{\textit{terme-clé}} = \textsc{Vp}, \text{rang}(\text{\textit{terme-clé}}))} \label{math:reciprocal_rank}
%    \end{align}

%    Toutes les mesures présentées précédemment respectent le paradigme de
%    l'évaluation \og{}à la Cranfield\fg{}. Cependant, associer des termes-clés à
%    un document est une tâche subjective~\cite{hasan2014state_of_the_art}, il
%    n'existe donc pas une solution unique. Des travaux proposent d'apporter plus
%    de souplesse à la comparaison entre termes-clés résultant d'une méthode et
%    termes-clés de référence en tenant compte de leur
%    chevauchement~\cite{zesch2009rprecision,kim2010rprecision}. Ces travaux
%    ne sont toutefois pas utilisés travaux récents.

    \TODO{Comparaisons avec les stems}

    \TODO{point sur le pessimisme}

  %-----------------------------------------------------------------------------

  \section{Conclusion}
  \label{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation-conclusion}
    Nous avons présenté la tâche d'indexation par termes-clés, de la sélection
    des termes-clés candidats aux différentes méthodes d'extraction et
    d'assignement de termes-clés, en passant par le processus d'évaluation
    automatique de ces dernière.

    La sélection des termes-clés candidats est une étape quasi-systématique de
    l'indexation automatique par termes-clés. Ne s'agissant cependant pas du
    c\oe{}ur de la tâche, la définition de nouvelle méthodes de sélection est
    négligée au profit de méthodes de sélection simples (sélection de n-grammes,
    \textit{chunks nominaux} ou séquences noms-adjectifs). Toutefois, l'idée que
    l'indexation par termes-clés gagnerait en performances si les candidats
    sélectionnés étaient moins nombreux, c'est-à-dire contiendraient moins
    d'erreurs, semble faire consensus auprès des chercheurs qui s'y intéressent.
    La méthode qui consiste à définir des patrons grammaticaux, tels que celui
    pour sélectionner les séquences noms-adjectifs,  pourait être utilisée pour
    sélectionner des candidats en s'intéressant plus en profondeur aux classes
    grammaticales employées dans les termes-clés, ainsi qu'à d'autres propriétés
    linguistiques de leurs composants.

    Le c\oe{}ur de la tâche d'indexation automatique par termes-clés est
    réalisée de deux manières différentes~: soit les termes-clés sont extraits
    depuis le contenu du document, soit ils sont assignés en puisant dans un
    vocabulaire contrôlé. Dans la littérature, l'extraction fait l'objet de plus
    de travaux que l'assignement. Parmi les travaux les plus récents, ce sont
    les méthodes d'extraction de termes-clés à base de graphe qui sont les plus
    étudiées. Elles ont l'avantage d'utiliser une représentation simple et
    intuitive du document. Cependant, leur focalisation sur les mots ne nous
    semble pas pertinente, car les termes-clés sont des mots ou des expressions.
    Par ailleurs, le problème de dispersion dans le graphe d'éléments
    sémantiquement équivalents n'a encore jamais été évoqué/résolu.

    L'évaluation des méthodes d'indexation par termes-clés est généralement
    effectuée de manière automatique. Comparé à un jugement de référence unique,
    le résultat d'une méthode d'indexation par termes-clés est évalué en termes
    de précision, qui est d'autant plus élevée s'il y a le moins d'erreurs, de
    rappel, qui est d'autant plus élevée s'il y a beaucoup de termes-clés
    positifs, et de f1-mesure, qui est le compromis entre précision et rappel.
    Ce modèle d'évaluation présente l'avantage d'être utilisable dès lors que
    des données de test sont disponibles. La comparaison à un jugement de
    référence unique rend cependant l'évaluation pessimiste. Lorsque les
    conditions le permettent, une évaluation manuelle reste indispensable pour
    mieux mesurer les forces et les faiblesses d'une méthode d'indexation par
    termes-clés.

