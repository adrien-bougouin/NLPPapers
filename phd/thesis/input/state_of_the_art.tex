\chapter[Indexation automatique par termes-clés]{Indexation automatique\\par termes-clés}
\label{chap:main-state_of_the_art}
  \chaptercite{
    Il y a besoin d'outils pouvant créer des termes-clés. Bien que les
    termes-clés sont très utiles, une infime quantité seulement des documents
    disponibles sur Internet en contient.
%    There is a need for tools that can automatically create keyphrases. Although
%    keyphrases are very useful, only a small minority of the many documents that
%    are available on-line today have keyphrases.
  }{
    \newcite{turney1999learningalgorithms}
  }{.75\linewidth}{\justify}

  \section{Introduction}
  \label{sec:main-state_of_the_art-introduction}
    Les termes-clés\index{Terme-cle@Terme-clé \textit{(keyphrase)}|textbf},
    souvent appelés mots-clés\index{Mot-cle@Mot-clé
    \textit{(keyword)}|textbf}\footnote{Un terme-clé est plus communément appelé
    mot-clé. Cependant, un mot-clé n'étant pas uniquement monolexical, nous
    utilisons la notion de terme-clé pour lever toute ambiguïté. Lorsque nous parlons de mots-clés, cela ne concerne donc que les
    monolexicaux.}, sont les unités textuelles (mots ou expressions) qui
    caractérisent le contenu principal d'un document~: les sujets qu'il aborde,
    ses idées, etc (cf exemple
    figure~\ref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation}).
    Associés à un document, ils donnent une description précise de son contenu
    et servent à l'indexer pour la recherche d'information (\textsc{Ri}). Nous
    parlons donc d'indexation par termes-clés\index{Indexation par
    termes-cles@Indexation par termes-clés \textit{(automatic keyphrase
    annotation)}|textbf}. Cette indexation ne doit toutefois pas être confondue
    avec l'indexation dite \og{}plein texte\fg{} au c\oe{}ur de nombreux
    systèmes de \textsc{Ri}. Celle-ci pondère tous les mots d'un document en
    fonction de leur importance relative à son contenu, tandis que l'indexation
    par termes-clés fournit un ensemble restreint de mots ou expressions qui
    représentent ses sujets importants, explicites ou non (cf figure~\ref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation}). Dans la suite, lorsque nous parlons d'indexation, nous
    nous référons à l'indexation par termes-clés.
    \begin{figure}
      \framebox[\linewidth]{ % linguistique_11-0080464
        \parbox{.99\linewidth}{\textbf{La cause linguistique}\\

          L'objectif est de fournir une définition de base du concept
          linguistique de la cause en observant son expression. Dans un premier
          temps, l'A. se demande si un tel concept existe en langue. Puis il
          part des formes de son expression principale et directe (les verbes et
          les conjonctions de cause) pour caractériser linguistiquement ce qui
          fonde une telle notion.\\

          \textbf{Termes-clés de référence~:} français~; interprétation sémantique~;
          \underline{conjonction}~; expression linguistique~; \underline{concept
          linguistique}~; relation syntaxique~; \underline{cause}. 
        }
      }
      \caption[
        Exemple d'indexation par termes-clés d'une notice bibliographique
        (résumé)
      ]{
        Exemple d'indexation par termes-clés  d'une notice bibliographique
        (résumé). Les termes-clés soulignés sont explicites, c'est-à-dire
        qu'ils occurrent dans le document, les autres sont implicites.
        \label{fig:main-state_of_the_art-introduction-example_keyphrase_annotation}
      }
    \end{figure}    

    Dans la littérature, nous distinguons deux catégories d'indexation
    automatique par termes-clés~: l'une libre, l'autre contrôlée. L'indexation
    libre\index{Indexation libre@Indexation libre \textit{(free indexing)}|see
    {Extraction automatique de termes-clés \textit{(automatic keyphrase
    extraction)}}} consiste à extraire d'un document les unités textuelles
    jugées les plus importantes vis-à-vis de son contenu. Nous parlons
    d'\emph{extraction automatique de termes-clés}\index{Extraction automatique
    de termes-cles@Extraction automatique de termes-clés \textit{(automatic
    keyphrase extraction)}|textbf}. L'indexation contrôlée\index{Indexation
    controlee@Indexation contrôlée \textit{(controlled indexing)}|see
    {Assignement automatique de termes-clés \textit{(automatic keyphrase
    assignment)}}} fournit les termes-clés en se fondant sur un vocabulaire
    contrôlé (une terminologie), sans se restreindre aux unités textuelles
    présentes dans le document. Nous parlons d'\emph{assignement automatique de
    termes-clés}\index{Assignement automatique de termes-cles@Assignement
    automatique de termes-clés \textit{(automatic keyphrase
    assignment)}|textbf}.

    Dans ce chapitre d'introduction à l'indexation automatique par termes-clés,
    nous commençons par présenter l'étape de sélection des termes-clés
    candidats, qui est une étape commune à la plupart des méthodes d'extraction
    de termes-clés, et qui devient un objet d'étude à part
    entière~\cite{wang2014keyphraseextractionpreprocessing}. Ensuite, nous
    présentons les tâches d'extraction automatique de termes-clés et
    d'assignement automatique de termes-clés, puis nous terminons par une
    description du processus d'évaluation des méthodes d'indexation par
    termes-clés.

  %-----------------------------------------------------------------------------

  \section{Sélection des termes-clés candidats}
  \label{sec:main-state_of_the_art-keyphrase_candidate_selection}
    % Quel est l'objectif ?
    La sélection des termes-clés candidats\index{Selection des termes-cles
    candidats@Sélection des termes-clés candidats \textit{Keyphrase candidate
    selection}|textbf}\index{Terme-cle candidat@Terme-clé candidat
    \textit{(keyphrase candidate)}|textbf} consiste à déterminer quelles sont
    les unités textuelles qui sont potentiellement des termes-clés, c'est-à-dire
    les unités textuelles qui ont des particularités similaires à celles des
    termes-clés définis par des humains, telles que la structure
    morphosyntaxique nom-adjectif commune à la majorité des termes-clés
    (par exemple, \og{}interprétation sémantique\fg{}, \og{}concept
    linguistique\fg{} et
    \og{}relation syntaxique\fg{}). Elle réduit l'espace de recherche et permet
    ainsi de diminuer le temps de traitement nécessaire pour l'extraction de
    termes-clés et de supprimer les
    %
    unités textuelles non pertinentes pouvant affecter négativement ses
    performances. Pour distinguer les différents candidats sélectionnés, nous
    définissons deux catégories~: les candidats positifs\index{Candidat
    positif@Candidat positif \textit{(positive candidate)}|textbf}, qui
    correspondent aux termes-clés assignés par des humains (termes-clés de
    référence), et les candidats négatifs\index{Candidat negatif@Candidat
    négatif \textit{(negative candidate)}|textbf}. Parmi les candidats négatifs,
    nous distinguons les candidats non importants des candidats erronés, tels que les conjonctions, les
    déterminants ou les unités textuelles mal segmentées (par exemple,
    \og{}base du concept\fg{} issu du groupe nominal \og{}une définition de base
    du concept linguistique\fg{}, lui même composé des groupes nominaux
    \og{}une définition de base\fg{} et \og{}concept linguistique\fg{} dans la
    notice de la
    figure~\ref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation}).

    Il existe plusieurs méthodes de sélection de candidats, de la simple
    sélection de n-grammes, de chunks nominaux ou d'unités textuelles
    grammaticalement définies, jusqu'à une méthode plus complexe visant à
    réduire radicalement le nombre de candidats.

    ~\\Les n-grammes\index{N-gramme@N-gramme \textit{(n-gram)}|textbf} sont
    toutes les séquences ordonnées de $n$ mots adjacents (voir
    l'exemple~\ref{ex:n_grams}). La sélection des n-grammes est très exhaustive,
    elle fournit un grand nombre de termes-clés candidats, ce qui maximise la
    quantité de candidats positifs, la quantité de candidats non importants,
    mais aussi la quantité de candidats erronés. Pour réduire cette dernière, il
    est courant de filtrer les n-grammes avec un
    antidictionnaire\index{Antidictionnaire@Antidictionnaire
    \textit{(stopwords)}|textbf} regroupant les mots ne pouvant pas être des
    mots-clés (conjonctions, prépositions, mots d'usage courant, etc.). Si un
    n-gramme contient un mot de l'antidictionnaire en début ou en fin, alors il
    n'est pas considéré comme un terme-clé candidat.
    
    Malgré son aspect grossier, la sélection des n-grammes est largement
    utilisée en extraction de
    termes-clés~\cite{witten1999kea,hulth2003keywordextraction,medelyan2009humancompetitivetagging},
    pour sa simplicité de mise en \oe{}uvre.

    \begin{example}\label{ex:n_grams}
      $\{1..3\}$-grammes sélectionnés dans le phrase \og{}L'objectif est de
      fournir une définition de base du concept linguistique de la cause en
      observant son expression.\fg{}~:
      \begin{center}
        \begin{tabular}{l|l|l}
          \toprule
          \multicolumn{1}{c|}{\textbf{Uni-gramme}} & \multicolumn{1}{c|}{\textbf{Bi-gramme}} & \multicolumn{1}{c}{\textbf{Tri-gramme}}\\
          \hline
          \og{}objectif\fg{} & \og{}concept linguistique\fg{} & \og{}définition de base\fg{}\\
          \og{}définition\fg{} & & \og{}base du concept\fg{}\\
          \og{}base\fg{} & &\\
          \og{}concept\fg{} & &\\
          \og{}linguistique\fg{} & &\\
          \og{}cause\fg{} & &\\
          \og{}expression\fg{} & &\\
          \bottomrule
        \end{tabular}
      \end{center}\vspace{.25em}
    \end{example}

    ~\\Les \textit{chunks} nominaux\index{NP-chunk@NP-\textit{chunk}|textbf}
    (\textit{NP-chunks}) sont des syntagmes\index{Syntagme@Syntagme
    \textit{(syntagm)}|textbf}\footnote{Syntagme~: unité syntaxique
    intermédiaire entre le mot et la phrase. Aussi appelé groupe, le syntagme
    constitue une unité de sens dont chaque constituant conserve sa
    signification et sa syntaxe propre.} non récursifs (ou minimaux) dont la
    tête est un nom, accompagné de ses éventuels déterminants et modifieurs
    usuels (voir l'exemple~\ref{ex:np_chunks}). Ils sont linguistiquement
    définis et leur sélection, sans considérer les déterminants qui les précèdent, est
    donc plus fiable que celle des n-grammes pour l'extraction de termes-clés.
    \newcite{hulth2003keywordextraction} le montre dans ses expériences
    consacrées à l'apport de connaissances linguistiques pour l'extraction
    automatique de termes-clés. Cependant, ses propos sont nuancés par un autre
    de ses constats~: tirer profit de la catégorie grammaticale des mots des
    n-grammes permet d'obtenir de meilleures performances qu'avec les
    \textit{chunks} nominaux.

    \begin{example}\label{ex:np_chunks}
      \textit{chunks} nominaux sélectionnés dans le phrase \og{}L'objectif est
      de fournir une définition de base du concept linguistique de la cause en
      observant son expression.\fg{}~:
      \begin{center}
        \begin{tabular}{l|l}
          \toprule
          \multicolumn{1}{c|}{\textbf{\textit{Chunk} nominal}} & \multicolumn{1}{c}{\textbf{Candidat sélectionné}}\\
          \hline
          \og{}l'objectif\fg{} & \og{}objectif\fg{}\\
          \og{}une définition\fg{} & \og{}définition\fg{}\\
          \og{}base\fg{} & \og{}base\fg{}\\
          \og{}concept linguistique\fg{} & \og{}concept linguistique\fg{}\\
          \og{}la cause\fg{} & \og{}cause\\
          \og{}expression\fg{} & \og{}expression\fg{}\\
          \bottomrule
        \end{tabular}
      \end{center}\vspace{.25em}
    \end{example}

    ~\\La sélection d'unités textuelles qui forment des séquences
    grammaticalement définies\index{Sequence grammaticalement definie@Séquence
    grammaticalement définie \textit{(POS sequence)}|textbf} permet de contrôler
    avec précision la nature et la grammaticalité des candidats sélectionnés.
    Pour cela, il faut définir des patrons grammaticaux tels que
    \texttt{/(N|A)+/} (voir l'exemple~\ref{ex:na+}), qui représente les plus
    longues séquences de noms (\texttt{N}) et d'adjectifs (\texttt{A}), exprimé
    avec la syntaxe des expressions rationnelles.

    À l'instar des \textit{chunks} nominaux, la sélection des séquences
    grammaticalement définies est plus fondée linguistiquement que celle des
    n-grammes. Dans ses travaux, \newcite{hulth2003keywordextraction}
    sélectionne les candidats à partir des patrons des termes-clés de référence
    les plus fréquents dans ses données. D'autres chercheurs,
    tels que \newcite{wan2008expandrank}, se contentent des plus longues
    séquences de noms (noms propres inclus) et d'adjectifs.

    \begin{example}\label{ex:na+}
      Séquences \texttt{/(N|A)+/} sélectionnés dans le phrase \og{}L'objectif
      est de fournir une définition de base du concept linguistique de la cause
      en observant son expression.\fg{}~:
      \begin{center}
        \begin{tabular}{l}
          \toprule
          \multicolumn{1}{c}{\textbf{\texttt{/(N|A)+/}}}\\
          \hline
          \og{}objectif\fg{}\\
          \og{}définition\fg{}\\
          \og{}base\fg{}\\
          \og{}concept linguistique\fg{}\\
          \og{}cause\\
          \og{}expression\fg{}\\
          \bottomrule
        \end{tabular}
      \end{center}\vspace{.25em}
    \end{example}

    ~\\En plus des trois méthodes de sélection précédentes,
    \newcite{huang2006semanticnetworkstructureanalysis} proposent un filtrage
    des candidats sélectionnés à partir des n-grammes, afin de réduire le nombre
    de candidats redondants (par exemple, \og{}cause\fg{} représente \og{}cause
    linguistique\fg{} dans la notice de la
    figure~\ref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation},
    page~\pageref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation}).
    Tout d'abord, ils suppriment les candidats peu fréquents dans le document,
    puis filtrent la redondance en les mettant en compétition. Ils construisent
    des groupes de candidats possédant le même mot, puis un seul candidat par groupe est
    retenu~: celui le plus fréquent. Un candidat peut être en compétition dans
    différents groupes. Dans ce cas, il doit être le \og{}vainqueur\fg{} de
    chaque groupe pour être retenu.

    Le travail de \newcite{huang2006semanticnetworkstructureanalysis}, sur la
    sélection des termes-clés candidats, fait partie d'un travail focalisé sur
    l'extraction de termes-clés. Leur évaluation ne s'intéresse qu'a cet aspect,
    l'apport de leur méthode de sélection des termes-clés candidats n'a donc pas
    été montré.

  %-----------------------------------------------------------------------------

  \section{Extraction automatique de termes-clés}
  \label{sec:main-state_of_the_art-automatic_keyphrase_extraction}
    L'extraction automatique de termes-clés est la tâche la plus utilisée pour
    l'indexation par termes-clés. Les méthodes d'extraction automatique de
    termes-clés effectuent soit un ordonnancement par importance des termes-clés
    candidats vis-à-vis du contenu du document, soit une classification des
    termes-clés candidats entre les classes \og{}terme-clé\fg{} et \og{}non
    terme-clé\fg{}. La figure~\ref{fig:etapes_de_l_extraction_de_termes_cles}
    présente la chaîne de traitement de la majorité des méthodes d'extraction de
    termes-clés. L'ordonnancement est principalement réalisé avec une
    approche non supervisée et la classification est réalisée avec une approche
    supervisée, qui requiert des documents d'apprentissage manuellement indexées.
    \begin{figure}[t]
      \tikzstyle{io}=[
        ellipse,
        minimum width=5cm,
        minimum height=2.5cm,
        %fill=green!20,
        %draw=green!33,
        draw=black,
        transform shape,
        font={\huge}
      ]
      \tikzstyle{component}=[
        text centered,
        thick,
        rectangle,
        minimum width=13.5cm,
        minimum height=2cm,
        %fill=cyan!20,
        %draw=cyan!33,
        draw=black,
        transform shape,
        font={\huge\bfseries}
      ]

      \centering
      \begin{tikzpicture}[thin,
                          align=center,
                          scale=.425,
                          node distance=2cm,
                          every node/.style={text centered, transform shape}]
        \node[io] (document) {document};
        \node[component] (preprocessing) [below=of document] {Prétraitement linguistique};
        \node[component] (candidate_extraction) [below=of preprocessing]
        {Sélection des termes-clés candidats};
        \node[component, yshift=-4cm] (candidate_classification_and_ranking) [below=of candidate_extraction] {Ordonnancement des candidats};
        \node[component, minimum width=29cm, xshift=7.75cm] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés à extraire};
        \node[io] (keyphrases) [below=of keyphrase_selection] {termes-clés};
        %
        \node[component] (preprocessing2) [right=of preprocessing] {Prétraitement linguistique};
        \node[component] (candidate_extraction2) [right=of candidate_extraction] {Sélection des termes-clés candidats};
        \node[component] (classification) [right=of candidate_classification_and_ranking] {Classification des candidats};
        \node[component] (learning) [below=of candidate_extraction2]
        {Apprentissage du modèle de classification};
        \node[io] (documents) [above=of preprocessing2] {documents d'apprentissage};

        \path[->, thick] (document) edge (preprocessing);
        \path[->, thick] (preprocessing) edge (candidate_extraction);
        \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
        \path[->, thick] (keyphrase_selection) edge (keyphrases);
        %
        \path[->, thick] (documents) edge (preprocessing2);
        \path[->, thick] (preprocessing2) edge (candidate_extraction2);
        \path[->, thick] (candidate_extraction2) edge (learning);
        \path[->, thick] (learning) edge (classification);
        \path[->, thick] (classification) edge (keyphrase_selection);
        %
        \draw[->, thick] (candidate_extraction) -- (candidate_classification_and_ranking) node [midway] (midway1) {};
        \draw[->, thick] (candidate_extraction) -- (classification.north west) node [midway] (midway2) {};
        \draw[dashed] (midway1) -- (midway2) node [midway, below] (xor) {\huge\{ou\}};

        \draw [dashed] ($(preprocessing2.north west)+(-.5cm,5cm)$) rectangle ($(learning.south east)+(.5cm,-.5cm)$);
        \node [above=of documents, yshift=-1.4cm, xshift=-5.25cm] (apprentissage) {\huge apprentissage};
      \end{tikzpicture}
      \caption{Chaîne de traitement classique en extraction de termes-clés
               \label{fig:etapes_de_l_extraction_de_termes_cles}}
    \end{figure}

    \subsection{Approche non supervisée}
    \label{subsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction}
      La plupart des méthodes non supervisées d'extraction de termes-clés
      ordonnent les termes-clés candidats d'après leur importance vis-à-vis du
      contenu du document (par exemple, l'expression \og{}concept
      linguistique\fg{} est importante vis-à-vis du document de la
      figure~\ref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation},
      page~\pageref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation}),
      puis extraient les $k$ plus importants en tant que termes-clés. Du fait
      qu'elles ne requièrent pas de données d'entraînement, elles sont
      applicables dans toutes les situations et ont la
      particularité de s'abstraire du domaine des documents
      qu'elles traitent. Les termes-clés candidats sont analysés avec des règles
      simples fondées sur des traits statistiques extraits du document ou d'un
      corpus de référence non indexé.

      De nombreuses méthodes sont proposées. Certaines se fondent uniquement
      sur des statistiques et d'autres les combinent avec des représentations
      plus complexes du document~: des groupes sémantiques et des
      graphes de cooccurrences de mots.

      Nous présentons ces différentes méthodes. Lorsque celles-ci ont été
      évaluées sur des données disponibles, nous comparons leurs performances
      aux autres dans le
      tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison}. Ces
      dernières sont exprimées en terme de f1-mesure. Cette mesure est exprimée entre 0 et 100
      et est d'autant plus élevée si la méthode évaluée extrait un grand nombre
      de termes-clés corrects (cf
      section~\ref{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation},
      page~\pageref{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation}).
      \begin{table}
        \resizebox{\linewidth}{!}{
          \begin{tabular}{l|c|c|c|c}
            \toprule
            \textbf{Méthode} & \textbf{\textsc{Duc}}~\textit{\cite{wan2008expandrank}} & \textbf{Inspec}~\textit{\cite{hulth2003keywordextraction}} & \textbf{\textsc{Nus}}~\textit{\cite{nguyen2007keadocumentstructure}} & \textbf{\textsc{Icsi}}~\textit{\cite{adam2003icsi}}\\
            \hline
            \textsc{Tf-Idf}$^*$ & 27,0 & 36,3 & \textbf{6,6} & \textbf{12,1}\\
            KeyCluster$^*$ & 14,0 & 40,6 & 1,7 & $~~$3,2\\
            TextRank$^*$ & $~~$9,7 & 33,0 & 3,2 & $~~$2,7\\
            SingleRank$^*$ & 25,6 & 35,3 & 3,8 & $~~$4,4\\
            ExpandRank$^*$ & 26,9 & 35,3 & 3,8 & $~~$4,3\\
            TopicalPageRank & 31,2 & --- & --- & ---\\
            WordTopic-MultiRank & \textbf{34,0} & \textbf{48,2} & --- & ---\\
            \bottomrule
          \end{tabular}
        }
        \caption[
          Comparaison des méthodes d'extraction non supervisée de termes-clés de la
          littérature, lorsque dix termes-clés sont extraits
        ]{
          Comparaison des méthodes d'extraction automatique de termes-clés de la
          littérature, lorsque dix termes-clés sont extraits. Les performances
          sont exprimées en terme de f1-mesure. \textsc{Duc} est
          une collection d'articles journalistiques, Inspec est une collection
          de résumés d'articles scientifiques, \textsc{Nus} est une collection
          d'articles scientifiques et \textsc{Icsi} est une collections de
          transcriptions textuelles de réunions. $^*$ indique que les résultats
          ont été reportés par \newcite{hassan2010conundrums}.
          \label{tab:state_of_the_art-unsupervised_methods_comparison}
        }
      \end{table}

      \subsubsection{Méthodes statistiques}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches}
        Les méthodes statistiques se fondent majoritairement sur le nombre d'occurrences des termes-clés candidats (souvent assimilé à leur
        fréquence) ou de leur nombre de mots, soit dans le
        document, soit dans un corpus de référence, ou bien les deux.

        ~\\\textsc{Tf-Idf}~\cite{jones1972tfidf} et Likey~\cite{paukkeri2010likey}
        sont deux méthodes similaires qui comparent le comportement d'une unité
        textuelle dans le document avec son comportement dans un corpus de
        référence. Elles font l'hypothèse qu'une unité textuelle a une forte
        importance vis-à-vis du document si elle y est très fréquente et si elle
        l'est peu dans le corpus de référence, auquel cas elle est spécifique au
        document~:
        \begin{align}
          \text{\textsc{Tf-Idf}}(\text{\textit{ut}}) &= \textsc{Tf}(\text{\textit{ut}}) \times \log\left(\frac{N}{\textsc{Df}(\text{\textit{ut}})}\right) \label{math:tfidf}\\
          \notag\\
          \text{Likey}(\text{\textit{ut}}) &= \frac{\text{rang}_{\text{document}}(\text{\textit{ut}})}{\text{rang}_{\text{corpus}}(\text{\textit{ut}})} \label{math:likey}
        \end{align}\\
        Dans \textsc{Tf-Idf}, $\textsc{Tf}$ (\textit{Term Frequency}) représente
        le nombre d'occurrences d'une unité textuelle \textit{ut} dans le
        document, $\textsc{Df}$ (\textit{Document Frequency}) représente le
        nombre de documents du corpus de référence dans lesquels elle occurre
        et $N$ est le nombre total de documents du corpus de référence. Plus le
        score \textsc{Tf-Idf} d'une unité textuelle est élevé, plus celle-ci est
        importante vis-à-vis du document. Dans Likey, les rangs d'une unité
        textuelle dans le document et dans le corpus est obtenu à partir de son
        nombre d'occurrences dans le document et dans le corpus, respectivement.
        Plus le rapport entre ces deux rangs est faible, plus l'unité textuelle
        évaluée est importante dans le document.

        La nature linguistique de l'unité textuelle \textit{ut} peut être fixée au mot ou au
        terme-clé candidat. Si la granularité fixée est le mot, il est courant
        de déterminer le score d'importance des termes-clés candidat en faisant
        la somme du score \textsc{Tf-Idf} ou Likey des mots qui les composent.
        Cependant, faire cette somme favorise les plus longues séquences de mots
        et fait monter dans le classement des candidats redondants qui possèdent
        un mot important en commun.

        Méthode de pondération historique de \textsc{Ri}, \textsc{Tf-Idf} reste
        encore aujourd'hui l'une des méthodes de référence à laquelle il faut se
        comparer pour montrer la validité d'une nouvelle méthode non supervisée
        d'extraction de termes-clés. Les résultats du
        tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison}
        (page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison})
        montrent que \textsc{Tf-Idf} est encore compétitive vis-à-vis des
        méthodes non supervisées récentes.

        ~\\Okapi (ou \textsc{Bm}25) \cite{robertson1999okapi} est une mesure
        alternative à \textsc{Tf-Idf}. En \textsc{Ri},
        celle-ci est préférée à \textsc{Tf-Idf}. Bien que l'extraction
        automatique de termes-clés soit une discipline entre le
        \textsc{Tal} et la \textsc{Ri}, la méthode de pondération Okapi n'a, à
        notre connaissance, pas été appliquée pour l'extraction de termes-clés.
        \newcite{claveau2012vectorisation} décrit Okapi comme un \textsc{Tf-Idf}
        prenant mieux en compte la longueur des documents. Cette dernière est
        utilisée pour normaliser le $\textsc{Tf}$
        ($\textsc{Tf}_{\textsc{Bm}25}$)~:
        \begin{align}
          \text{Okapi}(\text{\textit{ut}}) &= \textsc{Tf}_{\textsc{Bm}25}(\text{\textit{ut}}) \times \log\left(\frac{N - \textsc{Df}(\text{\textit{ut}}) + 0,5}{\textsc{Df}(\text{\textit{ut}}) + 0,5}\right) \label{math:okapi}\\
          \notag\\
          \textsc{Tf}_{\textsc{Bm}25}(\text{\textit{ut}}) &= \frac{\textsc{Tf}(\text{\textit{ut}}) \times (k_1 + 1)}{\textsc{Tf}(\text{\textit{ut}}) + k_1 \times \left(1 - b + b \times \frac{\textsc{Dl}}{\textsc{Dl}_{\text{moyenne}}}\right)} \label{math:tf_bm25}
        \end{align}\\
        où $k_1$ est une constante fixée à 2, où $b$ est une constante fixée à
        $0,75$, où $\textsc{Dl}$ (\textit{Document Length}) représente la
        longueur du document et où $\textsc{Dl}_{moyenne}$ représente la
        longueur moyenne des documents du corpus de référence.

        ~\\Le travail de \newcite{barker2000nounphrasehead} est un autre exemple
        d'utilisation de la fréquence pour extraire les termes-clés. Se reposant
        sur des fondements plus linguistiques, ils utilisent des groupes
        nominaux comme termes-clés candidats et tiennent compte à la fois de
        leur fréquence et de celle de leur tête nominale pour déterminer leur
        importance.
        
        Selon \newcite{barker2000nounphrasehead}, un candidat important est un
        candidat informatif et fréquent. L'informativité est ici assimilée à sa
        taille, en nombre de mots~: plus il contient de mots, plus il est
        informatif. Pour éviter les répétitions, jugées inesthétiques, les longs
        candidats (informatifs) sont parfois abrégés et leur fréquence réelle ne
        reflète pas leur usage. C'est pourquoi
        \newcite{barker2000nounphrasehead} proposent d'utiliser la fréquence de
        la tête des candidats pour décider s'ils doivent être extraits ou non.
        Leur méthode fonctionne en quatre étapes. Ils extraient tout d'abord les
        $n$ noms les plus fréquents, ils gardent uniquement les groupes nominaux
        contenant un de ces noms, puis les ordonnent selon le produit de leur
        taille et de leur fréquence réelle. Enfin, ils extraient les $k$ groupes
        nominaux de meilleur rang.

        ~\\\newcite{tomokiyo2003languagemodel} tentent aussi de vérifier
        statistiquement deux propriétés que doit respecter un terme-clé candidat
        pour être extrait~:
        \begin{itemize}
          \item{informativité : un terme-clé doit capturer au moins une des
                idées essentielles exprimées dans le document analysé;}
          \item{grammaticalité : un terme-clé doit être bien formé
                syntaxiquement.}
        \end{itemize}
        Pour vérifier ces deux propriétés, trois modèles de langue
        ($\textsc{Ml}$, cf équation~\ref{math:ml}) sont utilisés (cf. figure~\ref{fig:klml}). Les deux
        premiers modèles, l'un uni-gramme, $\textsc{Ml}_{\text{document}}^1$,
        l'un n-gramme, $\textsc{Ml}_{\text{document}}^N$, sont construits à
        partir du document. Le dernier, un modèle n-gramme,
        $\textsc{Ml}_{\text{référence}}^N$, est construit à partir d'un corpus
        de référence, c'est le modèle de référence. Il fournit une vision
        globale de la distribution des n-grammes dans la langue (français,
        anglais, etc.). De ce fait, plus la probabilité d'un terme-clé candidat
        selon le modèle n-gramme du document diverge positivement par rapport à
        sa probabilité selon le modèle de référence, plus il respecte la
        propriété d'informativité (cf. équation~\ref{math:informativeness}). De
        manière similaire, plus la probabilité d'un terme-clé candidat selon le
        modèle n-gramme du document diverge positivement par rapport à sa
        probabilité selon le modèle uni-gramme du document, plus il respecte la
        propriété de grammaticalité (cf. équation~\ref{math:phraseness}). La
        divergence est exprimée en terme de coût avec la divergence
        Kullback-Leibler (cf. équation \ref{math:kullbackleibler}). Les
        termes-clés candidats sont ordonnés dans l'ordre décroissant de la somme
        des scores d'informativité et de grammaticalité, puis les $k$
        termes-clés candidats de meilleur rang sont extraits comme termes-clés.
        \begin{align}
          \textsc{Ml}(\text{\textit{candidat}} = m_1\ m_2\ \dots\ m_k) &= \prod_{i = 1}^k P(m_i | m_{i - (N - 1)} m_{i - ((N - 1) - 1)} \dots m_{i - 1}) \label{math:ml}\\
          \notag\\
          \text{informativité}(\text{\textit{candidat}}) &= \textsc{Kl}_{\text{\textit{candidat}}}(\textsc{Ml}_{\text{document}}^{N} \| \textsc{Ml}_{\text{référence}}^{N}) \label{math:informativeness}\\
          \notag\\
          \text{grammaticalité}(\text{\textit{candidat}}) &= \textsc{Kl}_{\text{\textit{candidat}}}(\textsc{Ml}_{\text{document}}^{N} \| \textsc{Ml}_{\text{document}}^{1}) \label{math:phraseness}\\
          \notag\\
          \textsc{Kl}_{\text{\textit{candidat}}}(\textsc{Ml} \| \textsc{Ml}') &= \textsc{Ml}(\text{\textit{candidat}}) \log \frac{\textsc{Ml}(\text{\textit{candidat}})}{\textsc{Ml}'(\text{\textit{candidat}})} \label{math:kullbackleibler}
        \end{align}
        \begin{figure}
          \centering

          \begin{tikzpicture}
            \node [fill=@verticalgreen] (ml_n_ref) {$\textsc{Ml}_{\textnormal{référence}}^{N}$};
            \node [fill=@verticalgreen, right=of ml_n_ref, xshift=1em] (ml_n_doc) {$\textsc{Ml}_{\textnormal{document}}^{N}$};
            \node [fill=@verticalgreen, below=of ml_n_doc] (ml_1_doc) {$\textsc{Ml}_{\textnormal{document}}^{1}$};

            \path [<->] (ml_n_ref) edge node [above, yshift=.75em] {informativité} (ml_n_doc);
            \path [<->] (ml_n_doc) edge node [right, xshift=.75em] {grammaticalité} (ml_1_doc);
          \end{tikzpicture}

          \caption{Illustration des deux propriétés d'informativité et de
                   grammaticalité induites entre trois modèles de
                   langues~\cite{tomokiyo2003languagemodel}
                   \label{fig:klml}}
        \end{figure}

        \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches:ilp}
        ~\\Tout comme \newcite{tomokiyo2003languagemodel},
        \newcite{ding2011binaryintegerprogramming} tentent de définir des
        propriétés visant à affiner l'extraction de termes-clés. Ils expriment leurs propriétés sous
        la forme de contraintes dans un système d'optimisation (programmation
        par les entiers) qui explore l'espace des solutions possibles (toutes
        les combinaisons de mots à extraire). Les contraintes sont les
        suivantes~:
        \begin{itemize}
          \item{taille: les termes-clés extraits ne doivent pas être en nombre
                supérieur à $k$~;}
          \item{couverture : les termes-clés doivent couvrir le plus possible de
                sujets abordés dans le document~;}
          \item{cohérence : les mots des termes-clés doivent être cohérents
                entre eux.}
        \end{itemize}
        La couverture de chaque sujet d'une solution est calculée avec le modèle
        \textit{Latent Dirichlet Allocation} (\textsc{Lda})~\cite{blei2003lda}.
        \textsc{Lda} est un modèle probabiliste qui permet d'expliquer des
        ensembles d'observations (ici, des mots) avec des ensembles non observés
        (ici, des sujets), eux-mêmes définis par des distributions de
        probabilités calculées à partir de données (ici, des documents). Depuis
        le modèle \textsc{Lda}, \newcite{ding2011binaryintegerprogramming}
        extraient la probabilité conditionnelle des mots des termes-clés d'une
        solution sachant chaque sujet, ce qui indique quels mots de la solution
        sont importants pour chaque sujet. L'importance des mots des termes-clés
        doit excéder un seuil donné pour chaque sujet afin que la contrainte de
        couverture soit respectée pour la solution. La contrainte de cohérence
        est calculée entre chaque paire de mots de la solution. Si deux mots
        cooccurrent, c'est-à-dire apparaissent dans le même contexte dans le
        document, plus que selon un seuil donné, alors ceux-ci peuvent être
        présents dans la même solution, sinon la solution n'est pas
        satisfaisante.
        
        Les deux contraintes réduisent le nombre de solutions
        acceptables. Il faut ensuite trouver quel ensemble de termes-clés parmi
        ces solutions est le meilleur. Pour cela, un score d'importance des mots
        est calculé et l'ensemble de termes-clés pour lequel la somme du score
        d'importance des mots est la plus élevée est extrait. Ce score est
        obtenue avec une combinaison linéaire du score \textsc{Tf-Idf} du mot,
        d'un \og{}bonus\fg{} s'il occurre dans le titre du document et d'un autre
        \og{}bonus\fg{} s'il occurre dans sa première phrase~:
        \begin{align}
          \textnormal{importance}(\textnormal{mot}) &= \alpha \times\frac{\mathlarger\sum_{d \in D} \textnormal{\textsc{Tf-Idf}}_d(\textnormal{mot})}{|D|} + \beta \times \mu_\textnormal{mot} + \gamma \times \nu_\textnormal{mot}\\
          \mu_\textnormal{mot} &=\left\{\begin{array}{ll}\mu, & \textnormal{si mot} \in T\\0, & \textnormal{sinon}\end{array}\right.\notag\\
          \nu_\textnormal{mot} &=\left\{\begin{array}{ll}\nu, & \textnormal{si mot} \in P\\0, & \textnormal{sinon}\end{array}\right.\notag
        \end{align}
        où $\alpha$, $\beta$ et $\gamma$ sont les coefficients associés à chaque
        score ($\alpha + \beta + \gamma = 1$) et où $\mu$ et $\nu$ sont les
        \og{}bonus\fg{} attribués si le mot occurre dans le titre $T$ ou dans la
        première phrase $P$ du document, respectivement.

        Paramétrée à l'aide de 50 articles journalistiques et évaluée sur 100
        autres, la méthode de \newcite{ding2011binaryintegerprogramming} atteint
        environ 70~\% de précision en moyenne, c'est-à-dire en moyenne quatre
        termes-clés corrects sur les six demandés, soit une performance très
        satisfaisante.

      \subsubsection{Méthodes par groupement}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-clustering_approaches}
        Les méthodes par groupement utilisent des groupes d'unités textuelles
        partageant une ou plusieurs caractéristiques (similarité lexicale,
        similarité sémantique, etc.).

        ~\\\newcite{matsuo2004wordcooccurrence} groupent les 30~\% de termes-clés
        candidats les plus fréquents lorsqu'ils cooccurrent (dans la phrase) avec les
        mêmes autres candidats et avec une fréquence comparable (nous parlons
        abusivement de lien sémantique), puis extraient les termes-clés en
        analysant la fréquence de cooccurrences de tous les candidats avec ces groupes.
        Leur hypothèse est qu'un terme-clé candidat est plus vraisemblablement un
        terme-clé si sa fréquence de cooccurrence avec les candidats de chaque
        groupe est plus importante que selon toute probabilité. Dans un premier
        temps, ils estiment la fréquence de cooccurrence de chaque candidat avec
        chaque groupe, puis, dans un second temps, ils mesurent le biais
        statistique $\chi^2$ entre leur estimation et la fréquence réelle
        observée (cf équation~\ref{math:chi2}). Pour estimer la fréquence de
        cooccurrences d'un candidat avec ceux d'un groupe, ils supposent qu'un
        terme-clé candidat apparaissant dans de longues phrases a le plus de
        chance de cooccurrer avec un candidat d'un des groupes. Ainsi, soit
        $n_t$ le nombre de termes-clés candidats présents dans les phrases où le
        candidat étudié apparaît et $p_g$ le nombre de candidats présents dans
        les phrases ou un candidat du groupe $g$ apparaît, alors la fréquence
        attendue entre le candidat étudié et le groupe $g$ est représenté par le
        produit $n_tp_g$.
        \begin{align}
          \chi^2(\text{\textit{candidat}}) = \sum_{g} \frac{(\text{fréquence}(\text{\textit{candidat}}, g) - n_tp_g)^2}{n_tp_g} \label{math:chi2}
        \end{align}
        
        Lors de leurs expériences, les auteurs se sont aperçus que certains
        candidats peuvent être sémantiquement liées à des candidats fréquents
        dans un domaine plus général que celui du document. En supposant que ces
        cas spéciaux soient ceux ayant le plus fort biais statistique, ils
        suppriment du $\chi^2$ l'argument maximum de la sommation~:
        \begin{align}
          \chi^2{'}(\text{\textit{candidat}}) = \chi^2 - \max_{g}\left\{\frac{(\text{fréquence}(\text{\textit{candidat}}, g) - n_tp_g)^2}{n_tp_g}\right\}
        \end{align}
        Les termes-clés extraits sont les $k$ termes-clés candidats ayant le
        plus fort biais statistique mesuré par $\chi^2{'}$.

        ~\\Dans l'algorithme KeyCluster, \newcite{liu2009keycluster} utilisent
        aussi un groupement sémantique, mais dans leur cas, ils ne considèrent
        que les mots du document (mots d'un antidictionnaire exclus). Le mot le
        plus central de chaque groupe est sélectionné comme mot de référence et
        sert à l'extraction des termes-clés: chaque terme-clé candidat contenant
        au moins un mot de référence est extrait comme terme-clé. Cette méthode
        présente l'avantage d'offrir une bonne couverture des sujets abordés
        dans un document, car tous les groupes sémantiques sont représentés par
        au moins un terme-clé. Cependant, aucune pondération n'est proposée pour
        ordonner les termes-clés. De plus, \newcite{hassan2010conundrums} ont
        montré que KeyCluster est en général moins performant que \textsc{Tf-Idf}
        (cf tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).

      \subsubsection{Méthodes à base de graphe}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        Les approches à base de graphe sont actuellement les plus populaires.
        Utilisés dans de nombreuses applications du
        \textsc{Tal}~\cite{kozareva2013textgraphs}, les graphes ont l'avantage
        de présenter de manière simple et intuitive le document.

        ~\\\newcite{mihalcea2004textrank} proposent TextRank, une méthode
        d'ordonnancement d'unités textuelles à partir d'un graphe pour le résumé
        automatique et l'extraction de termes-clés. Pour l'extraction de
        termes-clés, les n\oe{}uds du graphe sont les mots du document et les
        arêtes qui les connectent représentent leurs relations d'adjacence dans
        le document, dans une fenêtre de deux mots. Un score
        d'importance (initialisé à un), est calculé pour chaque mot à partir de
        l'algorithme itératif PageRank~\cite{brin1998pagerank}. PageRank est un
        algorithme de marche aléatoire (\textit{random walk})~: un marcheur
        aléatoire parcours le graphe de mot en mot en se déplaçant vers un mot
        qui cooccurre avec le mot courant. Le résultat du parcours du marcheur
        permet de déduire l'importance de chaque mot d'après le principe de la
        recommandation (du vote)~:  un mot est d'autant plus important s'il
        cooccurre avec un grand nombre de mots (parce qu'il est beaucoup visité
        par le marcheur) et si les mots avec lesquels il cooccurre sont eux
        aussi importants (parce qu'il a plus de chance d'être visité par le
        marcheur). Les mots les plus importants sont considérés comme des
        mots-clés, ils sont marqués dans le document et les plus longues
        séquences de mots-clés adjacents sont extraites en tant que termes-clés.
      
        Soit le graphe de cooccurrences de mots non orienté $G = (N, A)$, où les
        n\oe{}uds $N$ représentent les mots du documents, et où les arêtes $A$
        les connectent lorsqu'ils cooccurrent dans le document. L'importance de
        chaque mot $n_i$ est obtenue itérativement selon la formule TextRank
        suivante~:
        \begin{align}
          S(n_i) &= (1 - \lambda) + \lambda \times \sum_{n_j \in A(n_i)} \frac{S(n_j)}{|A(n_j)|} \label{math:textrank}
        \end{align}
        où $A(n_i)$ est l'ensemble des n\oe{}uds connectés au n\oe{}ud $n_i$ et
        où $\lambda$ est un facteur d'atténuation. Nombre réel défini entre 0 et
        1, ce dernier peut être considéré comme la probabilité pour que le
        n\oe{}ud $n_i$ soit important d'après le principe de la recommandation.
        \newcite{brin1998pagerank} suggèrent 0,85 comme valeur par défaut de
        $\lambda$. Selon eux, cette valeur est un bon compromis entre la
        précision des résultats et la vitesse de convergence de l'algorithme.

        Bien qu'intéressant, de par son intuitivité,
        \newcite{hassan2010conundrums} ont montré que TextRank est moins
        performant que \textsc{Tf-Idf} (cf
        tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).

        ~\\\newcite{wan2008expandrank} modifient TextRank et proposent
        SingleRank. Dans un premier temps, leur méthode augmente la précision de
        l'ordonnancement en utilisant une fenêtre de cooccurrences élargie
        empiriquement à dix mots et en pondérant les arêtes par le nombre de
        cooccurrences entre les deux mots qu'elles connectent. La pondération,
        notée $\textnormal{poids}(n_j, n_i)$, sert à ajuster l'importance du mot
        $n_i$ acquise à partir de sa recommandation par le mot $n_j$ (cf.
        équation~\ref{math:singlerank}). Dans un second temps, les termes-clés
        ne sont plus générés à partir des séquences de mots-clés dans le
        document, mais ordonnés à partir de la somme du score d'importance des
        mots qui les composent. Comparé à TextRank, dans les expériences de
        \newcite{hassan2010conundrums} réalisées avec quatre collections de
        données différentes, SingleRank donne de meilleurs résultats
        (cf tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison}).
        Ils restent cependant plus faibles que ceux de
        \textsc{Tf-Idf}.
        \begin{align}
          S(n_i) &= (1 - \lambda) + \lambda \times \sum_{n_j \in A(n_i)} \frac{\text{poids}(n_j, n_i) \times S(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} \text{poids}(n_j, n_k)} \label{math:singlerank}
        \end{align}

        ~\\Toujours dans le but d'améliorer l'efficacité de l'ordonnancement
        proposé par \newcite{mihalcea2004textrank}, \newcite{wan2008expandrank}
        proposent ExpandRank. ExpandRank étend SingleRank en utilisant des
        documents similaires au document analysé d'après la mesure de similarité
        vectorielle cosinus. Faisant l'hypothèse que ces documents similaires
        fournissent des informations supplémentaires relatives aux mots du
        document et aux relations qu'ils entretiennent, ExpandRank utilise les
        relations de cooccurrences observées dans les documents similaires pour
        ajouter et renforcer des arêtes dans le graphe. Dans leurs expériences
        réalisée avec une collection de 308 articles journalistiques,
        \newcite{wan2008expandrank} obtiennent des résultats au-delà de ceux de
        SingleRank. Ces résultats n'ont cependant jamais pu être reproduit et
        les expériences de \newcite{hassan2010conundrums} ne montrent
        globalement pas d'amélioration vis-à-vis de SingleRank (cf
        tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).
        %Toutefois, ses performances sont fortement liées à la
        %disponibilité de documents similaires. Leur usage peut aussi ajouter et
        %renforcer des connexions qui ne devraient pas l'être s'ils ne sont pas
        %suffisamment similaires. Pour pallier ce problème, les auteurs pondèrent
        %l'impact des documents similaires à partir leur degré de similarité avec
        %le document.

%        ~\\\newcite{tsatsaronis2010semanticrank} tentent eux aussi d'améliorer
%        TextRank. Dans leur méthode, ils créent et pondèrent une arête entre
%        deux mots si et seulement si ceux-ci sont sémantiquement liés dans
%        WordNet~\cite{miller1995wordnet} ou dans
%        Wikipedia~\cite{milne2008wikipediasemanticrelatedness} (cf.
%        équation~\ref{math:semanticrank}). WordNet est une base de données
%        lexicale représentée par un graphe de mots connectés à leurs synonymes.
%        Chaque mot connecté à un autre est considéré comme un des sens possibles
%        de ce dernier. À partir de cette représentation,
%        \newcite{tsatsaronis2010semanticrank} déterminent toutes les paires de
%        sens $P_{ij}$ possibles, ainsi que tous les chemins $C_{i, j}$ possible
%        pour atteindre un sens du mot $n_j$ à partir d'un sens du mot $n_i$. Le
%        score de similarité sémantique avec WordNet est obtenu en trouvant le
%        couple paire sémantique/chemin sémantique pour lequel le produit des
%        mesures sémantiques \textit{Semantic Compactness Measure}
%        ($\textsc{Scm}$) et \textit{Semantic Path Elaboration} ($\textsc{Spe}$),
%        introduites par \newcite{tsatsaronis2010textrelatedness}, est le plus
%        élevé (cf. équation \ref{math:wordnetsemanticrelatedness}). Dans le cas
%        où l'un des termes-clés candidats n'est pas présent dans WordNet, la
%        similarité sémantique est calculée avec les données de Wikipédia (cf.
%        équation~\ref{math:wikipediasemanticrelatedness}).
%        \begin{align}
%          \text{poids}_{j, i} &= \left\{\begin{array}{ll}
%            1 & \text{si $n_i = n_j$}\\
%            \text{Sim}_{WN}(n_i, n_j) & \text{sinon, si $n_i, n_j \in \text{WordNet}$}\\
%             \text{Sim}_{W}(n_i, n_j) &  \text{sinon, si $n_i, n_j \in \text{Wikipedia}$}\\
%            0 & \text{sinon}
%          \end{array}\right. \label{math:semanticrank}\\
%          \notag\\
%          \text{Sim}_{WN}(n_i, n_j) &= \max_{p \in P_{i, j}}\left\{\max_{c \in C_{i, j}}\left\{\textsc{Scm}(p, c) \times \textsc{Spe}(p, c)\right\}\right\} \label{math:wordnetsemanticrelatedness}\\
%          \notag\\
%          \text{Sim}_{W}(n_i, n_j) &= \frac{\log(\max(|\text{art}(i)|, |\text{art}(j)|)) - \log(|\text{art}(i) \cup \text{art}(j)|)}{\log(|\text{Wikipedia}|) - \log(\min(|\text{art}(i)|, |\text{art}(j)|))} \label{math:wikipediasemanticrelatedness}\\
%          \notag\\
%          \text{art}(i) &= \left\{\text{\textit{article}} \in \text{Wikipedia}\ |\ n_i \in \text{\textit{article}}\right\} \notag
%        \end{align}
%
%        Cette modification seule donne de moins bons résultats que TextRank.
%        Toutefois, elle améliore les résultats en combinaison avec un
%        ordonnancement biaisé par le \textsc{Tf-Idf} des mots (cf
%        équation~\ref{math:apw}) ou avec un ordonnancement dont le facteur
%        $\lambda$ est  propre à chaque mot (cf équation~\ref{math:ppr}). Ce
%        dernier est calculé selon l'apparition ou non du mot dans le titre du
%        document.
%        \begin{align}
%          S_{\text{\textsc{Tf-Idf}}}(n_i) &= \frac{1}{2} \times \left(\frac{S(n_i)}{\mathlarger{\max}_{n_j \in N}(S(n_j))} + \frac{\text{\textsc{Tf-Idf}}(t_i)}{\mathlarger{\max}_{n_j \in N}(\text{\textsc{Tf-Idf}}(t_j))}\right) \label{math:apw}\\
%          \notag\\
%          S_{\lambda}(n_i) &= (1 - \lambda_i) + \lambda_i \times \sum_{n_j \in A(n_i)} \frac{\text{poids}_{j, i} \times S_{\lambda}(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} p_{j, k}} \label{math:ppr}
%        \end{align}

        ~\\\newcite{liu2010topicalpagerank} tentent aussi d'améliorer
        SingleRank. Ils proposent
        TopicalPageRank (\textsc{Tpr}), une méthode qui cherche cette fois-ci à augmenter
        la couverture du document par les termes-clés extraits. Pour ce faire,
        ils détectent les sujets du document et ordonnent les mots en fonction
        de chaque sujet (cf figure~\ref{fig:topicalpagerank}). À l'aide du modèle
        \textsc{Lda}~\cite{blei2003lda}, ils ajustent chaque ordonnancement avec
        la probabilité conditionnelle d'un sujet donné sachant chaque mot
        (cf. équation~\ref{math:topicalpagerank}), puis donnent plus
        d'importance aux candidats dont les mots ont la plus forte importance
        (le meilleur rang) selon les sujets les plus probables dans le document
        (cf. équation~\ref{math:topicalpagerankfinalscore}).
        \begin{align}
          S(n_i, \text{\textit{sujet}}) &= (1 - \lambda) \times p(\text{\textit{sujet}} | n_i) + \lambda \times \sum_{n_j \in A(n_i)} \frac{\textnormal{poids}(n_j, n_i) \times S(n_j)}{\mathlarger{\sum}_{n_k \in A(n_j)} \textnormal{poids}(n_j, n_k)} \label{math:topicalpagerank}\\
          \textsc{Tpr}(\text{\textit{candidat}}) &= \mathlarger{\sum}_{\text{\textit{sujet}}} \left[p(\text{\textit{sujet}} | \text{\textit{document}}) \times \sum_{n \in \text{\textit{candidat}}} \text{rang}_{\text{\textit{sujet}}}(n)\right] \label{math:topicalpagerankfinalscore}
        \end{align}
        \begin{figure}[t]
          \tikzstyle{io}=[
            ellipse,
            minimum width=5cm,
            minimum height=2.5cm,
            %fill=green!20,
            %draw=green!33,
            draw=black,
            transform shape,
            font={\Huge}
          ]
          \tikzstyle{component}=[
            text centered,
            %thick,
            rectangle,
            minimum width=13.5cm,
            minimum height=2cm,
            %fill=cyan!20,
            %draw=cyan!33,
            draw=black,
            transform shape,
            font={\Huge\bfseries}
          ]
          \centering
          \begin{tikzpicture}[thin,
                              align=center,
                              scale=.31,
                              node distance=1cm,
                              every node/.style={text centered, transform shape}]
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \node [draw, circle, minimum width=1cm] (n1) {};
            \node [draw, circle, minimum width=1cm, right=of n1] (n2) {};
            \node [draw, circle, minimum width=1cm, above=of n1.north east] (n3) {};
            \node [draw, circle, minimum width=1cm, below=of n2.north east, xshift=2cm] (n4) {};
            \node [draw, circle, minimum width=1cm, above=of n2.south east, xshift=2cm] (n5) {};
            \node [draw, circle, minimum width=1cm, above=of n5, xshift=-2cm] (n6) {};
            \node [below=of n1, xshift=.5cm, yshift=.5cm] (g) {\Huge graphe};
            %
            \path (n1) edge (n2);
            \path (n1) edge (n3);
            \path (n2) edge (n3);
            \path (n2) edge (n4);
            \path (n2) edge (n5);
            \path (n3) edge (n5);
            \path (n3) edge (n6);
            \path (n5) edge (n6);
            %
            \draw ($(n1.west)+(-.5cm,4.2cm)$) rectangle ($(n4.east)+(.5cm,-1cm)$);
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \node [draw, circle, minimum width=1cm, right=of n5, xshift=6.2cm, yshift=2.2cm] (nn1) {};
            \node [draw, circle, minimum width=1cm, right=of nn1] (nn2) {};
            \node [draw, circle, minimum width=1cm, above=of nn1.north east] (nn3) {};
            \node [draw, circle, minimum width=1cm, below=of nn2.north east, xshift=2cm] (nn4) {};
            \node [draw, circle, minimum width=1cm, above=of nn2.south east, xshift=2cm] (nn5) {};
            \node [draw, circle, minimum width=1cm, above=of nn5, xshift=-2cm] (nn6) {};
            \node [below=of nn1, xshift=.5cm, yshift=.5cm] (t1) {\Huge sujet 1};
            %
            \path (nn1) edge (nn2);
            \path (nn1) edge (nn3);
            \path (nn2) edge (nn3);
            \path (nn2) edge (nn4);
            \path (nn2) edge (nn5);
            \path (nn3) edge (nn5);
            \path (nn3) edge (nn6);
            \path (nn5) edge (nn6);
            %
            \draw ($(nn1.west)+(-.5cm, 4.2cm)$) rectangle ($(nn4.east)+(.5cm,-1cm)$);
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \node [draw, circle, minimum width=1cm, right=of n5, xshift=6.2cm, yshift=-4.8cm] (nnn1) {};
            \node [draw, circle, minimum width=1cm, right=of nnn1] (nnn2) {};
            \node [draw, circle, minimum width=1cm, above=of nnn1.north east] (nnn3) {};
            \node [draw, circle, minimum width=1cm, below=of nnn2.north east, xshift=2cm] (nnn4) {};
            \node [draw, circle, minimum width=1cm, above=of nnn2.south east, xshift=2cm] (nnn5) {};
            \node [draw, circle, minimum width=1cm, above=of nnn5, xshift=-2cm] (nnn6) {};
            \node [below=of nnn1, xshift=.5cm, yshift=.5cm] (t2) {\Huge sujet n};
            %
            \path (nnn1) edge (nnn2);
            \path (nnn1) edge (nnn3);
            \path (nnn2) edge (nnn3);
            \path (nnn2) edge (nnn4);
            \path (nnn2) edge (nnn5);
            \path (nnn3) edge (nnn5);
            \path (nnn3) edge (nnn6);
            \path (nnn5) edge (nnn6);
            %
            \draw ($(nnn1.west)+(-.5cm, 4.2cm)$) rectangle ($(nnn4.east)+(.5cm,-1cm)$);
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \node [io, right=of nn5, xshift=2.5cm, yshift=-.5cm] (ordonnancement1) {Ordonnancement 1};
            \node [io, right=of nnn5, xshift=2.5cm, yshift=-.5cm] (ordonnancement2) {Ordonnancement n};
            \node [draw, circle, right=of ordonnancement1, xshift=2cm] (add) {\Huge\textbf{+}};
            \node [io, right=of add, xshift=2cm] (keyphrases) {Termes-clés};
            \node [component, right=of n5, xshift=2cm, yshift=10cm] (lda) {\textsc{Lda}};
            \node [io, left=of lda, xshift=-2cm] (document) {document};
            \draw [dashed] ($(nnn1.west)+(-1cm, 11.6cm)$) rectangle ($(nnn4.east)+(1cm,-1.5cm)$);
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \node [below=of document, yshift=-4.7cm] (graph_top) {};
            \node [right=of graph_top, xshift=1.7cm, yshift=-3.15cm] (graph_right) {};
            \node [below=of lda, yshift=-1.1cm] (topic_graph_top) {};
            \node [right=of graph_right, xshift=4.7cm] (topic_graph_left) {};
            \node [right=of topic_graph_left, xshift=2cm, yshift=-.1cm] (dots) {\Huge...};
            \node [right=of topic_graph_top, xshift=1.9cm, yshift=-3.9cm] (topic1_graph_right) {};
            \node [right=of topic_graph_top, xshift=1.9cm, yshift=-10.9cm] (topic2_graph_right) {};
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            \path [->] (document) edge (graph_top);
            \path [->] (document) edge (lda);
            \path [->] (lda) edge (add);
            \path [->] (graph_right) edge (topic_graph_left);
            \path [->] (topic1_graph_right) edge (ordonnancement1);
            \path [->] (topic2_graph_right) edge (ordonnancement2);
            \path [->] (lda) edge (topic_graph_top);
            \path [->] (ordonnancement1) edge (add);
            \path [->] (ordonnancement2) edge (add);
            \path [->] (add) edge (keyphrases);
          \end{tikzpicture}
          \caption{Illustration du fonctionnement de TopicalPageRank~\cite{liu2010topicalpagerank}
                   \label{fig:topicalpagerank}}
        \end{figure}

        Contrairement aux précédentes méthodes à base de graphe que nous avons
        présenté, TopicalPageRank améliore \textsc{Tf-Idf} (cf
        tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).

        ~\\Dans la continuité du travail de \newcite{liu2010topicalpagerank},
        \newcite{zhang2013wordtopicmultirank} proposent WordTopic-MultiRank.
        WordTopic-MultiRank ajoute les sujets de \textsc{Lda} aux n\oe{}uds du
        graphe de cooccurrences et effectue un seul ordonnancement, qui tient
        compte de tous les sujets en même temps. Cet ordonnancement est réalisé
        conjointement entre les mots et les sujets, de sorte que~:
        \begin{itemize}
          \item{un sujet est d'autant plus important s'il est connecté à un
                grand nombre de mots importants~;}
          \item{un mot est d'autant plus important s'il cooccurre avec un grand
                nombre de mots importants et s'il est connecté à un grand nombre
                de sujets importants.}
        \end{itemize}
        Comme pour SingleRank et TopicalPageRank, les termes-clés candidats sont
        ensuite ordonnés d'après le score d'importance des mots qu'ils
        contiennent.

        L'ordonnancement conjoint (\textit{co-ranking}) à partir de modèles à
        base de graphe est une technique qui commence à susciter de l'intérêt en
        \textsc{Tal}~\cite{wan2011corankingsummarization,yan2012corankingtweetrecommendation,liu2014corankingopinionmining}.
        \newcite{zhang2013wordtopicmultirank} sont les premiers à l'appliquer à
        l'extraction de termes-clés. Cette approche est intéressante, car elle
        tient compte à la fois du contexte local du mot (le document) et de son
        contexte global (les sujets de la collection de données analysée par
        \textsc{Lda}).

        Comparés aux résultats de TopicalPageRank,
        \newcite{zhang2013wordtopicmultirank} montrent que l'ordonnancement
        conjoint des mots et des sujets est légèrement plus performant que la
        combinaison de multiples ordonnancements influencés par chaque sujet
        (cf tableau~\ref{tab:state_of_the_art-unsupervised_methods_comparison},
        page~\pageref{tab:state_of_the_art-unsupervised_methods_comparison}).

      \subsubsection{Bilan des méthodes non supervisées}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-bilan}
        Les méthodes non supervisées d'extraction de termes-clés utilisent des
        techniques très différentes, mais reposent toutes sur des statistiques
        simples~: la fréquence d'occurrence des mots dans le document, leur
        fréquence documentaire et la fréquence de cooccurrence entre eux. Les
        méthodes purement statistiques mises à part, c'est le mode de
        représentation du document et son analyse qui différencie les méthodes
        non-supervisées.
        
        Le graphe est le mode de représentation le plus utilisé actuellement.
        Représentant les relations de cooccurrences entre les mots du document,
        il est analysé à l'aide d'un algorithme de marche aléatoire qui attribue
        un score d'importance à chaque n\oe{}ud (mot). Ce graphe et la manière
        dont il est analysé sont très intuitifs, mais nous notons quelques
        défauts. Nous reprochons aux méthodes actuelles de modéliser le document
        par ses mots et leurs relations, et donc de déterminer l'importance des
        mots au lieu de celle des termes-clés candidats. Par ailleurs, bien que
        la notion de sujet ait été introduite, nous nous demandons s'il ne
        serait pas plus juste de grouper les candidats qui représentent le même
        sujet. Il est possible que l'ordonnancement gagne en précision en
        faisant de la sorte.

    \subsection{Approche supervisée}
    \label{subsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction}
      Les méthodes supervisées apprennent principalement à classer les
      termes-clés en tant que \og{}terme-clé\fg{} ou \og{}non terme-clé\fg{}.
      Leur apprentissage se fait à partir d'une collection d'apprentissage (ou
      d'entraînement) dont les documents sont manuellement indexés par des
      termes-clés. Les termes-clés candidats sont sélectionnés dans ces
      documents, ils servent d'exemples lorsqu'il font partie de l'indexation
      manuelle (de référence), de contre-exemples sinon et certaines de leurs
      caractéristiques (traits) sont analysées pour apprendre à discriminer
      \og{}termes-clés\fg{} et \og{}non termes-clés\fg{}.

      Les méthodes proposées emploient des classifieurs. Elles diffèrent selon
      ces classifieurs et les traits qu'elles utilisent. Nous présentons ces
      différentes méthodes en les groupant par classifieur et les présentons en
      soulignant les traits choisis.

      \subsubsection{Classifieurs probabilistes}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-probabilistic_models}
        Les classifieurs probabilistes utilisent des distributions de
        probabilités de divers traits. Pour l'extraction des termes-clés d'un
        document, ces distributions sont combinées pour déterminer le score de
        vraisemblance, la probabilité, de chaque terme-clé candidat en tant que
        \og{}terme-clé\fg{}. À l'instar des méthodes non supervisées, les
        méthodes supervisées utilisant un classifieur probabiliste peuvent
        ordonner les termes-clés candidats classés \og{}termes-clés\fg{} selon
        leur probabilité afin d'extraire un nombre donné de termes-clés, si
        nécessaire (pour évaluer les méthodes, entre autre).

        ~\\\textsc{Kea}~\cite{witten1999kea} est la méthode d'extraction de
        termes-clés la plus populaire. Elle effectue une classification naïve
        bayesienne pour attribuer le score de vraisemblance de chaque terme-clé
        candidat. Elle combine les distributions probabilistes de deux traits~:
        la première position du candidat dans le document et son poids
        \textsc{Tf-Idf}. L'intuition de \newcite{witten1999kea} est que les
        termes-clés ont une certaine importance vis-à-vis du document (leur
        poids \textsc{Tf-Idf}) et qu'ils font leur première apparition dans des
        zones similaires du document.

        ~\\\textsc{Kea} est une approche très simple qui considère tous les
        traits comme indépendants (principe de la classification naïve
        bayésienne). Sa simplicité et ses bonnes performances ont suscité un
        grand intérêt et de nombreuses variantes ont été proposées. C'est le cas
        de la méthode de \newcite{frank1999keafrequency}, qui utilise comme
        trait supplémentaire le nombre de fois qu'un terme-clé candidat est un
        exemple, c'est-à-dire un terme-clé de l'indexation manuelle d'un
        document de la collection d'entraînement. Appliquée
        en domaines de spécialité, cette variante de \textsc{Kea} favorise
        l'extraction de termes-clés déjà utilisés pour une extraction de
        termes-clés homogène et améliore significativement les performances de
        \textsc{Kea}. Par ailleurs, \newcite{frank1999keafrequency} montrent que
        les performances de \textsc{Kea} se stabilisent à partir de 50 documents
        d'apprentissage, alors que les performances de leur méthode augmente
        toujours lorsque le nombre de documents d'apprentissage augmente. Cette
        méthode est donc intéressante dans un contexte semi-automatique. Si ses
        sorties sont corrigées manuellement,
        et si chaque document nouvellement indexé est ajouté pour refaire
        l'apprentissage, alors sa précision doit toujours augmenter, contrairement à
        celle de \textsc{Kea}.
        
        ~\\\newcite{turney2003keacoherence} reprend lui aussi \textsc{Kea}.
        Comme \newcite{ding2011binaryintegerprogramming}, il améliore la
        cohérence entre les termes-clés candidats extraits (cf
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-statistical_approaches:ilp}).
        Pour cela,
        il ajoute une deuxième classification naïve bayesienne après celle de
        \textsc{Kea}. La première classification sert à ordonner les candidats
        selon leur vraisemblance et la deuxième attribue un nouveau score de
        vraisemblance aux candidats, de sorte que les $L$ meilleurs candidats
        aient un meilleur score de vraisemblance s'ils ont un fort lien
        sémantique avec un ou plusieurs candidat(s) parmi les $K$ meilleurs ($K
        < L$). La force du lien sémantique est représenté par deux scores (soit
        $2 \times K$ traits)~: le nombre de pages Web contenant les deux
        candidats et le nombre de titres de pages Web contenant les deux
        candidats.

        ~\\\newcite{nguyen2007keadocumentstructure} améliorent \textsc{Kea} pour
        l'extraction de termes-clés à partir d'articles scientifiques. Faisant
        l'hypothèse que les termes-clés n'ont pas une répartition homogène dans
        les sections d'un article scientifique, ils notent les occurrences des
        termes-clés candidats dans les sections génériques d'un article
        scientifique (résumé, introduction, motivations, état de l'art et
        conclusion), puis utilisent le vecteur d'occurrences ainsi construit
        comme trait supplémentaire. De cette manière, les termes-clés
        apparaissant dans les sections les plus susceptibles de contenir des
        termes-clés ont un score de vraisemblance plus élevé.
        
        ~\\\newcite{caragea2014citationenhancedkeyphraseextraction} utilisent
        eux aussi un classifieur naïf bayesien. Leur méthode repose sur le même
        constat que \newcite{wan2008expandrank}~: l'extraction de termes-clés
        peut bénéficier des informations extraites dans des documents en liens
        avec le document à partir duquel les termes-clés doivent être extraits
        (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}).
        Travaillant avec des articles scientifiques,
        \newcite{caragea2014citationenhancedkeyphraseextraction} utilisent le
        réseau de citations des documents afin de déterminer leur influence sur
        les autres documents et inversement. En plus des traits existant, ils
        ajoutent un \textsc{Tf-Idf} calculés à partir de la fréquence de chaque
        candidat dans les contextes citationnels, ainsi que deux traits binaires
        indiquant si (1) le candidat occurre dans une phrase (du document) qui cite
        un autre document ou si (2) il occurre dans une phrase d'un autre document
        qui cite le document. Bien que leur méthode obtient de meilleures
        performances que \textsc{Kea}, les auteurs mettent en évidence un défaut
        de leur approche. Considérant les contextes citationnels, un document
        qui vient d'être publié ne peut pas avoir été cité par d'autres articles
        et leur extraction de termes-clés pour un document tend à s'améliorer
        dans le temps.

        ~\\Contrairement à \newcite{witten1999kea}, qui utilisent un classifieur
        naïf bayésien et considèrent que tous les traits sont indépendants,
        \newcite{sujian2003maximumentropy} proposent une méthode utilisant un
        classifieur d'entropie maximale. Ce classifieur cherche parmi plusieurs
        distributions (une pour chaque trait) laquelle a la plus forte entropie.
        La distribution ayant la plus forte entropie est par définition celle
        qui contient le moins d'informations, ce qui la rend moins arbitraire et
        donc plus appropriée pour l'extraction automatique de termes-clés.
        Chaque trait se voit donc attribuer un poids, de sorte que les traits
        les moins arbitraires ont le plus de poids dans la classification. En
        plus des traits cités pour les méthodes précédentes, et à l'instar de
        \newcite{nguyen2007keadocumentstructure}, ils tirent parti d'autres
        traits liés à la nature des documents qu'ils traitent. Ainsi, pour des
        articles journalistiques ils utilisent leur type (information, sport,
        etc.) et la catégorie d'entité nommée des candidats s'ils en sont une
        (personne, pays, organisme, etc.).

        ~\\Plus récemment, le travail de \newcite{zhang2008crfkeywordextraction}
        montre l'applicabilité d'un \textsc{Crf} (\textit{Conditional Random
        Field}) à la tâche d'extraction de termes-clés. Ce classifieur a
        l'intéressante capacité à prédire des séquences de classes, soit à
        étiqueter tout un document en donnant les classes suivantes pour chaque
        mot~: \og{}terme-clé\fg{}, \og{}début d'un terme-clé\fg{} et \og{}partie
        d'un terme-clé\fg{} (cf
        exemple~\ref{ex:crf_tagging}). \newcite{zhang2008crfkeywordextraction}
        reprend les traits présentés précédemment (\textsc{Tf-Idf}, première position,
        section d'article scientifique, etc.) et y ajoute le contexte de
        chaque mot. Nous trouvons cette notion de contexte dans les méthodes non
        supervisées à base de graphe (cf.
        section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}
        page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-unsupervised_keyphrase_extraction-graph_based_approaches}),
        mais il s'agit de la première fois que nous trouvons celle-ci dans une
        méthode supervisée. Le fonctionnement particulier du \textsc{Crf}
        (étiquetage de séquences de mots) se
        prête plus à l'utilisation du contexte que les autres classifieurs.

        \begin{example}\label{ex:crf_tagging}
          Étiquetage par \textsc{Crf} de la phrase \og{}L'objectif est de
          fournir une définition de base du concept linguistique de la cause en
          observant son expression.\fg{} de la
          figure~\ref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation}
          (page\pageref{fig:main-state_of_the_art-introduction-example_keyphrase_annotation})
          avec les étiquettes \texttt{TC\_D} (début d'un terme-clé),
          \texttt{TC\_P} (partie d'un terme-clé), \texttt{N} (nom), \texttt{V}
          (verbe), \texttt{PP} (participe présent), \texttt{Pro} (pronom),
          \texttt{Det} (déterminant), \texttt{Pre} (préposition)~:\\
          \begin{center}\vspace{-1em}
            \parbox{.8\linewidth}{
              \texttt{L'/Det objectif/N est/V de/Pre fournir/V une/Det
              définition/N de/Pre base/N du/Pre \textbf{concept/TC\_D
              linguistique/TC\_P} de/Pre la/Det cause/N en/Pre observant/PP
              son/Pro expression/N ./PONCT}
            }
          \end{center}\vspace{.25em}
        \end{example}

      \subsubsection{Arbres de décision}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-decision_trees}
        Les arbres de décision sont des classifieurs dont les branches
        représentent des tests sur des traits des candidats. Ces tests routent
        les candidats vers les feuilles de l'arbre représentant leur classe
        respective (\og{}terme-clé\fg{} ou \og{}non terme-clé\fg{}).

        ~\\Dans son article sur l'apprentissage pour l'extraction automatique de
        termes-clés, \newcite{turney1999learningalgorithms} entraîne plusieurs
        arbres de décision (technique de \textit{random forest}) et réduit la
        tâche d'extraction de termes-clés à un vote. Les arbres de décision
        classent indépendamment chaque candidat et les candidats majoritairement
        classés \og{}terme-clé\fg{} sont extraits comme termes-clés. Parmi les
        nombreux traits qu'utilise \newcite{turney1999learningalgorithms}, les
        plus novateurs sont des traits binaires qui visent des catégories
        grammaticales précises~: \og{}contient un nom propre~?\fg{},
        \og{}contient un verbe usuel~?\fg{} et \og{}se termine par un
        adjectif~?\fg{}. Contrairement aux autres travaux, celui de
        \newcite{turney1999learningalgorithms} est aussi l'un des seuls à
        décliner les traits sur deux niveaux de granularité~: le candidat (grain
        expression) et chacun de ses mots (grain mot).

        ~\\\newcite{ercan2007lexicalchains} utilisent eux aussi des arbres de
        décision pour extraire les termes-clés. Les termes-clés sont ici
        restreints aux mots-clés. L'aspect novateur de leur méthode est l'usage
        de chaînes lexicales pour la définition de nouveaux traits
        discriminants. Une chaîne lexicale est un graphe de mots liés entre eux
        hiérarchiquement (cf. figure~\ref{fig:lexical_chain}).
        \newcite{ercan2007lexicalchains} tiennent compte des relations
        hiérarchiques de méronymie\footnote{Méronyme~: mot dont le signifié est
        une sous-partie de celui d'un autre mot, son holonyme. Par exemple,
        \og{}bras\fg{} est un méronyme de
        \og{}corps\fg{}.}/holonymie\footnote{Holonyme~: mot dont le signifié est
        composé de celui d'un autre mot, son méronyme.},
        d'hyponymie\footnote{Hyponyme~: mot dont le signifié est
        plus spécifique que celui d'un autre mot, son
        hyperonyme.}/hyperonymie\footnote{Hyperonyme~: mot dont le signifié est
        plus général que celui d'un autre mot, son hyponyme.} et de synonymie,
        auxquelles ils donnent un poids (4 pour la méronymie/holonymie, 7 pour
        l'hyponymie/hyperonymie et 10 pour la synonymie). Chaque mot se voit
        attribuer quatre traits correspondant à quatre scores obtenus à partir
        des poids des relations~:
        \begin{enumerate}
          \item{Score de la chaîne lexicale~: somme du poids de toutes les
                relations de la chaîne lexicale~;}
          \item{Score du mot dans la chaîne lexicale~: somme du poids de toutes
                les relations du mot avec les autres mots de la chaîne
                lexicale~;}
          \item{Couverture de la chaîne lexicale~: différence entre la dernière
                occurrence, dans le document, d'un mot de la chaîne lexicale
                avec la première occurrence, dans le document, d'un mot de la
                chaîne lexicale~;}
          \item{Couverture du mot et de ses voisins dans la chaîne lexicale~:
                identique à la couverture de la chaîne lexicale, mais en tenant
                compte uniquement du mot et de ses voisins dans la chaîne.}
        \end{enumerate}
        \begin{figure}
          \centering
          \begin{tikzpicture}
            \node (programme) {programme};
            \node [below=of programme] (logiciel) {logiciel};
            \node [right=of logiciel, xshift=2em] (paquetage) {paquetage};
            \node [left=of logiciel, xshift=-2em] (application) {application};
            \node [below=of application] (app) {app};

            \draw (programme) -- (logiciel);
            \draw (programme) -- (application);
            \draw (programme) -- (paquetage);
            \draw (application) -- (logiciel);
            \draw (logiciel) -- (paquetage);
            \draw [dashed] (application) -- (app);

            % legend
            \node [scale=.75, right=of app, xshift=12em, yshift=3em] (legend_title) {\underline{Légende~:}};
            \node [scale=.75, below=of legend_title, xshift=-1.5em, yshift=3em] (begin_hyponym) {};
            \node [scale=.75, right=of begin_hyponym, xshift=-1em] (end_hyponym) {: hyponymie/hyperonymie};
            \node [scale=.75, below=of begin_hyponym, yshift=3em] (begin_synonym) {};
            \node [scale=.75, right=of begin_synonym, xshift=-1em] (end_synonym) {: synonymie};

            \draw (legend_title.north  -| end_hyponym.east) rectangle (end_synonym.south -| legend_title.west);

            \draw (begin_hyponym) -- (end_hyponym);
            \draw [dashed] (begin_synonym) -- (end_synonym);
          \end{tikzpicture}
          \caption{Exemple de chaîne lexicale~\cite{ercan2007lexicalchains}
                   \label{fig:lexical_chain}}
        \end{figure}

        ~\\Tirant aussi profit d'arbres de décision, \newcite{lopez2010humb}
        sont les vainqueurs de la campagne d'évaluation
        SemEval-2010~\cite{kim2010semeval}. Ils extraient les termes-clés en
        deux étapes. Tout d'abord, ils ordonnent les termes-clés candidats avec
        les arbres de décision, puis ils les ré-ordonnent à la manière de
        \newcite{turney2003keacoherence}~: les candidats bien classés
        initialement sont d'autant mieux classés qu'ils ont un fort lien
        sémantique avec d'autres candidats bien classés initialement.

      \subsubsection{Séparateurs à vastes marges}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-svms}
        Les séparateurs à vastes marges (\textsc{Svm}) projettent les exemples
        et les contre-exemples du corpus d'entraînement sur un plan selon la
        valeur de leurs traits, puis construisent l'hyperplan qui les sépare.
        Pour classer les termes-clés candidats d'un document, il suffit ensuite
        de les projeter sur ce même plan et d'utiliser l'hyperplan appris.

        ~\\\newcite{zhang2006svm} utilisent un \textsc{Svm} pour extraire les
        termes-clés à partir de ce qu'ils appellent le contexte global et le
        contexte local des termes-clés candidats. Ils représentent le contexte
        global d'un candidats par son \textsc{Tf-Idf}, sa première position et
        ses occurrences dans différentes parties du document, tandis qu'ils
        représentent son contexte local par sa catégorie grammaticale et trois
        traits encore jamais utilisés auparavant. Les deux premiers traits sont
        déterminés à partir des dépendances entre les mots.
        L'un dénote le nombre de fois que le candidat modifie un mot
        et l'autre dénote le nombre de fois qu'un mot modifie le candidat. Le
        dernier trait s'appelle le \textsc{Tf-Idf} contextuel, il s'agit de la
        somme du \textsc{Tf-Idf} de tous les mots qui cooccurrent avec le
        candidat. Ce dernier trait est intéressant, il indique si un candidat occurre dans un
        contexte important vis-à-vis du document.

        ~\\\newcite{jiang2009rankingsvm} extraient les termes-clés à partir d'un
        type particulier de \textsc{Svm}, baptisé
        \textsc{Svm}$^\textnormal{rank}$. \textsc{Svm}$^\textnormal{rank}$
        construit plusieurs hyperplans qui permettent d'ordonner les termes-clés
        candidats. Utilisant le score \textsc{Tf-Idf} des candidats, leur taille
        (en nombre de mots), leur première position, leur entropie et d'autres
        traits, le travail de \newcite{jiang2009rankingsvm} montre que le
        classifieur \textsc{Svm}$^\textnormal{rank}$ est plus performant qu'un
        \textsc{Svm} ou qu'un classifieur naïf bayesien utilisant les mêmes
        traits.

        ~\\\newcite{eichler2010keywe} extraient eux aussi les termes-clés à
        partir d'un \textsc{Svm}$^\textnormal{rank}$. Ils apprennent le
        \textsc{Svm}$^\textnormal{rank}$ avec trois valeurs pour le rang. La
        valeur maximale est attribuée aux exemples d'un document
        d'apprentissage, la valeur minimale aux contre-exemples du document et
        une valeur intermédiaire à ses contre-exemples qui sont des exemples
        d'autres documents d'apprentissage. Cette approche peut être assimilé à
        celle de \newcite{frank1999keafrequency}, qui estime qu'un terme-clé
        candidat fréquemment utilisé comme terme-clé dans le corpus
        d'apprentissage est plus vraisemblablement un terme-clé. Quant aux
        traits utilisés pour entraîner le \textsc{Svm}$^\text{rank}$, le plus
        notable se réfère à Wikipedia. L'intuition des auteurs est que si un
        terme-clé candidat fait l'objet d'un article Wikipedia, alors il est
        plus vraisemblablement un terme-clé.

      \subsubsection{Perceptrons multicouches}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-neural_network}
        Les perceptrons multicouches sont des classifieurs qui émulent la
        biologie de l'apprentissage humain. Ce sont des réseaux de neurones
        répartis sur au moins trois couches. Les neurones de la première couche
        représentent les traits d'un candidat (un neurone par trait), ceux des
        couches intermédiaires (couches cachées) propagent des scores obtenus
        selon la valeur des traits et ceux de la dernière couche donnent un
        score final pour chaque classe \og{}terme-clé\fg{} et \og{}non
        terme-clé\fg{} (un neurone par classe). La classe ayant le plus haut
        score est celle du terme-clé candidat pour lequel correspond la valeur
        des traits. Optionnellement, les scores calculés pour chaque classe
        peuvent être utilisés pour déterminer le degré de confiance du
        perceptron pour la classe qu'il a
        attribué~\cite{denker1991neuralnetprobability}.
        
        ~\\\newcite{sarkar2010neuralnetwork} utilisent un perceptron
        multicouche. Les traits qu'ils emploient concernent la fréquence du
        candidat, sa position et sa taille (en nombre de mots) ainsi que celle
        de ses mots (en nombre de caractères). Cette dernière est rarement
        utilisée comme trait pour l'extraction supervisée de termes-clés.
        L'hypothèse de \newcite{sarkar2010neuralnetwork} se fonde sur la loi de
        \newcite{zipf1935zipflaw}~: les mots courts étant plus fréquents que les
        mots longs, alors la taille d'un mot est une indication de sa rareté,
        donc de sa spécificité vis-à-vis du document.
        
        À la manière des méthodes utilisant un classifieur probabiliste,
        \newcite{sarkar2010neuralnetwork} ordonnent les termes-clés candidats
        afin d'extraire un nombre donné de termes-clés lorsque nécessaire. Pour
        cela, ils utilisent le degré de confiance attribué à la
        classification~\cite{denker1991neuralnetprobability}. En premier sont
        placés les candidats classés \og{}terme-clé\fg{}, dans l'ordre
        décroissant du score de confiance~; en dernier sont placés les candidats
        classés \og{}non terme-clé\fg{}, dans l'ordre croissant du score
        de confiance. Ainsi, s'il y a plus de \og{}terme-clé\fg{} que requis,
        alors ceux ayant la plus haute confiance sont extrait. Inversement, s'il
        n'y a pas suffisamment de \og{}terme-clé\fg{}, alors des candidats
        classés \og{}non terme-clé\fg{} avec une confiance faible sont ajoutés.

      \subsubsection{Algorithmes génétiques}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-genex}
        Les algorithmes génétiques sont des algorithmes qui donnent une solution
        approchée à un problème d'optimisation. Ce type d'algorithme
        n'effectue pas de classification et n'est pas nécessairement supervisé.

        ~\\\newcite{turney1999learningalgorithms} propose une méthode
        supervisée, GenEx, dont les paramètres sont valués par un algorithme
        génétique, appelé \textit{Genitor}. Un algorithme d'extraction de
        termes-clés, appelé \textit{Extractor}, est appliqué sur le corpus
        d'apprentissage avec des paramètres initiaux, puis le \textit{Genitor}
        fait évoluer la valeur de ses paramètres jusqu'à trouver celle qui
        maximise les performances de l'extraction. L'extraction des termes-clés
        d'un document se fait ensuite avec l'\textit{Extractor} et ses
        paramètres configurés par le \textit{Genitor}. Les paramètres appris
        sont principalement des seuils limitant la taille des candidats, le
        nombre de mots importants à considérer pour filtrer les candidats, ou
        encore le nombre de termes-clés à extraire. Ce sont aussi des facteurs
        multiplicateurs utilisés notamment pour le calcul de l'importance des
        mots et des candidats.

      \subsubsection{Bilan des méthodes supervisées}
      \label{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-conclusion}
        Les méthodes supervisées reformulent la tâche d'extraction de
        termes-clés en une tâche de classification des termes-clés candidats en
        tant que \og{}terme-clé\fg{} ou \og{}non terme-clé\fg{}. Pour cela,
        elles utilisent des classifieurs et proposent divers traits pour
        discriminer les candidats. C'est par les traits qu'elles proposent que
        les méthodes supervisées rivalisent. Certains traits sont génériques et
        communs à la majorité des méthodes. C'est le cas de la position de la
        première occurrence du candidat et de son score \textsc{Tf-Idf}.
        D'autres traits sont spécifiques à certains types de documents. Par
        exemple, la section dans laquelle occurre un terme-clé est un trait
        discriminant pour l'extraction de termes-clés à partir d'articles
        journalistiques.

  \section{Assignement automatique de termes-clés}
  \label{sec:main-state_of_the_art-automatic_keyphrase_assignment}
    L'assignement automatique de termes-clés fait l'objet de moins de travaux
    que l'extraction. Il s'agit aussi d'une tâche plus difficile, car elle doit
    assigner des entrées d'un vocabulaire contrôlé en tant que termes-clés d'un
    document indépendamment de leur présence dans celui-ci.

    ~\\\newcite{medelyan2006kea++} sont les premiers à proposer une
    méthode capable de faire de l'assignement de termes-clés. Celle-ci,
    \textsc{Kea}++, améliore la méthode d'extraction \textsc{Kea}. Pour cela,
    elle utilise un thésaurus\footnote{Thésaurus~: liste de termes regroupés
    selon les concepts d'un domaine de connaissance qu'ils représentent.} du
    domaine de spécialité à traiter. Il est mis à profit de deux manières~:
    d'abord pour sélectionner les termes-clés candidats, ensuite pour améliorer
    la classification.

    \newcite{medelyan2006kea++} décident de réaliser l'assignement en se
    limitant aux termes-clés qui occurrent dans le document. Ils sélectionnent
    donc toutes les unités textuelles qui correspondent à une entrée du
    thésaurus. À l'instar des candidats de \textsc{Kea}, ceux de \textsc{Kea++}
    sont ensuite classés en tant que \og{}terme-clé\fg{} ou \og{}non
    terme-clé\fg{} par un classifieur naïf bayesien. Ce classifieur est le même
    que celui de \textsc{Kea}, à l'exception d'un trait supplémentaire~: le
    nombre de relations sémantiques qu'entretient le candidat avec les autres
    dans le thésaurus. De cette manière, ils déterminent l'importance du
    candidats dans le domaine.

    Évalué avec des documents du domaine agroalimentaire et le thésaurus
    Agrovoc\footnote{\url{http://aims.fao.org/vest-registry/vocabularies/agrovoc-multilingual-agricultural-thesaurus}},
    \textsc{Kea}++ double les performances de \textsc{Kea}. Le travail de
    \newcite{medelyan2006kea++} montre donc l'efficacité d'une méthode
    d'assignement de termes-clés, même limitée.

    ~\\\newcite{liu2011vocabularygap} proposent une méthode que nous assimilons
    à de l'assignement de termes-clés. Ils font l'hypothèse qu'un document et
    ses termes-clés expriment le même contenu, mais dans deux langues
    différentes~: l'une expressive et l'autre synthétique. Ils reformulent donc
    la tâche d'indexation par termes-clés en une tâche de traduction du langage
    naturel vers celui des termes-clés.
    
    \newcite{liu2011vocabularygap} apprennent un modèle de traduction
    \textit{\textsc{Ibm} Model-1}~\cite{brown1993ibmmodel1} à l'aide de paires
    de mots~: un mot du langage naturel, l'autre du langage synthétique des
    termes-clés. Les mots du langage naturel sont extraits du document et les
    mots du langage synthétique sont extrait soit de son titre, soit de son
    résumé. Le modèle de traduction peut ensuite être appliqué aux termes-clés
    candidats, pour réaliser de l'extraction de termes-clés à la manière des
    classifieurs probabilistes présentés dans la
    section~\ref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-probabilistic_models}
    (page~\pageref{subsubsec:main-state_of_the_art-automatic_keyphrase_extraction-supervised_keyphrase_extraction-probabilistic_models}),
    ou être utilisé pour générer une traduction, c'est-à-dire des termes-clés.

    Parce qu'elle est capable de générer des termes-clés, cette méthode est
    intéressante. Cependant, il ne s'agit là que d'un premier pas vers
    l'assignement de termes-clés, car aucun vocabulaire n'est utilisé pour
    contrôler la génération.

    ~\\Alors que l'assignement attribue des termes-clés d'une qualité certifiée
    grâce au vocabulaire contrôlé, cette tâche n'est encore que très peu
    étudiée. Seulement deux travaux originaux s'en rapprochent. L'un se fonde
    sur un vocabulaire contrôlé (un thésaurus), mais ne va pas au-delà du
    contenu du document~; l'autre génère des termes-clés qui n'occurrent pas
    nécessairement dans le document, mais ne se fonde pas sur un vocabulaire
    contrôlé.

  %-----------------------------------------------------------------------------

  \section{Évaluation automatique de l'indexation par termes-clés}
  \label{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation}
    Pour montrer l'apport des nouvelles méthodes d'indexation par termes-clés,
    celles-ci sont comparées automatiquement aux méthodes existantes dans un
    processus d'évaluation \og{}à la Cranfield\fg{}
    \citep{voorhees2002philosophy}. Chaque méthode est appliquée à un ensemble
    de documents de test (collection de test), les termes-clés qu'elle fournit
    pour chaque document sont mis en correspondance \og{}exacte\fg{} avec les
    termes-clés attribués manuellement aux documents (jugements de
    référence)\footnote{Les termes-clés de référence sont soit les termes-clés
    des auteurs, soit les termes-clés de lecteurs (personnes lambda ou
    professionnelles), soit la combinaison des deux.}, puis évalués selon
    différents critères. Pour chaque critère, c'est la méthode qui obtient les
    meilleurs résultats en moyenne qui est jugée la plus efficace.
  
    La mise en correspondance des termes-clés extraits/assignés aux termes-clés
    de référence sert à distinguer ceux qui sont corrects de ceux qui ne le sont
    pas. Nous parlons, respectivement, de vrais positifs et de faux positifs (cf
    tableau~\ref{tab:confusion_matrix}). De la même manière, toute autre unité
    textuelle non extraite/assignée par la méthode automatique est appelée faux
    négatif si elle correspond à un terme-clé de référence, et vrai négatif dans
    le cas contraire.
    
    D'après le paradigme d'évaluation \og{}à la Cranfield\fg{}, un
    vrai positif ne peut être considéré comme tel que s'il est strictement
    identique à un terme-clé de référence. Cette correspondance \og{}exacte\fg{}
    induit une évaluation pessimiste des méthodes d'indexation automatique par
    termes-clés, car les variantes des termes-clés de référence sont jugées
    incorrectes sans distinction avec les autres faux positifs. Pour minimiser
    ce problème, toutes les évaluations réalisées dans la littérature tiennent
    compte uniquement du radical des mots des termes-clés, c'est-à-dire leur
    forme privée de tout suffixe (par exemple, \og{}empir\fg{} est le radical de
    \og{}empirique\fg{}). Les différences d'accords en genre et en
    nombre sont donc autorisées, ainsi que toute autre dérivation suffixale.
    Cette approche n'est pas parfaite, car elle fait parfois correspondre des
    mots porteurs de sens différents (par exemple, \og{}empire\fg{} et
    \og{}empirique\fg{} possèdent la même racine \og{}empir\fg{}). Une approche
    plus rigoureuse serait d'utiliser les lemmes des mots, c'est-à-dire leur
    forme conventionnelle (celle que nous retrouvons dans  un dictionnaire).
    Contrairement à la racinisation, qui applique seulement des règles de
    désuffixage (par exemple, \textit{-es $\rightarrow$ -} afin d'enlever l'accord du
    féminin pluriel), la lemmatisation requiert un lexique et doit être
    appliquée selon le context du mot à analyser (par exemple, le lemme de
    \og{}couvant\fg{} est soit \og{}couvant\fg{}, soit \og{}couver\fg{} selon
    son contexte). Pour des raisons pratiques, la lemmatisation n'est donc jamais
    utilisée pour l'évaluation automatique de termes-clés.
    \begin{table}
      \begin{center}
        \begin{tabular}{cc|cc}
          \toprule
          \multicolumn{2}{c|}{} & \multicolumn{2}{c}{\textbf{Jugement de référence}}\\
          \multicolumn{2}{c|}{} & \og{}terme-clé\fg{} & \og{}non terme-clé\fg{}\\
          \hline
          \multirow{2}{*}{\textbf{Résultat}} & \og{}terme-clé\fg{} & vrai positif ($\textsc{Vp}$) & faux positif ($\textsc{Fp}$)\\
          & \og{}non terme-clé\fg{} & faux negatif ($\textsc{Fn}$) & vrai negatif ($\textsc{Vn}$)\\
          \bottomrule
        \end{tabular}
        \caption{Matrice de confusion pour l'évaluation des méthodes
                 d'indexation automatique par termes-clés
                \label{tab:confusion_matrix}}
      \end{center}
    \end{table}

    Les critères d'évaluation utilisés pour évaluer et comparer les méthodes
    d'indexation par termes-clés sont la précision, le rappel et la f1-mesure.
    La précision capture la capacité d'une méthode à minimiser les erreurs (cf
    équation~\ref{math:precision}). Inversement, le rappel mesure la capacité de
    la méthode à fournir le plus possible de termes-clés corrects (cf
    équation~\ref{math:recall}). Quant à la f1-mesure, elle évalue le compromis
    entre précision et rappel, c'est-à-dire la capacité de la méthode à extraire
    un maximum de termes-clés corrects tout en faisant un minimum d'erreurs (cf
    équation~\ref{math:f1_measure}).
    \begin{align}
      \text{précision} &= \frac{\#\textsc{Vp}}{\#\textsc{Vp} + \#\textsc{Fp}} \label{math:precision}\\
      \text{rappel} &= \frac{\#\textsc{Vp}}{\#\textsc{Vp} + \#\textsc{Fn}} \label{math:recall}\\
      \text{f-mesure} &= (1 + \beta^2) \times \frac{\text{précision} \times \text{rappel}}{(\beta^2 \times \text{précision}) + \text{rappel}} \label{math:f_measure}\\
      \text{f1-mesure} &= 2 \times \frac{\text{précision} \times \text{rappel}}{\text{précision} + \text{rappel}} \label{math:f1_measure}
    \end{align}
      
%    En \textsc{Ri}, il est courant d'évaluer les méthodes selon la qualité de
%    leur ordonnancement. Prenons l'exemple des moteurs de recherche, si deux
%    moteurs de recherche doivent fournir dix documents répondant à une requête
%    et que les deux systèmes n'ont que deux propositions pertinentes, alors ils
%    ont tous les deux la même précision (20~\%) et le même rappel (20~\%).
%    Toutefois, si le premier système classe ces documents en premier et que le
%    second système les classe aux positions neuf et dix, alors le premier
%    système est le meilleur. Lorsque les méthodes d'indexation par termes-clés
%    le permettent, il est intéressant de mesurer leur capacité à classer en
%    premier les vrais positifs. Dans la littérature, quatre mesures, dont
%    certaines empruntées à la \textsc{Ri}, sont utilisées~: la \textsc{Map}
%    (\textit{Mean Average Precision}), la Bpref (\textit{Binary Preference
%    Measure}), la R-précision et la \textsc{Mrr} (\textit{Mean Reciprocal
%    Rank}). La \textsc{Map} mesure pour chaque document la moyenne de la
%    précision à chaque rang ($\textnormal{précision}@\textnormal{rang}$) d'un
%    vrai positif (cf. équation~\ref{math:average_precision}). Avec la Bpref, la
%    \textsc{Map} est la seule mesure qui tient compte de tous les vrais
%    positifs. La Bpref est une mesure similaire à la \textsc{Map} qui,
%    contrairement à cette dernière, s'abstrait de la connaissance de tous les
%    termes-clés de référence (cf. équation~\ref{math:bpref}). Elle peut donc,
%    par exemple, s'appliquer dans le cadre d'évaluations manuelles où chaque
%    terme-clé fourni par la méthode est jugé correct ou non par un évaluateur
%    humain et où tous les termes-clés du document ne sont pas connus. La
%    R-précision est une variante de la précision. Elle mesure cette dernière
%    dans le cas optimal (tous les termes-clés sont fournis et il n'y a aucune
%    erreur), soit au rang $R$, où $R$ est égal au nombre de termes-clés de
%    référence du document (cf. équation~\ref{math:r_precision}). Quant à la
%    \textsc{Mrr}, celle-ci est la moins précise, elle ne s'intéresse qu'au
%    meilleur rang obtenu pour un vrai positif (cf.
%    équation~\ref{math:reciprocal_rank}).
%    \begin{align}
%      \textsc{Map} &= \frac{\mathlarger{\sum}_{\text{\textit{terme-clé}} = \textsc{Vp}}\text{précision}@\text{rang}(\text{\textit{terme-clé}})}{\#\textsc{Vp} + \#\textsc{Fn}} \label{math:average_precision}\\
%      \notag \\
%      \text{Bpref} &= \sum_{\text{\textit{terme-clé}} = \textsc{Vp}}{1 - \frac{|\text{\textit{terme-clé}'}\ \text{de meilleur rang que}\ \text{\textit{terme-clé}}|}{\#\textsc{Vp} + \#\textsc{Fp}}} \label{math:bpref}\\
%      \notag \\
%      \text{R-précision} &= \text{précision}@(\#\textsc{Vp} + \#\textsc{Fn}) \label{math:r_precision}\\
%      \notag \\
%      \textsc{Mrr} &= \frac{1}{\text{argmin}(\forall \text{\textit{terme-clé}} = \textsc{Vp}, \text{rang}(\text{\textit{terme-clé}}))} \label{math:reciprocal_rank}
%    \end{align}

%    Toutes les mesures présentées précédemment respectent le paradigme de
%    l'évaluation \og{}à la Cranfield\fg{}. Cependant, associer des termes-clés à
%    un document est une tâche subjective~\cite{hasan2014state_of_the_art}, il
%    n'existe donc pas une solution unique. Des travaux proposent d'apporter plus
%    de souplesse à la comparaison entre termes-clés résultant d'une méthode et
%    termes-clés de référence en tenant compte de leur
%    chevauchement~\cite{zesch2009rprecision,kim2010rprecision}. Ces travaux
%    ne sont toutefois pas utilisés travaux récents.

  %-----------------------------------------------------------------------------

  \section{Conclusion}
  \label{sec:main-state_of_the_art-automatic_evaluation_of_keyphrase_annotation-conclusion}
    Nous avons présenté la tâche d'indexation par termes-clés, de la sélection
    des termes-clés candidats aux différentes méthodes d'extraction et
    d'assignement de termes-clés, en passant par le processus d'évaluation
    automatique de ces dernières.

    La sélection des termes-clés candidats est une étape quasi-systématique de
    l'extraction automatique de termes-clés. Ne s'agissant cependant pas du
    c\oe{}ur de la tâche, la définition de nouvelle méthodes de sélection est
    négligée au profit de méthodes de sélection simples (sélection de n-grammes,
    \textit{chunks nominaux} ou séquences de noms et d'adjectifs). Toutefois,
    l'idée que l'indexation par termes-clés gagnerait en performances si les
    candidats sélectionnés étaient moins nombreux, c'est-à-dire contiendraient
    moins d'erreurs, semble faire consensus auprès des chercheurs qui s'y
    intéressent~\cite{huang2006semanticnetworkstructureanalysis,wang2014keyphraseextractionpreprocessing}. La méthode qui
    consiste à définir des patrons grammaticaux, tels que celui pour
    sélectionner les plus longues séquences de noms et d'adjectifs, pourrait
    être utilisée pour sélectionner des candidats en s'intéressant plus en
    profondeur aux classes grammaticales employées dans les termes-clés, ainsi
    qu'à d'autres propriétés linguistiques de leurs composants.

    Le c\oe{}ur de la tâche d'indexation automatique par termes-clés est
    réalisé de deux manières différentes~: soit les termes-clés sont extraits
    depuis le contenu du document, soit ils sont assignés en puisant dans un
    vocabulaire contrôlé. Dans la littérature, l'extraction fait l'objet de plus
    de travaux que l'assignement. Elle est plus simple à mettre en \oe{}uvre,
    car elle analyse les unités textuelles présentent dans le document, tandis
    que l'assignement doit pouvoir déterminer si une entrée du vocabulaire
    contrôlé (n'occurrant pas nécessairement dans le document) est importante
    vis-à-vis de celui-ci. Par ailleurs, la seule méthode réalisant actuellement
    l'assignement se limite aux entrées présentent dans le document, tant il
    peut parfois être difficile d'établir le lien entre celles qui n'y sont pas
    et le contenu du document.

    L'évaluation des méthodes d'indexation par termes-clés est généralement
    effectuée de manière automatique. Comparé à un jugement de référence unique,
    le résultat d'une méthode d'indexation par termes-clés est évalué en termes
    de précision, qui est d'autant plus élevée s'il y a le moins d'erreurs, de
    rappel, qui est d'autant plus élevée s'il y a beaucoup de termes-clés
    positifs, et de f1-mesure, qui est le compromis entre précision et rappel.
    Ce modèle d'évaluation présente l'avantage d'être utilisable dès lors que
    des données de test sont disponibles. La comparaison à un jugement de
    référence unique rend cependant l'évaluation pessimiste. Lorsque les
    conditions le permettent, une évaluation manuelle reste indispensable pour
    mieux mesurer les forces et les faiblesses d'une méthode d'indexation par
    termes-clés.

