\section{État de l'art}
\label{sec:etat_de_l_art}
  % Quel est le fonctionnement général des méthodes d'extraction automatique de
  % termes-clés ?
  L'extraction automatique de termes-clés est une tâche répartie en quatre
  étapes. Les documents sont traités un par un. Ils sont tout d'abord enrichis
  linguistiquement (segmentés en phrases, segmentés en mots, étiquetés en
  parties du discours, etc.), puis des termes-clés candidats en sont extraits et
  classifiés, ou ordonnés, afin de pouvoir sélectionner leurs termes-clés (cf.
  figure~\ref{fig:etapes_de_l_extraction_de_termes_cles}). L'extraction des
  termes-clés candidats et leur classification/ordonnancement sont les deux
  étapes auxquels nous nous intéressons dans cet article. En effet, la
  classification/l'ordonnancement des termes-clés candidats est le c\oe{}ur de
  la tâche d'extraction de termes-clés et ses performances dépendent de la
  qualité des candidats préalablement extraits.
  \begin{figure}
    \tikzstyle{io}=[
      ellipse,
      minimum width=5cm,
      minimum height=2cm,
      fill=green!20,
      draw=green!33,
      transform shape,
      font={\huge}
    ]
    \tikzstyle{component}=[
      text centered,
      thick,
      rectangle,
      minimum width=11cm,
      minimum height=2.5cm,
      fill=cyan!20,
      draw=cyan!33,
      transform shape,
      font={\huge\bfseries}
    ]

    \centering
    \begin{tikzpicture}[thin,
                        align=center,
                        scale=.45,
                        node distance=2cm,
                        every node/.style={text centered, transform shape}]
      \node[io] (document) {document};
      \node[component] (preprocessing) [right=of document] {Prétraitement Linguistique};
      \node[component] (candidate_extraction) [below=of preprocessing] {Extraction des candidats};
      \node[component] (candidate_classification_and_ranking) [below=of candidate_extraction] {
        \begin{tabular}{r|lcl}
          Classification & des candidats\\
          Ordonnancement &\\
        \end{tabular}
      };
      \node[component] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés};
      \node[io] (keyphrases) [right=of keyphrase_selection] {termes-clés};

      \path[->, thick] (document) edge (preprocessing);
      \path[->, thick] (preprocessing) edge (candidate_extraction);
      \path[->, thick] (candidate_extraction) edge (candidate_classification_and_ranking);
      \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
      \path[->, thick] (keyphrase_selection) edge (keyphrases);
    \end{tikzpicture}
    \caption{Les quatre principales étapes de l'extraction automatique de
             termes-clés. \label{fig:etapes_de_l_extraction_de_termes_cles}}
  \end{figure}

  \subsection{Extraction de termes-clés candidats}
  \label{subsec:extraction_de_termes_cles_candidats}
    % Quel est l'objectif ?
    L'objectif de l'extraction de termes-clés candidats est de réduire l'espace
    des solutions possibles aux seules unités textuelles ayant des
    particularités semblables à celles des termes-clés tels qu'ils peuvent être
    donnés par des humains. Deux avantages directs à cela sont la réduction du
    temps de calcul nécessaire et la suppression d'unités textuelles non
    pertinentes pouvant engendrer du bruit affectant les performances de
    l'extraction de termes-clés. Pour distinguer les différents candidats
    extraits, nous définissons deux catégories~: les candidats positifs, qui
    sont de réels termes-clés, et les candidats non positifs, qui ne sont pas de
    réels termes-clés. Parmi les candidats non positifs, nous distinguons aussi
    deux catégories~: les candidats porteurs d'informations utiles à la
    promotions de candidats positifs et les candidats non pertinents, qui sont
    considérés comme des erreurs d'extraction.

    % Quels sont les différentes méthodes utilisées pour extraire les
    % termes-clés candidats ?
    Dans les travaux précédents concernant l'extraction automatique de
    termes-clés, trois méthodes d'extraction de candidats sont classiquement
    utilisées~: l'extraction de n-grammes filtrés avec une liste de mots outils,
    l'extraction d'unités minimales de sens ayant pour tête un nom (chunks
    nominaux) ou l'extraction des unités textuelles respectant certains patrons
    syntaxiques.

    L'extraction de n-grammes consiste en l'extraction de séquences ordonnées
    de $n$ mots. Cette extraction est très exhaustive, elle fournit une grande
    quantité de termes-clés candidats, maximisant ainsi la quantité de
    candidats positifs ou porteurs d'informations, mais aussi la quantité de
    candidats non pertinents. Pour supprimer un grand nombre de candidats non
    pertinents, il est courant d'utiliser une liste de mots outils
    (conjonctions, prépositions, mots usuels, etc.). Une unité textuelle
    contenant un mot outils au début ou à la fin ne doit pas être considérée
    comme un terme-clé candidat. Bien que l'extraction de n-grammes filtrés
    fournisse un ensemble bruité de candidats, elle est encore largement
    utilisée parmi les méthodes supervisées d'extraction automatique de
    termes-clés~\cite{witten1999kea,turney1999learningalgorithms,hulth2003keywordextraction}.
    Ceci est dû au fait que leur phase d'apprentissage les rend plus robustes et
    donc moins sensibles aux bruits que les autres méthodes.

    L'extraction de chunks nominaux consiste en l'extraction d'unités
    minimales de sens ayant pour tête un nom. Contrairement aux n-grammes, les
    chunks nominaux sont toujours des unités textuelles grammaticalement
    correctes. D'un point de vue linguistique, l'extraction de chunks nominaux
    est donc plus justifiée que l'extraction de n-grammes filtrés. Cependant
    son caractère plus restrictif ne permet pas d'extraire autant de candidats
    positifs qu'avec les n-grammes. Il est donc important de s'assurer que les
    propriétés des chunks nominaux sont en accord avec les propriétés des
    termes-clés tels qu'ils peuvent être donnés par des humains. Les expériences
    menées par \newcite{hulth2003keywordextraction} et
    \newcite{eichler2010keywe} avec les chunks nominaux montrent une
    amélioration des performances vis-à-vis de l'usage des n-grammes.
    Cependant, \newcite{hulth2003keywordextraction} montre aussi qu'en tirant
    partie de l'étiquetage en parties du discours des termes-clés candidats,
    l'extraction supervisée de termes-clés à partir de n-grammes donne des
    performances au-dessus de celles obtenues avec les chunks nominaux.

    L'extraction d'unités textuelles respectant certains patrons syntaxiques
    permet l'extraction de candidats qui sont syntaxiquement
    contrôlés. Du fait de la syntaxe contrôlée, cette extraction est, tout comme
    l'extraction de chunks nominaux, plus fondée linguistiquement
    que la simple extraction de n-grammes filtrés. Alors que
    \newcite{hulth2003keywordextraction} extraient des candidats avec les
    patrons de termes-clés les plus fréquents (plus de 10 occurrences) dans une
    collection de documents annotés, d'autres chercheurs tels que
    \newcite{wan2008expandrank} se concentrent uniquement sur les plus longues
    séquences de noms (noms propres inclus) et d'adjectifs. Pour des méthodes
    non-supervisées telles que la notre, l'extraction des séquences de noms et
    d'adjectifs est intéressante, car elle nécessite ni des données
    supplémentaires, ni une adaptation particulière pour une langue donnée,
    tel que c'est le cas pour l'extraction des chunks nominaux.

    % Que veut-on apporter ?
    Dans le but d'améliorer la qualité des candidats extraits à partir
    d'articles scientifique, \newcite{kim2009termextraction} proposent un
    filtrage des candidats en fonction de leur spécificité vis-à-vis du document
    analysé. Cette spécificité est déterminée en fonction du rapport entre la
    fréquence d'un candidat dans le document et le nombre de documents, d'une
    collection, dans lesquels il est présent \cite[TF-IDF]{jones1972tfidf}.
    Intuitivement, un candidat très fréquent dans le document analysé est
    d'autant plus spécifique à celui-ci s'il est présent dans très peu d'autres
    documents. Ce type d'approche est intéressant, mais cela suppose que les
    documents traitées aient une forte cohérence de domaine. Les documents de
    nos collections de données ne répondent pas tous à ce critère, nous ne
    pouvons donc pas appliquer cette méthode, qui en plus requière des documents
    supplémentaires et la définition d'un seuil pour le filtrage.

  \subsection{Classification/Ordonnancement des termes-clés candidats}
  \label{subsec:classification_ordonnancement_des_termes_cles_candidats}
    % Quel est l'objectif ?
    L'étape de classification/ordonnancement intervient après l'extraction des
    termes-clés candidats. Son rôle est de déterminer quels sont, parmi les
    candidats, les termes-clés du document analysé. La classification est
    majoritairement utilisée par les méthodes supervisées. Les méthodes
    non-supervisées, quant à elles,  effectuent en général un ordonnancement des
    candidats. Dans cet article, nous nous intéressons aux méthodes
    non-supervisées, nous ne présentons donc que ces dernières. De plus, les
    différences notables entre différentes méthodes supervisées résident
    principalement dans le choix du classifieur (classifieur naïf bayésien,
    arbres de décisions, perceptron multi-couches, etc) ou des traits (TF-IDF,
    première position, parties du discours, etc.).

    % Quels sont les différentes méthodes non-supervisées existantes pour
    % l'extraction de termes-clés ?
    % Quels sont les inconvénients des méthodes actuelles ?
    % Que veut-on apporter ?
    Les méthodes non-supervisées d'extraction automatique de termes-clés
    emploient des techniques très différentes, allant du simple usage de mesures
    statistiques~\cite{jones1972tfidf,paukkeri2010likey} au groupement des mots
    par fréquence de co-occurrences~\cite{liu2009keycluster}, en passant par
    l'utilisation de modèles de langues obtenus à partir de données
    non-annotées~\cite{tomokiyo2003languagemodel}, ou encore la construction
    d'un graphe de co-occurrences~\cite{mihalcea2004textrank}. Puisque la
    méthode que nous présentons dans cet article est une méthode dite
    \og à base de graphe~\fg, nous nous intéressons ici à cette dernière
    catégorie de méthodes.

    \newcite{mihalcea2004textrank} proposent une méthode d'ordonnancement
    d'unités textuelles à partir d'un graphe. Leur méthode, utilisée pour le
    résumé automatique et l'extraction de termes-clés, s'inspire de la méthode
    PageRank~\cite[Google]{brin1998pagerank} qui détermine l'importance de pages
    Web grâce à celles qui s'y réfèrent, et celles auxquelles elles se réfèrent.
    Le plus une page Web est citée par d'autres, le plus elle est importante, et
    le plus elle est importante, le plus elle donne d'importance aux pages Web
    auxquelles elle fait référence. Cette notion de référence entre les pages
    Web est représentée par un graphe dans lequel les n\oe{}uds sont des pages
    Web et les références sont les liens entre elles. Ensuite, une mesure de
    centralité, inspirée de la mesure de centralité eigenvector, est appliquée
    pour ordonner les pages Web par importance. Pour l'extraction de termes-clés
    avec TextRank, les pages Web sont remplacées par les mots (nom et adjectifs)
    du document analysé et les liens entre eux symbolisent leur(s)
    co-occurrence(s) dans une fenêtre de 2 mots. Les mots sont ordonnés par
    importance et les $k$ meilleurs, les mots clés, servent à la génération des
    termes-clés. Pour ce faire, les mots-clés sont marqués dans le documents et
    les plus longues séquences de mots-clés adjacents sont extraits comme
    termes-clés. Dans cette méthode, la précision de l'ordonnancement dépend de
    la qualité du graphe qui elle même dépend de la fenêtre de co-occurrences.
    La définition de cette fenêtre est sujette à une intervention manuelle et
    peut aussi dépendre des propriétés des documents analysés. Dans nos travaux,
    nous tentons de nous abstraire de cette fenêtre.

    \newcite{wan2008expandrank} proposent la méthode SingleRank. Celle-ci
    présente deux améliorations à TextRank. Dans un premier temps, les auteurs
    pondèrent les liens de co-occurrence par le nombre de co-occurrences
    calculées avec une fenêtres maintenant définit à 10 mots (par exemple, un
    mot co-occurrent deux fois avec un autre est relié à celui-ci par un poids
    de 2). Ce poids est ensuite utilisé pour transférer plus ou moins
    d'importance lors de l'application de l'algorithme d'ordonnancement de
    TextRank.
    %Ce nouvel ordonnancement utilise plus d'informations présentes dans le
    %document analysé et est dotant plus efficace quand le document analysé est
    %de grande taille.
    Dans un second temps, les termes-clés ne sont plus générés, mais ordonnés à
    partir de la somme du score d'importance des mots qu'ils contiennent. Bien 
    que la méthode SingleRank donne, dans la majorité des cas, des résultats
    meilleurs que ceux de TextRank, faire la somme du score d'importance des
    mots pour ordonner les candidats est une approche maladroite. En effet, cela
    a pour effet de faire monter dans le classement des candidats qui se
    recouvrent. Ainsi, dans le document \textit{as\_2002\_000700ar} de la
    collection DEFT (voir la section~\ref{sec:evaluation}), le candidat positif
    \og bio-politique~\fg\ est classé neuvième, alors que les autres candidats
    contenant \og bio-politique~\fg\ plus d'autres mots non nécessairement
    importants occupent les classements 2 à 8. Dans nos travaux nous
    ordonnons les termes-clés candidats en tenant compte de l'importance du
    sujet qu'ils représentent puis choisissons un représentant par sujet, nous
    évitons ainsi le problème rencontré avec SingleRank.

    Toujours dans l'optique d'utiliser plus d'informations pour améliorer
    l'efficacité de l'ordonnancement, \newcite{wan2008expandrank} étendent
    SingleRank en utilisant des documents voisins (similaires) du document en
    cours d'analyse. Leur approche (ExpandRank) consiste à observer les
    co-occurrences dans les documents similaires afin de renforcer ou ajouter
    des liens dans le graphe initial. Cependant, en fonction de la similarité
    entre le document analysé et certains documents voisins, des liens non
    pertinents peuvent être ajoutés. Pour y remédier, les auteurs utilisent le
    score de similarité entre les deux documents comme facteur d'atténuation de
    l'ajout ou du renforcement de liens. Cette approche donne des résultats au
    delà de ceux de SingleRank, mais il est important de noter que ses
    performances sont fortement liées à la présence de documents supplémentaires
    pertinents.

    A l'instar de \newcite{wan2008expandrank},
    \newcite{tsatsaronis2010semanticrank} tentent d'améliorer TextRank en
    modifiant le processus de création des liens entre les n\oe{}uds du graphe.
    Dans leur approche, un lien entre deux mots est créé et pondéré en fonction
    du lien sémantique de ces derniers selon WordNet~\cite{miller1995wordnet} ou
    Wikipedia~\cite{milne2008wikipediasemanticrelatedness}. Les expériences
    menées par les auteurs montrent de moins bons résultats que TextRank.
    Toutefois, en biaisant l'ordonnancement en faveur des mots apparaissant dans
    le titre du document analysé ou bien en ajoutant le TF-IDF dans le calcul de
    l'importance des mots, leur méthode est capable de donner de meilleurs
    résultats que TextRank.

    L'usage de sujets dans le processus d'ordonnancement avec TextRank est à
    l'origine proposé par \newcite{liu2010topicalpagerank}. Reposant sur un
    modèle LDA~\cite[Latent Dirichlet Allocation]{blei2003lda}, leur méthode
    effectue des ordonnancements biaisés par les sujets du document, puis
    fusionne les rangs des mots dans chaque ordonnancement afin d'obtenir un
    ordonnancement global. Dans notre travail, nous émettons aussi l'hypothèse
    que le sujet auquel appartient une unité textuelle doit jouer un rôle majeur
    dans le processus d'ordonnancement. Cependant, nous tentons de nous
    abstraire de l'usage de documents supplémentaires et n'utilisons donc pas le
    modèle LDA. De plus, il nous semble plus judicieux d'effectuer un seule
    ordonnancement, en prenant directement en compte l'appartenance d'une unité
    textuelle à un sujet particulier.

