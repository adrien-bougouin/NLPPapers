\section{État de l'art}
\label{sec:etat_de_l_art}
  TopicRank faisant partie des méthodes non-supervisées, l'état de l'art
  présenté ici se focalise sur cette catégorie de méthodes.
  % Quel est le fonctionnement général des méthodes d'extraction automatique de
  % termes-clés ?
  L'extraction automatique non-supervisée de termes-clés est une tâche répartie
  en quatre étapes. Les documents sont traités un par un. Ils sont tout d'abord
  enrichis linguistiquement (segmentés en phrases, segmentés en mots, étiquetés
  en parties du discours, etc.), des termes-clés candidats en sont extraits,
  puis ordonnés afin de ne sélectionner que les plus pertinents (cf.
  figure~\ref{fig:etapes_de_l_extraction_de_termes_cles}). L'extraction des
  termes-clés candidats et leur ordonnancement sont les deux étapes auxquels
  nous nous intéressons dans cet article. En effet, la l'ordonnancement des
  termes-clés candidats est le c\oe{}ur de la tâche d'extraction de termes-clés
  et ses performances dépendent de la qualité des candidats préalablement
  extraits.
  \begin{figure}
    \tikzstyle{io}=[
      ellipse,
      minimum width=5cm,
      minimum height=2cm,
      fill=green!20,
      draw=green!33,
      transform shape,
      font={\huge}
    ]
    \tikzstyle{component}=[
      text centered,
      thick,
      rectangle,
      minimum width=11cm,
      minimum height=2cm,
      fill=cyan!20,
      draw=cyan!33,
      transform shape,
      font={\huge\bfseries}
    ]

    \centering
    \begin{tikzpicture}[thin,
                        align=center,
                        scale=.45,
                        node distance=2cm,
                        every node/.style={text centered, transform shape}]
      \node[io] (document) {document};
      \node[component] (preprocessing) [right=of document] {Prétraitement Linguistique};
      \node[component] (candidate_extraction) [below=of preprocessing] {Extraction des candidats};
      \node[component] (candidate_classification_and_ranking) [below=of candidate_extraction] {Ordonnancement des candidats};
      \node[component] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés};
      \node[io] (keyphrases) [right=of keyphrase_selection] {termes-clés};

      \path[->, thick] (document) edge (preprocessing);
      \path[->, thick] (preprocessing) edge (candidate_extraction);
      \path[->, thick] (candidate_extraction) edge (candidate_classification_and_ranking);
      \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
      \path[->, thick] (keyphrase_selection) edge (keyphrases);
    \end{tikzpicture}
    \caption{Les quatre principales étapes de l'extraction automatique de
             termes-clés. \label{fig:etapes_de_l_extraction_de_termes_cles}}
  \end{figure}

  \subsection{Extraction de termes-clés candidats}
  \label{subsec:extraction_de_termes_cles_candidats}
    % Quel est l'objectif ?
    L'objectif de l'extraction de termes-clés candidats est de réduire l'espace
    des solutions possibles aux seules unités textuelles ayant des
    particularités semblables à celles des termes-clés tels qu'ils peuvent être
    donnés par des humains. Deux avantages directs à cela sont la réduction du
    temps de calcul nécessaire à l'extraction des termes-clés et la suppression
    d'unités textuelles non pertinentes pouvant engendrer du bruit affectant
    les performances de la méthode. Pour distinguer les différents candidats
    extraits, nous définissons deux catégories~: les candidats positifs, qui
    sont présents dans les références de nos collection de données, et les
    candidats non positifs, qui n'y sont pas. Parmi les candidats non positifs,
    nous distinguons aussi deux catégories~: les candidats porteurs
    d'informations utiles à la promotions de candidats positifs et les candidats
    non pertinents, que nous considérons comme des erreurs d'extraction.

    % Quels sont les différentes méthodes utilisées pour extraire les
    % termes-clés candidats ?
    Dans les travaux précédents concernant l'extraction automatique de
    termes-clés, trois méthodes d'extraction de candidats sont classiquement
    utilisées~: l'extraction de n-grammes filtrés avec une liste de mots outils,
    l'extraction de chunks nominaux ou l'extraction des unités textuelles
    respectant des patrons syntaxiques prédéfinis.

    L'extraction de n-grammes consiste en l'extraction de toutes les séquences
    ordonnées de $n$ mots. Cette extraction est très exhaustive, elle fournit
    un grand nombre de termes-clés candidats, maximisant ainsi la quantité de
    candidats positifs ou porteurs d'informations, mais aussi la quantité de
    candidats non pertinents. Pour pallier en partie ce problème, il est courant
    d'utiliser une liste de mots outils (conjonctions, prépositions, mots
    usuels, etc.). Un n-gramme contenant un mot outil au début ou à la fin ne
    doit pas être considéré comme un terme-clé candidat. Cette extraction de
    n-grammes filtrés est encore largement utilisée parmi les méthodes
    supervisées~\cite{witten1999kea,turney1999learningalgorithms,hulth2003keywordextraction},
    celles-ci étant robustes et peu sensibles aux bruits, du fait de leur phase
    d'apprentissage.

    L'extraction de chunks nominaux consiste en l'extraction d'unités
    minimales de sens ayant pour tête un nom. Contrairement aux n-grammes, les
    chunks nominaux sont toujours des unités textuelles grammaticalement
    correctes. D'un point de vue linguistique, l'extraction de chunks nominaux
    est donc plus justifiée que l'extraction de n-grammes filtrés. Les
    expériences menées par \newcite{hulth2003keywordextraction} et
    \newcite{eichler2010keywe} avec les chunks nominaux montrent une
    amélioration des performances vis-à-vis de l'usage des n-grammes.
    Cependant, \newcite{hulth2003keywordextraction} constate qu'en tirant partie
    de l'étiquetage en parties du discours des termes-clés candidats,
    l'extraction supervisée de termes-clés à partir de n-grammes donne des
    performances au-dessus de celles obtenues avec les chunks nominaux.

    L'extraction d'unités textuelles respectant des patrons syntaxiques permet
    de contrôler avec précision la nature des candidats extraits (par exemple,
    les chunks nominaux). De ce fait cette extraction est, tout comme
    l'extraction de chunks nominaux, plus fondée linguistiquement que la simple
    extraction de n-grammes filtrés. \newcite{hulth2003keywordextraction}
    choisie d'extraire des candidats avec les patrons des termes-clés les plus
    fréquents (plus de 10 occurrences) dans sa collection d'apprentissage,
    tandis que d'autres chercheurs tels que \newcite{wan2008expandrank} se
    concentrent uniquement sur les plus longues séquences de noms (noms propres
    inclus) et d'adjectifs. Pour des méthodes non-supervisées telles que la
    notre, l'extraction des séquences de noms et d'adjectifs est intéressante,
    car elle ne nécessite ni données supplémentaires, ni adaptation particulière
    pour une langue donnée (tel que c'est le cas pour l'extraction des chunks
    nominaux, par exemple).

    % Que veut-on apporter ?
    Dans le but d'améliorer la qualité des candidats extraits à partir
    d'articles scientifique, \newcite{kim2009termextraction} proposent un
    filtrage des candidats en fonction de leur spécificité vis-à-vis du document
    analysé. Cette spécificité est déterminée par rapport à la fréquence d'un
    candidat dans le document et le nombre de documents, d'une collection, dans
    lesquels il apparaît~\cite[TF-IDF]{jones1972tfidf}. Intuitivement, un
    candidat très fréquent dans le document analysé est d'autant plus spécifique
    à celui-ci s'il est présent dans très peu d'autres documents. Cette approche
    est intéressant, mais elle requière des documents  supplémentaires et la
    définition d'un seuil pour le filtrage. Dans le cas de TopicRank, nous
    tentons de nous abstraire de l'usage d'autres documents que celui qui est
    analysé, cette méthode d'extraction de candidats n'est donc pas consistante
    avec nos objectifs.

  \subsection{Ordonnancement des termes-clés candidats}
  \label{subsec:ordonnancement_des_termes_cles_candidats}
    % Quel est l'objectif ?
    L'étape d'ordonnancement intervient après l'extraction des termes-clés
    candidats. Son rôle est de déterminer quels sont, parmi les candidats, les
    termes-clés du document analysé.
    % Quels sont les différentes méthodes non-supervisées existantes pour
    % l'extraction de termes-clés ?
    % Quels sont les inconvénients des méthodes actuelles ?
    % Que veut-on apporter ?
    Les méthodes non-supervisées d'extraction automatique de termes-clés
    emploient des techniques très différentes, allant du simple usage de mesures
    statistiques~\cite{jones1972tfidf,paukkeri2010likey} à l'utilisation de
    modèles de langues obtenus à partir de données
    non-annotées~\cite{tomokiyo2003languagemodel}, en passant par la
    construction d'un graphe de co-occurrences~\cite{mihalcea2004textrank}.
    Puisque la méthode que nous présentons dans cet article est une méthode dite
    \og à base de graphe~\fg, nous ne nous intéressons ici qu'à cette dernière
    catégorie de méthodes.

    \newcite{mihalcea2004textrank} proposent TextRank, une méthode
    d'ordonnancement d'unités textuelles à partir d'un graphe. Celle-ci,
    utilisée pour le résumé automatique et l'extraction de termes-clés,
    s'inspire de la méthode PageRank~\cite[Google]{brin1998pagerank} qui
    détermine l'importance de pages Web grâce à celles qui s'y réfèrent, et
    celles auxquelles elles se réfèrent. Le plus une page Web est citée par
    d'autres, le plus elle est importante, et le plus elle est importante, le
    plus elle donne d'importance aux pages Web auxquelles elle fait référence.
    Cette notion de référence entre les pages Web est représentée par un graphe
    dans lequel les n\oe{}uds sont des pages Web et les références sont
    symbolisés par les liens entre elles. Ensuite, une mesure de centralité,
    inspirée de la mesure de centralité eigenvector, est appliquée pour ordonner
    les pages Web par importance. Pour l'extraction de termes-clés avec
    TextRank, les pages Web sont remplacées par les mots (nom et adjectifs) du
    document analysé et les liens entre eux symbolisent leur(s) co-occurrence(s)
    dans une fenêtre de 2 mots. Les mots sont ordonnés par importance et les $k$
    meilleurs, les mots clés, servent à la génération des termes-clés. Pour ce
    faire, les mots-clés sont marqués dans le documents et les plus longues
    séquences de mots-clés adjacents sont extraits comme termes-clés. Dans cette
    méthode, la précision de l'ordonnancement dépend de la qualité du graphe qui
    elle même dépend de la fenêtre de co-occurrences. La définition de cette
    fenêtre est sujette à une intervention manuelle et peut dépendre des
    propriétés des documents analysés. Dans nos travaux, nous tentons de nous
    abstraire de cette fenêtre.

    \newcite{wan2008expandrank} proposent la méthode SingleRank qui présente
    deux améliorations à TextRank. Dans un premier temps, les auteurs améliorent
    la précision de l'ordonnancement en pondèrant les liens de co-occurrence par
    le nombre de co-occurrences (par exemple, un mot co-occurrent deux fois avec
    un autre est relié à celui-ci par un poids de 2) et en utilisant ce poids
    lors du transfère d'importance.
    %Ce nouvel ordonnancement utilise plus d'informations présentes dans le
    %document analysé et est dotant plus efficace quand le document analysé est
    %de grande taille.
    Dans un second temps, les termes-clés ne sont plus générés, mais ordonnés à
    partir de la somme du score d'importance des mots qu'ils contiennent. La
    méthode SingleRank donne, dans la majorité des cas, des résultats meilleurs
    que ceux de TextRank. Cependant, faire la somme du score d'importance des
    mots pour ordonner les candidats est une approche maladroite. En effet, cela
    a pour effet de faire monter dans le classement des candidats qui se
    recouvrent. Ainsi, dans le document \textit{as\_2002\_000700ar} de la
    collection DEFT (voir la section~\ref{sec:evaluation}), le candidat positif
    \og bio-politique~\fg\ est classé neuvième, alors que les autres candidats
    contenant \og bio-politique~\fg\ plus d'autres mots non importants occupent
    les classements 2 à 8. Dans nos travaux nous ordonnons les termes-clés
    candidats en tenant compte de l'importance du sujet qu'ils représentent puis
    choisissons un représentant par sujet, nous évitons ainsi le problème
    rencontré avec SingleRank.

    Toujours dans l'optique d'utiliser plus d'informations pour améliorer
    l'efficacité de l'ordonnancement, \newcite{wan2008expandrank} étendent
    SingleRank en utilisant des documents voisins (similaires) du document en
    cours d'analyse. Leur méthode, ExpandRank, consiste à observer les
    co-occurrences dans les documents similaires afin de renforcer ou ajouter
    des liens dans le graphe initial. Cette approche donne des résultats au delà
    de ceux de SingleRank, mais il est important de noter que ses performances
    sont fortement liées à la disponibilité de documents similaires à celui qui
    est analysé.

    A l'instar de \newcite{wan2008expandrank},
    \newcite{tsatsaronis2010semanticrank} tentent d'améliorer TextRank en
    modifiant le processus de création des liens entre les n\oe{}uds du graphe.
    Dans leur approche, un lien entre deux mots est créé et pondéré en fonction
    du lien sémantique de ces derniers selon WordNet~\cite{miller1995wordnet} ou
    Wikipedia~\cite{milne2008wikipediasemanticrelatedness}. Les expériences
    menées par les auteurs montrent de moins bons résultats que TextRank.
    Toutefois, en biaisant l'ordonnancement en faveur des mots apparaissant dans
    le titre du document analysé ou bien en ajoutant le poids TF-IDF des mots
    dans le calcul de l'importance des mots, leur méthode est capable de donner
    de meilleurs résultats que TextRank.

    L'usage de sujets dans le processus d'ordonnancement de TextRank est à
    l'origine proposé par \newcite{liu2010topicalpagerank}. Reposant sur un
    modèle LDA~\cite[Latent Dirichlet Allocation]{blei2003lda}, leur méthode
    effectue des ordonnancements biaisés par les sujets du document, puis
    fusionne les rangs des mots dans ces différents ordonnancement afin
    d'obtenir un rang global pour chaque mot. Dans notre travail, nous émettons
    aussi l'hypothèse que le sujet auquel appartient une unité textuelle doit
    jouer un rôle majeur dans le processus d'ordonnancement. Cependant, nous
    tentons de nous abstraire de l'usage de documents supplémentaires et
    n'utilisons donc pas le modèle LDA. En addition, il nous semble plus
    judicieux d'effectuer un seul ordonnancement.

