\section{État de l'art}
\label{sec:etat_de_l_art}
  % Quel est le fonctionnement général des méthodes d'extraction automatique de
  % termes-clés ?
  L'extraction automatique de termes-clés est une tâche répartie en quatre
  étapes. Les documents sont considérés un par un, ils sont tout d'abord
  enrichis linguistiquement (segmentés en phrases, segmentés en mots, étiquetés
  en parties du discours, etc.), puis des termes-clés candidats en sont extraits
  et classifiés, ou ordonnés, afin de pouvoir sélectionner leurs termes-clés
  (cf. figure~\ref{fig:etapes_de_l_extraction_de_termes_cles}). L'extraction des
  termes-clés candidats et leur classification, ou ordonnancement, sont les deux
  étapes auxquels nous nous intéressons dans cet article. En effet, la
  classification, ou l'ordonnancement, des termes-clés candidats est le c\oe{}ur
  de la tâche d'extraction de termes-clés et ses performances peuvent dépendre
  de la qualité des candidats préalablement extraits.
  \begin{figure}
    \tikzstyle{io}=[
      ellipse,
      minimum width=5cm,
      minimum height=2cm,
      fill=green!20,
      draw=green!33,
      transform shape,
      font={\huge}
    ]
    \tikzstyle{component}=[
      text centered,
      thick,
      rectangle,
      minimum width=11cm,
      minimum height=2.5cm,
      fill=cyan!20,
      draw=cyan!33,
      transform shape,
      font={\huge\bfseries}
    ]

    \centering
    \begin{tikzpicture}[thin,
                        align=center,
                        scale=.45,
                        node distance=2cm,
                        every node/.style={text centered, transform shape}]
      \node[io] (document) {document};
      \node[component] (preprocessing) [right=of document] {Prétraitement Linguistique};
      \node[component] (candidate_extraction) [below=of preprocessing] {Extraction des candidats};
      \node[component] (candidate_classification_and_ranking) [below=of candidate_extraction] {
        \begin{tabular}{r|lcl}
          Classification & des candidats\\
          Ordonnancement &\\
        \end{tabular}
      };
      \node[component] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés};
      \node[io] (keyphrases) [right=of keyphrase_selection] {termes-clés};

      \path[->, thick] (document) edge (preprocessing);
      \path[->, thick] (preprocessing) edge (candidate_extraction);
      \path[->, thick] (candidate_extraction) edge (candidate_classification_and_ranking);
      \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
      \path[->, thick] (keyphrase_selection) edge (keyphrases);
    \end{tikzpicture}
    \caption{Les quatre principales étapes de l'extraction automatique de
             termes-clés. \label{fig:etapes_de_l_extraction_de_termes_cles}}
  \end{figure}

  \subsection{Extraction de termes-clés candidats}
  \label{subsec:extraction_de_termes_cles_candidats}
    % Quel est l'objectif ?
    L'objectif de l'extraction de termes-clés candidats est de réduire l'espace
    des solutions possibles aux seules unités textuelles ayant des
    particularités semblables à celles des termes-clés (tels qu'ils peuvent être
    donnés par des humains). Deux avantages directs à cela sont la réduction du
    temps de calcul nécessaire et la suppression d'unités textuelles non
    pertinentes pouvant engendrer du bruit affectant les performances de
    l'extraction de termes-clés. Pour distinguer les différents candidats
    extraits, nous définissons deux catégories~: les candidats positifs, qui
    sont de réels termes-clés, et les candidats non positifs, qui ne sont pas de
    réels termes-clés. Parmi les candidats non positifs, nous distinguons aussi
    deux catégories~: les candidats porteurs d'informations utiles à la
    promotions de candidats positifs et les candidats non pertinents, qui sont
    considérés comme des erreurs d'extraction.

    % Quels sont les différentes méthodes utilisées pour extraire les
    % termes-clés candidats ?
    Dans les travaux précédents pour l'extraction automatique de termes-clés,
    trois méthodes d'extraction de candidats sont utilisées~: l'extraction de
    n-grammes filtrés avec une liste de mots outils, l'extraction d'unités
    minimales de sens ayant pour tête un nom (chunks nominaux) ou l'extraction
    des unités textuelles respectant certains patrons syntaxiques.

    L'extraction de n-grammes consiste en l'extraction de séquences ordonnées de
    $n$ mots. Cette extraction est très exhaustive, elle fournit une grande
    quantité de termes-clés candidats, maximisant ainsi la quantité de candidats
    positifs ou porteurs d'informations, mais aussi la quantité de candidats non
    pertinents. Pour supprimer un grand nombre de ces candidats non pertinents,
    il est courant d'utiliser une liste de mots outils (conjonctions,
    prépositions, mots usuels, etc.). Une unité textuelle contenant un mot
    outils en début ou en fin ne doit pas être considérée comme un terme-clé
    candidat. Bien que l'extraction de n-grammes filtrés fournisse un ensemble
    bruité de candidats, elle est utilisée dans les méthodes supervisées
    d'extraction automatique de
    termes-clés~\cite{witten1999kea,turney1999learningalgorithms,hulth2003keywordextraction}.
    En effet, du fait de leur phase d'apprentissage, les méthodes
    non-supervisées sont très robustes et donc peu sensibles aux bruits.

    L'extraction de chunks nominaux consiste en l'extraction d'unités minimales
    de sens ayant pour tête un nom. Contrairement aux n-grammes, les chunks sont
    des unités textuelles grammaticalement correctes. De ce fait, elles sont
    moins arbitraires. D'un point de vue linguistique, l'extraction de chunks
    nominaux est plus justifiée que l'extraction de n-grammes. Cependant, son
    caractère plus restrictif ne permet pas d'extraire autant de candidats
    positifs. Il est donc important de s'assurer que les propriétés des chunks
    nominaux sont en accord avec les propriétés des termes-clés (tels qu'ils
    peuvent être donnés par des humains). Les expériences mennées par
    \newcite{hulth2003keywordextraction} et \newcite{eichler2010keywe} avec les
    chunks nominaux montrent une amélioration des performances vis-à-vis de
    l'usage de n-grammes. Cependant, \newcite{hulth2003keywordextraction} montre
    aussi qu'en tirant partie de l'étiquetage en parties du discours,
    l'extraction de termes-clés à partir de n-grammes donne des performances
    au-dessus de celles obtenues avec les chunks nominaux.

    L'extraction d'unités textuelles respectant certains patrons syntaxiques
    permet l'extraction de candidats qui sont grammaticalement corrects et qui
    respectent une syntaxe particulière\footnote{Il est possible d'extraire les
    chunks nominaux à partir de patrons syntaxiques.}. Alors que
    \newcite{hulth2003keywordextraction} extraient des candidats avec les
    patrons de termes-clés les plus fréquents (plus de 10 occurrences) dans une
    collection de documents annotés, d'autres chercheurs tels que
    \newcite{wan2008expandrank} se concentrent uniquement sur les plus longues
    séquences de nom (nom propres inclus) et d'adjectifs. TODO faire un point de
    comparaison avec les chunks nominaux.

    % Que veut-on apporter ?
    Dans le but d'améliorer la qualité des candidats extraits avec les méthodes
    susmentionnées, \newcite{kim2009termextraction} proposent de filtrer les
    candidats en fonction de leur spécificité vis-à-vis du domaine du document
    analysé. Cette spécificité est déterminée en fonction du rapport entre la
    fréquence d'un candidat dans le document et le nombre de documents dans
    lesquels il est présent \cite[TF-IDF]{jones1972tfidf}. Intuitivement, un
    candidat très fréquent dans le document analysé est d'autant plus spécifique
    à celui-ci s'il est présent dans très peu d'autres documents.
    
    L'idée d'extraire des candidats spécifiques au domaine du document analysé
    est une idée intéressant et il nous est possible d'aller encore plus loin.
    En effet, nous pouvons tirer partie des travaux menés en extraction
    terminologique. Les méthodes automatiques d'extraction terminologique, dont
    \newcite{castellvi2001automatictermdetection} en ont fait le revue,
    extraient des mots ou expressions symbolisant un concept et devant, à ce
    titre, faire partie des entrées d'un index terminologique. Toutefois, ces
    méthodes nécessitent une collection de documents appartenant au domaine de
    spécialité des documents à analyser dans le future. Ces méthodes ne sont
    donc pas adaptées pour l'extraction de termes-clés candidats à partir de
    documents hétérogènes (articles journalistiques, par exemple).
    TODO introduire TermSuite et la méthode d'ajout de sous-composants.

  \subsection{Classification/Ordonnancement des termes-clés candidats}
  \label{subsec:classification_ordonnancement_des_termes_cles_candidats}
    % Quel est l'objectif ?
    L'étape de classification/ordonnancement intervient après l'extraction des
    termes-clés candidats. Son rôle est de déterminer quels sont, parmi les
    candidats, les termes-clés du document analysé. La classification est
    majoritairement utilisée par les méthodes supervisées. Les méthodes
    non-supervisées, quant à elles,  effectuent en général un ordonnancement des
    candidats. Dans cet article, nous nous intéressons aux méthodes
    non-supervisées, nous ne présentons donc que ces dernières. De plus, les
    différences notables entre les différentes méthodes supervisées ne sont que
    dans le choix du classifieur (classifieur naïf bayésien, arbres de
    décisions, perceptron multi-couches, etc) ou des traits (TF-IDF, première,
    position, parties du discours, etc.).

    % Quels sont les différentes méthodes non-supervisées existantes pour
    % l'extraction de termes-clés ? (plus de détails)
    Les méthodes non-supervisées d'extraction automatique de termes-clés
    emploient des méthodes très différentes, allant du simple usage de mesures
    statistiques~\cite{jones1972tfidf,paukkeri2010likey} au regroupement des
    mots par fréquence de co-occurrences~\cite{liu2009keycluster}, en passant
    par l'utilisation de modèles de langues obtenus à partir de données
    non-annotées~\cite{tomokiyo2003languagemodel}, ou encore la construction
    d'un graphe de co-occurrences~\cite{mihalcea2004textrank}. Bien que dans la
    méthode que nous proposons nous faisons aussi du regroupement, celle-ci
    appartient à la dernière catégorie de méthodes mentionnée. Nous nous
    intéressons donc, ici, aux méthodes dites \og à base de graphe \fg.

    TODO méthodes à base de graphe.

    % Quels sont les inconvénients des méthodes actuelles ?
    % Que veut-on apporter ?

