\section{État de l'art}
\label{sec:etat_de_l_art}
  \begin{figure}
    \tikzstyle{io}=[
      ellipse,
      minimum width=5cm,
      minimum height=2cm,
      fill=green!20,
      draw=green!33,
      transform shape,
      font={\huge}
    ]
    \tikzstyle{component}=[
      text centered,
      thick,
      rectangle,
      minimum width=13cm,
      minimum height=2cm,
      fill=cyan!20,
      draw=cyan!33,
      transform shape,
      font={\huge\bfseries}
    ]

    \centering
    \begin{tikzpicture}[thin,
                        align=center,
                        scale=.45,
                        node distance=2cm,
                        every node/.style={text centered, transform shape}]
      \node[io] (document) {document};
      \node[component] (preprocessing) [right=of document] {Prétraitement Linguistique};
      \node[component] (candidate_extraction) [below=of preprocessing]
      {Sélection des termes-clés candidats};
      \node[component] (candidate_classification_and_ranking) [below=of candidate_extraction] {Ordonnancement des candidats};
      \node[component] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés};
      \node[io] (keyphrases) [right=of keyphrase_selection] {termes-clés};

      \path[->, thick] (document) edge (preprocessing);
      \path[->, thick] (preprocessing) edge (candidate_extraction);
      \path[->, thick] (candidate_extraction) edge (candidate_classification_and_ranking);
      \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
      \path[->, thick] (keyphrase_selection) edge (keyphrases);
    \end{tikzpicture}
    \caption{Les quatre principales étapes de l'extraction automatique de
             termes-clés. \label{fig:etapes_de_l_extraction_de_termes_cles}}
  \end{figure}
  Dans cet état de l'art, nous nous focalisons sur la catégorie de méthodes à
  laquelle appartient TopicRank, c'est-à-dire les méthodes non supervisées.
  L'extraction automatique non supervisée de termes-clés est une tâche répartie
  généralement en quatre étapes. Les méthodes non supervisées traitent les
  documents un à un. Ceux-ci sont tout d'abord enrichis linguistiquement,
  c'est-à-dire segmentés en phrases, segmentés en mots  et étiquetés
  grammaticalement. Des termes-clés candidats y sont sélectionnés, puis
  ordonnés afin de n'extraire que les termes-clés les plus pertinents (voir la
  figure~\ref{fig:etapes_de_l_extraction_de_termes_cles}). La sélection des
  termes-clés candidats et leur ordonnancement sont les deux étapes auxquelles
  nous nous intéressons dans cet état de l'art. Si l'ordonnancement des
  termes-clés candidats est le c\oe{}ur de la tâche d'extraction de termes-clés,
  ses performances dépendent de la qualité des candidats préalablement
  sélectionnés~\cite{wang2014keyphraseextractionpreprocessing} et il est donc
  important de bien choisir leur méthode de sélection.

  \subsection{Sélection des termes-clés candidats}
  \label{subsec:extraction_de_termes_cles_candidats}
    % Quel est l'objectif ?
    L'objectif de la sélection des termes-clés candidats est de déterminer
    quelles sont les unités textuelles qui sont potentiellement des termes-clés,
    c'est-à-dire les unités textuelles qui ont des particularités similaires à
    celles des termes-clés tels qu'ils peuvent être donnés par des humains. Nous
    savons par exemple que les termes-clés sont majoritairement constitués de
    noms et d'adjectifs. Cette étape de sélection des termes-clés présente deux
    avantages. Le premier est la réduction du temps de calcul nécessaire à
    l'extraction des  termes-clés. Le second est la suppression d'unités
    textuelles non pertinentes, ces dernières pouvant affecter négativement les
    performances de l'ordonnancement. Pour distinguer les différents candidats
    sélectionnés, nous définissons deux catégories~: les candidats positifs, qui
    correspondent aux termes-clés assignés par des humains (termes-clés de
    référence), et les candidats non positifs. Parmi les candidats non positifs,
    nous distinguons deux sous-catégories~: les candidats porteurs d'indices de
    différentes natures pouvant influencer la promotion de candidats positifs
    (p. ex. la présence des candidats \og{}alerte rouge\fg{}, \og{}alerte
    jaune\fg{} et \og{}alerte orange\fg{} influence l'extraction du candidat
    positif \og{}alerte\fg{} en tant que terme-clé, dans l'exemple de la
    figure~\ref{fig:recurrent_example} page~\pageref{fig:recurrent_example}) et
    les candidats non pertinents, que nous considérons comme des erreurs.

    % Quels sont les différentes méthodes utilisées pour extraire les
    % termes-clés candidats ?
    Dans les travaux précédents, trois méthodes d'extraction de candidats sont
    utilisées~: l'extraction de n-grammes, de \textit{chunks} nominaux, et d'unités
    textuelles respectant certains patrons grammaticaux. Dans cette section,
    nous ne présentons que les travaux utilisés pour la sélection des
    termes-clés candidats. Des travaux connexes pourraient toutefois être
    considérés~: extraction
    terminologique~\cite{castellvi2001automatictermdetection}, détection de
    collocation~\cite{pearce2002collocationdetection}, etc.

    Les n-grammes sont toutes les séquences ordonnées de $n$ mots adjacents. Leur extraction est très exhaustive, elle fournit un
    grand nombre de termes-clés candidats, maximisant la quantité de candidats
    positifs, la quantité de candidats porteurs d'indices utiles, mais aussi la
    quantité de candidats non pertinents. Pour pallier en partie ce problème, il
    est courant d'utiliser un anti-dictionnaire pour filtrer les candidats. Ce
    dernier regroupe les mots fonctionnels de la langue (conjonctions,
    prépositions, etc.) et les mots courants (\og particulier~\fg, \og près~\fg,
    \og beaucoup~\fg, etc.). Un n-gramme contenant un mot présent dans
    l'anti-dictionnaire en début ou en fin n'est pas considéré comme un
    terme-clé candidat. Malgré son aspect bruité, ce type d'extraction est
    encore largement utilisé parmi les méthodes
    supervisées~\cite{witten1999kea,turney1999learningalgorithms,hulth2003keywordextraction}.
    La phase d'apprentissage de celles-ci les rend moins sensibles aux éventuels
    candidats erronés (bruit) que les méthodes non supervisées.

    \textit{Exemples de $\{1..3\}$-grammes sélectionnés dans la phrase \og{}Une
    légère brise de côte pourra faiblement rafraichir l'atmosphère.\fg{} dans
    l'exemple de la figure~\ref{fig:recurrent_example}
    page~\pageref{fig:recurrent_example}~: \og{}légère\fg{}, \og{}brise\fg{},
    \og{}côte\fg{}, \og{}pourra\fg{}, \og{}faiblement\fg{},
    \og{}rafraichir\fg{}, \og{}atmosphère\fg{}, \og{}légère brise\fg{},
    \og{}côte pourra\fg{}, \og{}pourra faiblement\fg{}, \og{}faiblement
    rafraichir\fg{}, \og{}brise de côte\fg{}, \og{}côte pourra faiblement\fg{},
    \og{}pourra faiblement rafraichir\fg{} et \og{}rafraichir
    l'atmosphère\fg{}.}

    Les \textit{chunks} nominaux sont des syntagmes non récursifs dont la tête
    est un nom accompagné de ses éventuels déterminants et modifieurs usuels.
    Ils sont linguistiquement définis et donc plus fiables que les n-grammes,
    comme le montrent les expériences menées par
    \newcite{hulth2003keywordextraction} et \newcite{eichler2010keywe}. Cependant, \newcite{hulth2003keywordextraction}
    constate que l'usage de l'étiquetage grammatical des termes-clés candidats
    lors de l'extraction supervisée de termes-clés permet d'éliminer les
    n-grammes grammaticalement incorrects et d'obtenir de meilleurs performances
    qu'avec les \textit{chunks} nominaux. Contrairement à
    \newcite{hulth2003keywordextraction}, nous proposons une méthode
    d'extraction non supervisée de termes-clés. Sélectionner les \textit{chunks}
    nominaux est donc une solution plus fiable que de sélectionner les
    n-grammes.

    \textit{Exemples de \textit{chunks} nominaux sélectionnés dans la phrase
    \og{}Une légère brise de côte pourra faiblement rafraichir
    l'atmosphère.\fg{} dans l'exemple de la figure~\ref{fig:recurrent_example}
    page~\pageref{fig:recurrent_example}~: \og{}une légère brise\fg{},
    \og{}côte\fg{} et \og{}l'atmosphère\fg{}.}

    La sélection d'unités textuelles à partir de patrons grammaticaux prédéfinis
    permet de contrôler avec précision la nature et la grammaticalité des
    candidats à sélectionner. À l'instar des \textit{chunks} nominaux, leur
    sélection est plus fondée linguistiquement que celle des n-grammes. Dans ses
    travaux, \newcite{hulth2003keywordextraction} sélectionne les candidats à
    partir des patrons des termes-clés de référence les plus fréquents dans sa
    collection d'apprentissage (plus de 10 occurrences), tandis que d'autres
    chercheurs, tels que \newcite{wan2008expandrank} et
    \newcite{hassan2010conundrums}, se concentrent uniquement sur les plus
    longues séquences de noms (noms propres inclus) et d'adjectifs. Pour des
    méthodes non supervisées telles que la nôtre, la sélection des séquences de
    noms et d'adjectifs est intéressante, car elle ne nécessite ni données
    supplémentaires, ni adaptation particulière pour une langue donnée, tel que
    c'est le cas pour les \textit{chunks} nominaux.

    \textit{Exemples de plus longues séquences de noms et d'adjectifs
    sélectionnées dans la phrase \og{}Une légère brise de côte pourra faiblement
    rafraichir l'atmosphère.\fg{} dans l'exemple de la
    figure~\ref{fig:recurrent_example} page~\pageref{fig:recurrent_example}~:
    \og{}légère brise\fg{}, \og{}côte\fg{} et \og{}atmosphère\fg{}.}

  \subsection{Ordonnancement des termes-clés candidats}
  \label{subsec:ordonnancement_des_termes_cles_candidats}
    % Quel est l'objectif ?
    L'étape d'ordonnancement intervient après la sélection des termes-clés
    candidats. Son rôle est de déterminer quels sont parmi les candidats d'un
    document ceux les plus importants (les termes-clés).
    % Quels sont les différentes méthodes non supervisées existantes pour
    % l'extraction de termes-clés ?
    % Quels sont les inconvénients des méthodes actuelles ?
    % Que veut-on apporter ?
    Les méthodes non supervisées d'extraction automatique de termes-clés
    emploient des techniques très différentes, allant du simple usage de mesures
    fréquentielles~\cite{paukkeri2010likey} à l'utilisation de modèles de
    langues~\cite{tomokiyo2003languagemodel}, en passant par la construction
    d'un graphe de cooccurrences~\cite{mihalcea2004textrank}. Puisque la méthode
    que nous présentons dans cet article est une méthode dite \og à base de
    graphe~\fg, nous décrivons ici uniquement les travaux effectués pour cette
    catégorie de méthodes.

    \newcite{mihalcea2004textrank} proposent TextRank, une méthode
    d'ordonnancement d'unités textuelles à partir d'un graphe. Utilisés dans de
    nombreuses applications du TAL~\cite{kozareva2013textgraphs}, les graphes
    ont l'avantage de présenter de manière simple et efficace les unités
    textuelles d'un document et les relations qu'elles entretiennent. Dans le
    cas de TextRank, les n\oe{}uds du graphe sont les mots du document et leurs
    arêtes représentent leurs relations d'adjacence dans le document,
    c'est-à-dire leurs relations de cooccurrences dans une fenêtre de 2 mots. Un
    score d'importance est calculé pour chaque mot à partir de l'algorithme
    PageRank~\cite{brin1998pagerank} qui est issu de la mesure de centralité des
    vecteurs propres. Le principe utilisé est celui de la recommandation (du
    vote)~: un mot est d'autant plus important s'il cooccurre avec un grand
    nombre de mots et si les mots avec lesquels il cooccurre sont eux aussi
    important. Les mots les plus importants sont considérés comme des mots-clés,
    ces mots-clés sont marqués dans le document et les plus longues séquences de
    mots-clés adjacents sont extraites en tant que termes-clés. Bien qu'elle
    utilise une représentation intéressante et efficace d'un document, cette
    méthode présente l'inconvénient d'ordonner uniquement les mots plutôt que
    les termes-clés candidats. Dans nos travaux, nous proposons d'ordonner
    directement les termes-clés candidats.

    \newcite{wan2008expandrank} modifient TextRank et proposent SingleRank. Dans
    un premier temps, leur méthode augmente la précision de l'ordonnancement en
    utilisant une fenêtre de cooccurrence élargie (empiriquement) à 10 et en
    pondérant les arêtes par le nombre de cooccurrences entre les deux mots
    qu'elles relient. Dans un second temps, les termes-clés ne sont plus
    générés, mais ordonnés à partir de la somme des scores d'importance des mots
    qui les composent. Cette nouvelle méthode donne, dans la majorité des cas,
    des résultats meilleurs que ceux de TextRank. Cependant, la précision de
    l'ordonnancement dépend de la valeur de la fenêtre de cooccurrence qui est
    fixée, en témoignent les observations contradictoires de
    \newcite{mihalcea2004textrank} et de \newcite{wan2008expandrank} lorsqu'ils
    appliquent leurs méthodes avec différentes fenêtres sur des documents de
    natures différentes. De plus, faire la somme des scores d'importance des
    mots pour ordonner les candidats est une approche qui a pour conséquence de
    favoriser les plus longues séquences tout en faisant monter dans le
    classement des candidats redondants (p. ex. dans l'exemple de la
    figure~\ref{fig:recurrent_example} page~\pageref{fig:recurrent_example}, le
    candidat positif \og{}alerte~\fg{} est classé quatrième par SingleRank,
    alors que les candidats non positifs \og{}alerte orange\fg{}, \og{}alerte
    jaune\fg{} et \og{}alerte rouge\fg{} qui le contiennent occupent de
    meilleurs classements). Ici, nous proposons d'utiliser un graphe complet
    pour éviter de définir une fenêtre de cooccurrences et de grouper les
    termes-clés candidats afin d'éviter le problème de redondance.

    Toujours dans le but d'améliorer l'efficacité de l'ordonnancement proposé
    par \newcite{mihalcea2004textrank}, \newcite{wan2008expandrank} étendent
    SingleRank en utilisant des documents similaires au document analysé, selon
    la mesure de similarité vectorielle cosinus. Faisant l'hypothèse que ces
    documents similaires fournissent des données supplémentaires relatives aux
    mots du document analysé et aux relations qu'ils entretiennent, ils
    utilisent les relations de cooccurrences observées dans les documents
    similaires pour ajouter ou renforcer des liens dans le graphe. Cette
    approche donne des résultats au-delà de ceux de SingleRank. Toutefois, ses
    performances sont fortement liées à la disponibilité de documents similaires
    à celui qui est analysé. Cette méthode ne peut donc être appliquée que dans
    un contexte particulier, contexte que nous ne pouvons garantir dans ce
    travail.

    \newcite{tsatsaronis2010semanticrank} tentent eux aussi d'améliorer
    TextRank. Dans leur méthode, ils créent et pondèrent une arête entre deux
    mots si et seulement si ceux-ci sont sémantiquement liés dans
    WordNet~\cite{miller1995wordnet} ou dans
    Wikipedia~\cite{milne2008wikipediasemanticrelatedness}. Leurs expériences
    montrent de  moins bons résultats que TextRank. Toutefois, en biaisant
    l'ordonnancement en faveur des mots apparaissant dans le titre du document
    analysé ou en ajoutant le poids TF-IDF~\cite{jones1972tfidf} des mots dans
    le calcul de l'importance des mots, leur méthode est capable de donner de
    meilleurs résultats que TextRank.

    L'usage de sujets dans le processus d'ordonnancement de TextRank est à
    l'origine proposé par \newcite{liu2010topicalpagerank}. Reposant sur un
    modèle LDA~\cite[Latent Dirichlet Allocation]{blei2003lda}, leur méthode
    effectue des ordonnancements biaisés par les sujets du document, puis
    fusionne les rangs des mots dans ces différents ordonnancements afin
    d'obtenir un rang global pour chaque mot. Dans notre travail, nous émettons
    aussi l'hypothèse que le sujet auquel appartient une unité textuelle doit
    jouer un rôle majeur dans le processus d'ordonnancement. Cependant, dans le
    but de proposer une méthode générique qui ne requièrt aucun travail
    préalable, nous tentons de nous abstraire de l'usage de documents
    supplémentaires et n'utilisons pas le modèle LDA.

