\section{État de l'art}
\label{sec:etat_de_l_art}
  \begin{figure}
    \tikzstyle{io}=[
      ellipse,
      minimum width=5cm,
      minimum height=2cm,
      fill=green!20,
      draw=green!33,
      transform shape,
      font={\huge}
    ]
    \tikzstyle{component}=[
      text centered,
      thick,
      rectangle,
      minimum width=13cm,
      minimum height=2cm,
      fill=cyan!20,
      draw=cyan!33,
      transform shape,
      font={\huge\bfseries}
    ]

    \centering
    \begin{tikzpicture}[thin,
                        align=center,
                        scale=.45,
                        node distance=2cm,
                        every node/.style={text centered, transform shape}]
      \node[io] (document) {document};
      \node[component] (preprocessing) [right=of document] {Prétraitement Linguistique};
      \node[component] (candidate_extraction) [below=of preprocessing]
      {Sélection des termes-clés candidats};
      \node[component] (candidate_classification_and_ranking) [below=of candidate_extraction] {Ordonnancement des candidats};
      \node[component] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés};
      \node[io] (keyphrases) [right=of keyphrase_selection] {termes-clés};

      \path[->, thick] (document) edge (preprocessing);
      \path[->, thick] (preprocessing) edge (candidate_extraction);
      \path[->, thick] (candidate_extraction) edge (candidate_classification_and_ranking);
      \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
      \path[->, thick] (keyphrase_selection) edge (keyphrases);
    \end{tikzpicture}
    \caption{Les quatre principales étapes de l'extraction automatique de
             termes-clés. \label{fig:etapes_de_l_extraction_de_termes_cles}}
  \end{figure}
  TopicRank faisant partie des méthodes non-supervisées, l'état de l'art
  présenté ici se focalise sur cette catégorie de méthodes. L'extraction
  automatique non-supervisée de termes-clés est une tâche décomposée en général
  en quatre étapes. Les méthodes non-supervisées traitent les documents
  généralement un à un. Ceux-ci sont tout d'abord enrichis linguistiquement,
  c'est-à-dire segmentés en phrases, segmentés en mots  et étiquetés
  grammaticalement. Des termes-clés candidats en sont sélectionnés, puis
  ordonnés afin de ne sélectionner que les plus pertinents (voir la
  figure~\ref{fig:etapes_de_l_extraction_de_termes_cles}). La sélection des
  termes-clés candidats et leur ordonnancement sont les deux étapes auxquelles
  nous nous intéressons dans cet article. L'ordonnancement des termes-clés
  candidats est le c\oe{}ur de la tâche d'extraction de termes-clés et ses
  performances dépendent de la qualité des candidats préalablement
  sélectionnés~\cite{wang2014keyphraseextractionpreprocessing}.

  \subsection{Sélection des termes-clés candidats}
  \label{subsec:extraction_de_termes_cles_candidats}
    % Quel est l'objectif ?
    L'objectif de la sélection des termes-clés candidats est de déterminer quels
    sont les unités textuelles qui sont potentiellement des termes-clés,
    c'est-à-dire celles qui ont des particularités similaires à celles des
    termes-clés tels qu'ils peuvent être donnés par des humains. Nous savons par
    exemple que les termes-clés sont majoritairement constitués de noms et
    d'adjectifs. Cette étape présente deux avantages. Le premier, très évident,
    est la réduction du temps de calcul nécessaire à l'extraction des
    termes-clés. Le second avantage est la suppression en amont d'unités
    textuelles non pertinentes, ces dernières pouvant affecter négativement les
    performances de l'ordonnancement. Pour distinguer les différents candidats
    sélectionnés, nous définissons deux catégories~: les candidats positifs, qui
    sont présents en tant que termes-clés de référence dans nos collections de
    données, et les candidats non positifs. Parmi les candidats non positifs,
    nous distinguons deux sous-catégories~: les candidats porteurs d'indices de
    différentes natures pouvant influencer la promotion de candidats positifs
    (par exemple, la présence des candidats \og{}alerte rouge\fg{}, \og{}alerte
    jaune\fg{} et \og{}alerte orange\fg{} influence l'extraction du candidat
    positif \og{}alerte\fg{} en tant que terme-clé, dans l'article présenté dans
    la figure~\ref{fig:recurrent_example}) et les candidats non pertinents, que
    nous considérons comme des erreurs.

    % Quels sont les différentes méthodes utilisées pour extraire les
    % termes-clés candidats ?
    Dans les travaux précédents, trois méthodes d'extraction de candidats sont
    classiquement utilisées~: l'extraction de n-grammes, de chunks nominaux, et
    d'unités textuelles respectant certains patrons grammaticaux. \TODO{Ce
    travail ne propose pas de nouvelle méthode d'extraction, nous ne présentons
    pas de méthodes de sélection autres que celles déjà proposées}

    Les n-grammes sont toutes les séquences ordonnées de $n$ mots adjacents,
    avec $n \in 1..m$, où $m$ vaut généralement
    3~\cite{witten1999kea,turney1999learningalgorithms,hulth2003keywordextraction},
    du fait de l'usage majoritaire de termes-clés composés d'un à trois mots.
    Leur extraction est très exhaustive, elle fournit un grand nombre de
    termes-clés candidats, maximisant ainsi la quantité de candidats positifs,
    la quantité de candidats porteurs d'indices utiles, mais aussi la quantité
    de candidats non pertinents. Pour pallier en partie ce problème, il est
    courant d'utiliser une liste de mots outils pour filtrer les candidats. Les
    mots outils regroupent les mots fonctionnels de la langue (conjonctions,
    prépositions, etc.) et les mots courants (\og particulier~\fg, \og près~\fg,
    \og beaucoup~\fg, etc.). Ainsi, un n-gramme contenant un mot outil en début
    ou en fin n'est pas considéré comme un terme-clé candidat. Malgré son aspect
    bruité, ce type d'extraction est encore largement utilisé parmi les méthodes
    supervisées~\cite{witten1999kea,turney1999learningalgorithms,hulth2003keywordextraction}.
    En effet, la phase d'apprentissage de celles-ci les rend moins sensibles aux
    éventuels candidats erronés (bruit) par rapport aux méthodes supervisées.

    \textit{
      Exemples de $\{1..3\}$-grammes sélectionnés dans le phrase \og{}Une légère
      brise de côte pourra faiblement rafraichir l'atmosphère.\fg{} dans
      l'exemple de la figure~\ref{fig:recurrent_example}
      page~\pageref{fig:recurrent_example}~: \og{}légère\fg{}, \og{}brise\fg{},
      \og{}côte\fg{}, \og{}pourra\fg{}, \og{}faiblement\fg{},
      \og{}rafraichir\fg{}, \og{}atmosphère\fg{}, \og{}légère brise\fg{},
      \og{}côte pourra\fg{}, \og{}pourra faiblement\fg{}, \og{}faiblement
      rafraichir\fg{}, \og{}brise de côte\fg{}, \og{}côte pourra
      faiblement\fg{}, \og{}pourra faiblement rafraichir\fg{} et \og{}rafraichir
      l'atmosphère\fg{}.}

    Les chunks nominaux sont des syntagmes non récursifs dont la tête est un
    nom, accompagné de ses éventuels déterminants et modifieurs usuels. Ce sont
    des segments linguistiquement définis rendant leur extraction plus fiable
    que celle des n-grammes. Les expériences menées par
    \newcite{hulth2003keywordextraction} et \newcite{eichler2010keywe} avec les
    chunks nominaux premettent de meilleures performances  pour l'extraction de
    termes-clés que les n-grammes. Cependant,
    \newcite{hulth2003keywordextraction} constate aussi qu'en tirant parti de
    l'étiquetage en parties du discours des termes-clés candidats, l'extraction
    supervisée de termes-clés à partir de n-grammes donne des performances
    au-dessus de celles obtenues avec les chunks nominaux. Cette amélioration
    s'explique par le fait que les n-grammes qui ne sont pas grammaticalement
    corrects sont facilement éléminés dans le processus de classification.
    Cependant, contrairement à \newcite{hulth2003keywordextraction}, nous
    proposons une méthode d'extraction non-supervisée de termes-clés.
    Sélectionner les chunks nominaux est donc une solution plus fiable que de
    sélectionner les n-grammes.

    \textit{Exemples de chunks nominaux sélectionnés dans le phrase \og{}Une
    légère brise de côte pourra faiblement rafraichir l'atmosphère.\fg{} dans
    l'exemple de la figure~\ref{fig:recurrent_example}
    page~\pageref{fig:recurrent_example}~: \og{}une légère brise\fg{},
    \og{}côte\fg{} et \og{}l'atmosphère\fg{}.}

    L'extraction d'unités textuelles à partir de patrons grammaticaux prédéfinis
    permet de contrôler avec précision la nature et la grammaticalité des
    candidats extraits. À l'instar des chunks nominaux, leur extraction est plus
    fondée linguistiquement que celle des n-grammes filtrés, et comparée à eux,
    elle fournit un plus grand nombre de candidats positifs. Dans ses travaux,
    \newcite{hulth2003keywordextraction} choisie d'extraire des candidats avec
    les patrons des termes-clés de références les plus fréquents (plus de 10
    occurrences) dans sa collection d'apprentissage, tandis que d'autres
    chercheurs tels que \newcite{wan2008expandrank} et
    \newcite{hassan2010conundrums} se concentrent uniquement sur les plus
    longues séquences de noms (noms propres inclus) et d'adjectifs. Pour des
    méthodes non-supervisées telles que la nôtre, l'extraction des séquences de 
    noms et d'adjectifs est intéressante, car elle ne nécessite ni données
    supplémentaires, ni adaptation particulière pour une langue donnée, tel que
    c'est le cas pour les chunks nominaux.

    \textit{Exemples de plus longues séquences de noms et d'adjectifs
    sélectionnées dans le phrase \og{}Une légère brise de côte pourra faiblement
    rafraichir l'atmosphère.\fg{} dans l'exemple de la
    figure~\ref{fig:recurrent_example} page~\pageref{fig:recurrent_example}~:
    \og{}légère brise\fg{}, \og{}côte\fg{} et \og{}atmosphère\fg{}.}

  \subsection{Ordonnancement des termes-clés candidats}
  \label{subsec:ordonnancement_des_termes_cles_candidats}
    % Quel est l'objectif ?
    L'étape d'ordonnancement intervient après l'extraction des termes-clés
    candidats. Son rôle est de déterminer quels sont, parmi les candidats, les
    termes-clés d'un document.
    % Quels sont les différentes méthodes non-supervisées existantes pour
    % l'extraction de termes-clés ?
    % Quels sont les inconvénients des méthodes actuelles ?
    % Que veut-on apporter ?
    Les méthodes non-supervisées d'extraction automatique de termes-clés
    emploient des techniques très différentes, allant du simple usage de mesures
    fréquentielles~\cite{paukkeri2010likey} à l'utilisation de modèles de
    langues obtenus à partir de données
    non-annotées~\cite{tomokiyo2003languagemodel}, en passant par la
    construction d'un graphe de co-occurrences~\cite{mihalcea2004textrank}.
    Puisque la méthode que nous présentons dans cet article est une méthode dite
    \og à base de graphe~\fg, nous décrivons ici uniquement les travaux
    effectués au sujet de cette catégorie de méthodes.

    \newcite{mihalcea2004textrank} proposent TextRank, une méthode
    d'ordonnancement d'unités textuelles à partir d'un graphe. Utilisés dans de
    nombreuses applications du TAL~\cite{kozareva2013textgraphs}, les graphes
    ont l'avantage de présenter de manière simple et efficace les unités
    textuelles d'un document et les relations qu'elles entretiennent entre
    elles. De plus, ils bénéficient de nombreuses études théoriques donnant lieu
    à des outils et algorithmes capables de résoudre de nombreux problèmes du
    TAL, tels que le résumé automatique~\cite{wan2007iterativereinforcement}, la
    compression multi-phrase~\cite{boudin2013multisentencecompression} et la
    désambiguïsassion de texte~\cite{schwab2013desambiguisation}. Dans le cas de
    TextRank, les n\oe{}uds du graphe sont les mots du document et les arrêtes
    représentent leurs relations d'adjacence dans le document, c'est-à-dire
    leurs relations de co-occurrence dans une fenêtre de 2 mots. Un score
    d'importance est calculé pour chaque mot à partir de l'algorithme
    PageRank~\cite{brin1998pagerank} qui est issu de la mesure de centralité des
    vecteurs propres. Le principe utilisé est celui de la recommandation, ou du
    vote, c'est-à-dire un mot est d'autant plus important qu'il co-occurre avec
    un grand nombre de mots et si les mots avec lesquels il co-occurre sont eux
    aussi important. Les mots les plus importants sont considérés comme des
    mots-clés. Ces mots-clés sont marqués dans le document et les plus longues
    séquences de mots-clés adjacents sont extraites en tant que termes-clés.
    \TODO{Problème du fait de la pondération de mots}

    \newcite{wan2008expandrank} modifient TextRank et proposent SingleRank. Dans
    un premier temps, leur méthode augmente la précision de l'ordonnancement en
    utilisant une fenêtre de cooccurrence élargie à 10 (empiriquement) et en
    pondérant les arêtes par le nombre de co-occurrences entre les mots qu'elles
    relient. Dans un second temps, les termes-clés ne sont plus générés, mais
    ordonnés à partir de la somme du score d'importance des mots qui les
    composent. Cette nouvelle méthode donne dans la majorité des cas des
    résultats meilleurs que ceux de TextRank. Dans cette méthode, la précision
    de l'ordonnancement dépend de la qualité du graphe qui elle-même dépend de
    la fenêtre de co-occurrence, en témoignent les observations contradictoires
    de \newcite{mihalcea2004textrank} et de \newcite{wan2008expandrank}
    lorsqu'ils appliquent leurs méthodes avec différentes fenêtres sur des
    documents de natures différentes. De plus, faire la somme du score
    d'importance des mots pour ordonner les candidats est une approche
    maladroite qui a pour conséquence de faire monter dans le classement des
    candidats redondants. Ainsi, dans l'exemple de la
    figure~\ref{fig:recurrent_example}, le candidat positif \og{}alerte~\fg{}
    est classé quatrième par SingleRank, alors que les autres candidats (non
    positifs) qui le contiennent (\og{}alerte orange\fg{}, \og{}alerte
    jaune\fg{} et \og{}alerte rouge\fg{}) occupent de meilleurs classement. Dans
    nos travaux, nous créons un graphe dont la qualité ne dépend pas de la
    fenêtre de cooccurrence. Aussi, nous n'ordonnons pas les termes-clés
    candidats selon les mots qu'ils contiennent et évitons alors le problème de
    redondance rencontré par SingleRank.

    Toujours dans l'optique d'améliorer l'efficacité de l'ordonnancement,
    \newcite{wan2008expandrank} étendent SingleRank en utilisant des documents
    similaires au document analysé, selon la mesure de similarité vectorielle
    cosinus. Faisant l'hypothèse que ces documents similaires fournissent des
    données supplémentaires relatives aux mots du document analysé et aux
    relations qu'ils entretiennent, \newcite{wan2008expandrank} utilisent les
    relations de co-occurrences observées dans les documents similaires pour
    ajouter ou renforcer des liens dans le graphe. Cette approche donne des
    résultats au delà de ceux de SingleRank. Toutefois, ses performances sont
    fortement liées à la disponibilité de documents similaires à celui qui est
    analysé. Cette méthode ne peut donc être appliquée que dans un context
    particulier, context que nous ne pouvons garantir dans ce travail.

    À l'instar de \newcite{wan2008expandrank},
    \newcite{tsatsaronis2010semanticrank} tentent d'améliorer TextRank. Dans
    leur méthode, ils créent et pondèrent une arrête entre deux mots si et
    seulement si ceux-ci sont sémantiquement liés selon deux mesures définies à
    partir de WordNet~\cite{miller1995wordnet} et de
    Wikipedia~\cite{milne2008wikipediasemanticrelatedness}. Les expériences
    menées par les auteurs montrent de moins bons résultats que TextRank.
    Toutefois, en biaisant l'ordonnancement en faveur des mots apparaissant dans
    le titre du document analysé ou en ajoutant le poids
    TF-IDF~\cite{jones1972tfidf} des mots dans le calcul de l'importance des
    mots, leur méthode est capable de donner de meilleurs résultats que
    TextRank. \TODO{Argumenter}

    L'usage de sujets dans le processus d'ordonnancement de TextRank est à
    l'origine proposé par \newcite{liu2010topicalpagerank}. Reposant sur un
    modèle LDA~\cite[Latent Dirichlet Allocation]{blei2003lda}, leur méthode
    effectue des ordonnancements biaisés par les sujets du document, puis
    fusionne les rangs des mots dans ces différents ordonnancements afin
    d'obtenir un rang global pour chaque mot. Dans notre travail, nous émettons
    aussi l'hypothèse que le sujet auquel appartient une unité textuelle doit
    jouer un rôle majeur dans le processus d'ordonnancement. Cependant, nous
    tentons de nous abstraire de l'usage de documents supplémentaires et
    n'utilisons pas le modèle LDA. De plus, il nous semble plus judicieux, d'un
    point de vue complexité, d'effectuer un seul ordonnancement.

