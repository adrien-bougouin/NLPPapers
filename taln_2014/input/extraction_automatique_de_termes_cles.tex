\section{Extraction automatique de termes-clés}
\label{sec:extraction_automatique_de_termes_cles}
  L'extraction non-supervisée de termes-clés peut se décomposer en quatre
  étapes (cf.~figure~\ref{fig:processing_steps}). Tout d'abord, les documents
  sont un à un enrichis linguistiquement (segmentés en phrases, segmentés en
  mots et étiquetés en parties du discours), des termes-clés candidats en sont
  ensuite extraits, puis ordonnés par importance et enfin, les $k$ plus
  importants sont sélectionnés en tant que termes-clés. Les étapes les plus
  importantes d'un système d'extraction automatique de termes-clés sont celles
  d'extraction des candidats et d'ordonnancement de ceux-ci. Intuitivement,
  l'ordonnancement des candidats est le c\oe{}ur du système, mais la performance
  de celui-ci est limitée par la qualité de l'ensemble de termes-clés candidats
  qui lui est fourni. Nous estimons qu'un ensemble de candidats est de bonne
  qualité lorsqu'il fournit un maximum de candidats présents dans l'ensemble des
  termes-clés de référence et lorsqu'il fournit peu de candidats non-pertinents,
  i.e.~des candidats qui ne se sont pas dans l'ensemble des termes-clés de
  référence et qui peuvent dégrader la performance du système d'extraction de
  termes-clés utilisé.
  \begin{figure}
    \tikzstyle{io}=[
      ellipse,
      minimum width=5cm,
      minimum height=2cm,
      %fill=green!20,
      draw,%=green!33,
      transform shape,
      font={\huge}
    ]
    \tikzstyle{component}=[
      text centered,
      %thick,
      rectangle,
      minimum width=11cm,
      minimum height=2cm,
      %fill=cyan!20,
      draw,%=cyan!33,
      transform shape,
      font={\huge\bfseries}
    ]

    \centering
    \begin{tikzpicture}[thin,
                        align=center,
                        scale=.45,
                        node distance=2cm,
                        every node/.style={text centered, transform shape}]
      \node[io] (document) {document};
      \node[component] (preprocessing) [right=of document] {Prétraitement Linguistique};
      \node[component] (candidate_extraction) [below=of preprocessing] {Extraction des candidats};
      \node[component] (candidate_classification_and_ranking) [below=of candidate_extraction] {
        %\begin{tabular}{r|l}
        %  Ordonnancement & \multirow{2}{*}[-2pt]{des candidats}\\
        %  Classification & \\
        %\end{tabular}
        Ordonnancement des candidats
      };
      \node[component] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés};
      \node[io] (keyphrases) [right=of keyphrase_selection] {termes-clés};

      \path[->, thick] (document) edge (preprocessing);
      \path[->, thick] (preprocessing) edge (candidate_extraction);
      \path[->, thick] (candidate_extraction) edge (candidate_classification_and_ranking);
      \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
      \path[->, thick] (keyphrase_selection) edge (keyphrases);
%      \draw[decorate, decoration={brace, mirror, amplitude=5pt}, thick] ($(candidate_classification_and_ranking.north west)+(-0.9,0.5)$) -- ($(keyphrase_selection.south west)+(-0.9,-0.5)$) node[midway, xshift=-9em] {
%        \huge
%        \begin{tabular}{c}
%          \textbf{Extraction}\\
%          \textbf{des}\\
%          \textbf{termes-clés}\\
%        \end{tabular}
%      };
    \end{tikzpicture}
    \caption{Chaîne de traitements d'un système non-supervisé d'extraction
             automatique de termes-clés.
             \label{fig:processing_steps}}
  \end{figure}

  \subsection{Préparation des données}
  \label{subsec:preparation_des_donnees}
    Les documents des collections de données utilisées subissent tous les mêmes
    prétraitements. Ils sont tout d'abord segmentés en phrases, puis en mots et
    enfin étiquetés en parties du discours. Dans ce travail, la segmentation en
    phrase est effectuée avec le \textit{PunktSentenceTokenizer} disponible avec
    la librairie Python
    NLTK~\cite[\textit{Natural Language ToolKit}]{bird2009nltk} la segmentation
    en mots est effectuée avec l'outil Bonsai, du Bonsai PCFG-LA
    parser\footnote{\url{http://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html}}
    et l'étiquetage en parties du discours est réalisé avec
    MElt~\cite{denis2009melt}. Tous ces outils sont utilisés avec leurs
    paramètres par défaut.

  \subsection{Extraction des termes-clés candidats}
  \label{subsec:extraction_de_termes_cles_candidats}
    Dans les travaux précédents, deux approches sont fréquemment utilisées. Soit
    les candidats sont extraits à partir de n-grammes filtrés, soit ils sont
    extraits par reconnaissance de formes~\cite{hulth2003keywordextraction}.
    Dans ce travail, nous expérimentons trois méthodes différentes~: deux
    méthodes conformes aux approches standards et une méthode utilisant un
    extracteur terminologique. Un extracteur terminologique fournit des unités
    textuelles représentant des concepts spécifiques à une discipline. Il semble
    donc pertinent d'utiliser un tel outil lorsque nous traitons des documents
    de domaines de spécialité.

    L'extraction des \textbf{n-grammes} filtrés consiste à extraire toutes les
    séquences ordonnées de $n$ mots, puis à les filtrer avec une liste de mots
    outils regroupant les mots fonctionnels de la langue (conjonctions,
    prépositions, etc.) et les mots courants (\og{}près\fg{},
    \og{}beaucoup\fg{}, etc.). Dans ce travail, nous suivons
    \newcite{witten1999kea} et extrayons les n-grammes de taille
    $n \in \{1..3\}$ ($\{1..3\}$-grammes) dont les mots en tête et en queue ne
    sont pas présents dans notre liste de mots outils, fournie par l'université
    de
    Neuchâtel\footnote{\url{http://members.unine.ch/jacques.savoy/clef/index.html}}
    (UniNE).
    
    \textit{Exemple de $\{1..3\}$-grammes, extraits à partir de \og{}[\dots]
    (bassin moyen du Don) [\dots]\fg{} dans la notice d'Archéologie de la
    figure~\ref{fig:exemple_notice_inist}~: \og{}bassin\fg{}, \og{}moyen\fg{},
    \og{}Don\fg{}, \og{}bassin moyen\fg{} et \og{}moyen du Don\fg{}}.

    La reconnaissance de formes consiste à extraire les unités textuelles qui
    respectent des patrons définis. Dans ce travail, nous suivons les travaux
    précédents et extrayons les plus longues séquences de noms communs, de noms
    propres et d'adjectifs, considérées comme étant les \textbf{groupes
    nominaux}~\cite{hassan2010conundrums}.
    
    \textit{Exemple de groupes nominaux extraits à partir de \og{}[\dots]
    (bassin moyen du Don) [\dots]\fg{} dans la notice d'Archéologie de la
    figure~\ref{fig:exemple_notice_inist}~: \og{}bassin moyen\fg{} et
    \og{}Don\fg{}.}

    L'extraction de \textbf{candidats termes} consiste à extraire les unités
    textuelles qui sont potentiellement des termes. En terminologie, un terme
    est un mot, ou une séquence de mots, représentant un concept spécifique à un
    domaine (ou une discipline). Dans ce travail, nous utilisons l'extracteur
    terminologique TermSuite~\cite{rocheteau2011termsuite}, capable de détecter
    des candidats termes (simples et complexes) et leurs variantes. Une
    terminologie candidate (non filtrée) par corpus est construite
    automatiquement par TermSuite (32~119 candidats termes en Archéologie,
    16~557 candidats termes en Sciences de l'Information, 21~330 candidats
    termes en Linguistique, 24~680 candidats termes en Psychologie et 21~020
    candidats termes en Chimie) et seules les unités textuelles se trouvant dans
    cette terminologie sont extraites comme termes-clés candidats. Contrairement
    à la méthode utilisée pour extraire les groupes nominaux, la méthode
    d'extraction de candidats termes de TermSuite se fonde sur un travail de
    spécialisation linguistique des termes ayant donné lieu à des patrons plus
    précis (e.g. \texttt{N à N}, \texttt{N en N}, etc.).
    
    \textit{Exemple de candidats termes extraits à partir de \og{}[\dots]
    (bassin moyen du Don) [\dots]\fg{} dans la notice d'Archéologie de la
    figure~\ref{fig:exemple_notice_inist}~: \og{}bassin\fg{}, \og{}Don\fg{},
    \og{}bassin moyen\fg{} et \og{}bassin moyen du Don\fg{}.}
    
    %En comparaison avec les méthodes de reconnaissance de forme et d'extraction
    %de termes, la méthode d'extraction de $\{1..3\}$-grammes filtrés n'est pas
    %fondée linguistiquement. En effet, la nature et la grammaticalité de ces
    %termes-clés candidats n'est pas contrôlée. Cependant, cela rend l'ensemble
    %de $\{1..3\}$-grammes plus exhaustifs que les deux autres ensembles et il
    %est donc intéressant de comparer la performance d'une méthode d'extraction
    %de termes-clés lorsqu'elle utilise un tel ensemble et lorsqu'elle utilise un
    %ensemble plus contraint, et plus fondé, contenant potentiellement moins de
    %candidats présents dans la référence.

  \subsection{Ordonnancement des termes-clés candidats}
  \label{subsec:extraction_de_termes_cles}
    Dans la catégorie des méthodes non-supervisées, un grand nombre de méthodes
    différentes est proposé, dont la méthode TF-IDF~\cite{jones1972tfidf} et
    la méthode TopicRank~\cite{bougouin2013topicrank}. De part sa simplicité et
    sa robustesse, le TF-IDF s'impose comme la méthode de
    référence\footnote{Notons qu'une variante de la pondération TF-IDF est
    utilisée en Recherche
    d'Information~\cite[Okapi]{robertson1999okapi,claveau2012vectorisation}.
    Bien que cette variante est jugée plus efficace en Recherche d'Information,
    celle-ci n'a, à notre connaissance, jamais été employée pour l'extraction
    automatique de termes-clés. Notre objectif n'étant pas de trouver la
    meilleure méthode d'extraction de termes-clés, nous préférons utiliser la
    méthode originale.}, tandis que les méthodes à base de graphe, comme
    TopicRank, suscitent un intérêt grandissant, car les graphes permettent de
    présenter simplement et efficacement les unités textuelles d'un document et
    leurs relations en son sein. De plus, les graphes bénéficient de nombreuses
    études théoriques donnant lieu à des outils et algorithmes efficaces pour
    résoudre divers problèmes.

    La méthode \textbf{TF-IDF} consiste à extraire en tant que termes-clés les
    candidats dont les mots sont importants. Un mot est considéré
    important dans un document s'il est fréquent dans le document et s'il est
    spécifique à celui-ci. La spécificité est déterminée à partir d'une
    collection de documents, de sorte qu'un mot est considéré spécifique
    lorsqu'il apparaît dans très peu de documents\footnote{Dans ce travail, nous
    utilisons la collection dont est extrait le document.}.

    \textbf{TopicRank}~\cite{bougouin2013topicrank} extrait les termes-clés qui
    représentent les sujets les plus importants d'un document. Tout d'abord,
    TopicRank groupe les termes-clés candidats selon leur appartenance à un
    sujet, représente les documents sous la forme d'un graphe de sujets, ordonne
    les sujets selon leur importance dans le graphe, puis sélectionne, pour
    chacun des meilleurs sujets, son candidat le plus représentatif.
    
    Pour effectuer le groupement en sujets, TopicRank utilise une mesure de
    similarité lexicale. Cependant, TermSuite fournit un groupement
    terminologique des termes et des variantes qu'il extrait. Lorsque les
    termes-clés candidats sont ceux extraits avec TermSuite, nous tirons profit
    de ce groupement terme/variantes, à la place de celui fondé sur la
    similarité lexicale. Tenant compte du groupement (moins naïf) de TermSuite,
    TopicRank distingue alors les candidats \og{}Kostienki 11/II/\fg{} et
    \og{}Kostienki 21/III/\fg{} (voir la figure~\ref{fig:exemple_notice_inist})
    qui représentent des faciès différents.

