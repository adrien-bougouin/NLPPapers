\section{Extraction automatique de termes-clés}
\label{sec:extraction_automatique_de_termes_cles}
  L'extraction non-supervisée de termes-clés peut se décomposer en quatre
  étapes~: un à un, les documents sont enrichis linguistiquement (segmentés et
  étiquetés en parties du discours), puis des termes-clés candidats en sont
  extraits, ordonnés et enfin, les termes-clés sont sélectionnés parmi les
  meilleurs candidats (voir la figure~\ref{fig:processing_steps}). Les étapes
  les plus importantes d'un système d'extraction automatique de termes-clés sont
  celles d'extraction de candidats et d'ordonnancement des termes-clés.
  Intuitivement, l'ordonnancement des candidats est le c\oe{}ur du système, mais
  la performance de celui-ci est limitée par la qualité de l'ensemble de
  termes-clés candidats qui lui est fourni. Nous estimons qu'un ensemble de
  candidats est de bonne qualité lorsqu'il fournit un maximum de candidats
  présents dans l'ensemble des termes-clés de référence et lorsqu'il fournit peu
  de candidats non-pertinents, i.e.~des candidats qui ne se sont pas dans
  l'ensemble des termes-clés de référence et qui peuvent dégrader la performance
  du système d'extraction de termes-clés.
  \begin{figure}
    \tikzstyle{io}=[
      ellipse,
      minimum width=5cm,
      minimum height=2cm,
      %fill=green!20,
      draw,%=green!33,
      transform shape,
      font={\huge}
    ]
    \tikzstyle{component}=[
      text centered,
      %thick,
      rectangle,
      minimum width=11cm,
      minimum height=2cm,
      %fill=cyan!20,
      draw,%=cyan!33,
      transform shape,
      font={\huge\bfseries}
    ]

    \centering
    \begin{tikzpicture}[thin,
                        align=center,
                        scale=.45,
                        node distance=2cm,
                        every node/.style={text centered, transform shape}]
      \node[io] (document) {document};
      \node[component] (preprocessing) [right=of document] {Prétraitement Linguistique};
      \node[component] (candidate_extraction) [below=of preprocessing] {Extraction des candidats};
      \node[component] (candidate_classification_and_ranking) [below=of candidate_extraction] {
        %\begin{tabular}{r|l}
        %  Ordonnancement & \multirow{2}{*}[-2pt]{des candidats}\\
        %  Classification & \\
        %\end{tabular}
        Ordonnancement des candidats
      };
      \node[component] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés};
      \node[io] (keyphrases) [right=of keyphrase_selection] {termes-clés};

      \path[->, thick] (document) edge (preprocessing);
      \path[->, thick] (preprocessing) edge (candidate_extraction);
      \path[->, thick] (candidate_extraction) edge (candidate_classification_and_ranking);
      \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
      \path[->, thick] (keyphrase_selection) edge (keyphrases);
%      \draw[decorate, decoration={brace, mirror, amplitude=5pt}, thick] ($(candidate_classification_and_ranking.north west)+(-0.9,0.5)$) -- ($(keyphrase_selection.south west)+(-0.9,-0.5)$) node[midway, xshift=-9em] {
%        \huge
%        \begin{tabular}{c}
%          \textbf{Extraction}\\
%          \textbf{des}\\
%          \textbf{termes-clés}\\
%        \end{tabular}
%      };
    \end{tikzpicture}
    \caption{Chaîne de traitements d'un système d'extraction automatique de
             termes-clés.
             \label{fig:processing_steps}}
  \end{figure}

  \subsection{Préparation des données}
  \label{subsec:preparation_des_donnees}
    Les documents des collections de données utilisées subissent les mêmes
    prétraitements. Ils sont tout d'abord segmentés en phrases, puis en mots et
    enfin étiquetés en parties du discours. Dans ce travail, la segmentation en
    mots est effectuée avec l'outil Bonsai, du Bonsai PCFG-LA
    parser\footnote{\url{http://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html}}
    et l'étiquetage en parties du discours est réalisé avec
    MElt~\cite{denis2009melt}. Tous ces outils sont utilisés avec leurs
    paramètres par défaut.

  \subsection{Extraction des termes-clés candidats}
  \label{subsec:extraction_de_termes_cles_candidats}
    Dans les travaux précédents, deux approches sont utilisées. Soit les
    candidats sont extraits à partir des n-grammes filtrés soit ils sont
    extraits par reconnaissance de formes~\cite{hulth2003keywordextraction}.
    Dans ce travail, nous expérimentons avec une méthode pour chacune de ces
    deux approches et une méthode qui extrait les candidats au moyen d'un
    extracteur terminologique.

    L'extraction des \textbf{n-grammes} filtrés consiste à extraire toutes les
    séquences ordonnées de $n$ mots, puis à les filtrer avec une liste
    regroupant les mots fonctionnels de la langue (conjonctions, prépositions,
    etc.) et les mots courants (\og{}près\fg{}, \og{}beaucoup\fg{}, etc.). Dans
    ce travail, les n-grammes de taille $n \in \{1..3\}$ ($\{1..3\}$-grammes)
    sont extraits lorsque leurs mots en tête et en queue ne sont pas présents
    dans la liste de mots outils~\cite{witten1999kea} fournie par l'université
    de
    Neuchâtel\footnote{\url{http://members.unine.ch/jacques.savoy/clef/index.html}}
    (UniNE). Exemple de {1..3}-grammes, extraits à partir de \og{}[\dots]
    (bassin moyen du Don) [\dots]\fg{} dans la notice d'Archéologie de la
    figure~\ref{fig:exemple_notice_inist}~: \og{}bassin\fg{}, \og{}moyen\fg{},
    \og{}Don\fg{}, \og{}bassin moyen\fg{} et \og{}moyen du Don\fg{}.

    La reconnaissance de formes consiste à extraire les unités textuelles qui
    respectent des patrons définis. Dans ce travail, nous suivons les travaux
    précédents et extrayons les plus longues séquences de noms communs, de noms
    propres et d'adjectifs, considérées comme étant les \textbf{groupes
    nominaux}~\cite{hassan2010conundrums}. Exemple de groupes nominaux extraits
    à partir de \og{}[\dots] (bassin moyen du Don) [\dots]\fg{} dans la notice
    d'Archéologie de la figure~\ref{fig:exemple_notice_inist}~: \og{}Don\fg{} et
    \og{}bassin moyen\fg{}.

    L'extraction de \textbf{candidats termes} consiste à extraire les unités
    textuelles qui sont potentiellement des termes. En terminologie, un terme
    est un mot, ou une séquence de mots, représentant un concept spécifique à un
    domaine (ou une discipline). Dans ce travail, nous utilisons l'extracteur
    terminologique TermSuite~\cite{rocheteau2011termsuite}, capable de détecter
    des candidats termes et leurs variantes. Une terminologie (variantes
    incluses) par corpus est construite automatiquement par TermSuite (32~119
    termes en Archéologie, 16~557 termes en Sciences de l'Information, 21~330
    termes en Linguistique, 24~680 termes en Psychologie et 21~020 termes en
    Chimie) et uniquement les unités textuelles se trouvant dans cette
    terminologie sont extraites comme termes-clés candidats. Exemple de
    candidats termes extraits à partir de \og{}[\dots] (bassin moyen du Don)
    [\dots]\fg{} dans la notice d'Archéologie de la
    figure~\ref{fig:exemple_notice_inist}~: \og{}bassin\fg{}, \og{}Don\fg{},
    \og{}bassin moyen\fg{} et \og{}bassin moyen du Don\fg{}.
    
    %En comparaison avec les méthodes de reconnaissance de forme et d'extraction
    %de termes, la méthode d'extraction de $\{1..3\}$-grammes filtrés n'est pas
    %fondée linguistiquement. En effet, la nature et la grammaticalité de ces
    %termes-clés candidats n'est pas contrôlée. Cependant, cela rend l'ensemble
    %de $\{1..3\}$-grammes plus exhaustifs que les deux autres ensembles et il
    %est donc intéressant de comparer la performance d'une méthode d'extraction
    %de termes-clés lorsqu'elle utilise un tel ensemble et lorsqu'elle utilise un
    %ensemble plus contraint, et plus fondé, contenant potentiellement moins de
    %candidats présents dans la référence.

  \subsection{Ordonnancement des termes-clés candidats}
  \label{subsec:extraction_de_termes_cles}
    Dans les travaux précédents, de nombreuses méthodes sont proposées pour
    extraire les termes-clés. Dans la catégorie des méthodes non-supervisées, un
    grand nombre de méthodes différentes sont proposées, dont la méthode
    TF-IDF~\cite{jones1972tfidf} et la méthode
    TopicRank~\cite{bougouin2013topicrank}. De part sa simplicité et sa
    robustesse, le TF-IDF s'impose comme la méthode de référence\footnote{Notons
    que cette méthode de pondération à été modifiée en Recherche
    d'Information~\cite[Okapi]{robertson1999okapi,claveau2012vectorisation}.
    Cette variante n'étant, à notre connaissance, pas employée pour l'extraction
    automatique de termes-clés, nous optons pour la méthode classique.}, tandis
    que les méthodes à base de graphe, comme TopicRank, suscitent un intérêt
    grandissant du fait que les graphes présentent simplement et efficacement
    des unités textuelles et leurs relations aux sein d'un document. De plus,
    ils bénéficient de nombreuses études théoriques donnant lieu à des outils et
    algorithmes utiles pour de nombreux problèmes.

    La méthode \textbf{TF-IDF} consiste à extraire en tant que termes-clés les
    candidats dont les mots sont les plus importants. Un mot est considéré
    important, dans un document, s'il est fréquent dans le document et s'il est
    spécifique à celui-ci. La spécificité est déterminée à partir d'une
    collection de documents\footnote{Dans ce travail, nous utilisons la
    collection dont le document est extrait.}~: un mot est considéré spécifique
    lorsqu'il apparaît dans très peu de documents.

    \textbf{TopicRank}~\cite{bougouin2013topicrank} extrait les termes-clés qui
    représentent les sujets les plus importants d'un document. Tout d'abord, les
    termes-clés candidats sont groupés par sujets, puis les relations entre ces
    sujets sont modélisées par un graphe dans lequel ils sont les n\oe{}uds.
    Ensuite, l'algorithme TextRank~\cite{mihalcea2004textrank} ordonne les
    sujets par importance, puis pour chaque sujet, le candidat le plus
    représentatif est extrait. TopicRank groupe les candidats en sujet grâce à
    une mesure de similarité lexicale. Cependant, TermSuite fournit un
    groupement terminologique des termes et des variantes qu'il extrait. Lorsque
    les candidats sont extraits avec TermSuite, nous utilisons ce groupement
    term/variant à la place de celui fondé sur la similarité lexicale. Tenant
    compte du groupement (moins naïf) de TermSuite, TopicRank est alors capable
    de distinguer les candidats \og{}Kostienki 11/II/\fg{} et \og{}Kostienki
    21/III/\fg{} (voir la figure~\ref{fig:exemple_notice_inist}) qui
    représentent des faciès différents, mais qui sont groupés lorsque c'est le
    groupement par défaut de TopicRank qui est utilisé.

