\section{Extraction automatique de termes-clés}
\label{sec:extraction_automatique_de_termes_cles}
  L'extraction non-supervisée de termes-clés peut se décomposer en quatre étapes
  (cf.~figure~\ref{fig:processing_steps}). Tout d'abord, les documents sont un à
  un enrichis linguistiquement (segmentés en phrases, segmentés en mots et
  étiquetés en parties du discours), des termes-clés candidats y sont ensuite
  sélectionnés, puis ordonnés par importance et enfin, les $k$ plus importants
  sont sélectionnés en tant que termes-clés. Les étapes les plus importantes
  d'un système d'extraction automatique de termes-clés sont celles de sélection
  des candidats et d'ordonnancement de ceux-ci. Intuitivement, l'ordonnancement
  des candidats est le c\oe{}ur du système, mais la performance de celui-ci est
  limitée par la qualité de l'ensemble de termes-clés candidats qui lui est
  fourni. Un ensemble de candidats est de bonne qualité lorsqu'il fournit un
  maximum de candidats présents dans l'ensemble des termes-clés de référence et
  lorsqu'il fournit peu de candidats non-pertinents, c'est-à-dire des candidats
  qui ne sont pas dans l'ensemble des termes-clés de référence et qui peuvent
  dégrader la performance du système d'extraction de termes-clés utilisé.
  \begin{figure}
    \tikzstyle{io}=[
      ellipse,
      minimum width=5cm,
      minimum height=2cm,
      %fill=green!20,
      draw,%=green!33,
      transform shape,
      font={\huge}
    ]
    \tikzstyle{component}=[
      text centered,
      %thick,
      rectangle,
      minimum width=11cm,
      minimum height=2cm,
      %fill=cyan!20,
      draw,%=cyan!33,
      transform shape,
      font={\huge\bfseries}
    ]

    \centering
    \begin{tikzpicture}[thin,
                        align=center,
                        scale=.45,
                        node distance=2cm,
                        every node/.style={text centered, transform shape}]
      \node[io] (document) {document};
      \node[component] (preprocessing) [right=of document] {Prétraitement Linguistique};
      \node[component] (candidate_extraction) [below=of preprocessing] {Sélection des candidats};
      \node[component] (candidate_classification_and_ranking) [below=of candidate_extraction] {
        %\begin{tabular}{r|l}
        %  Ordonnancement & \multirow{2}{*}[-2pt]{des candidats}\\
        %  Classification & \\
        %\end{tabular}
        Ordonnancement des candidats
      };
      \node[component] (keyphrase_selection) [below=of candidate_classification_and_ranking] {Sélection des termes-clés};
      \node[io] (keyphrases) [right=of keyphrase_selection] {termes-clés};

      \path[->, thick] (document) edge (preprocessing);
      \path[->, thick] (preprocessing) edge (candidate_extraction);
      \path[->, thick] (candidate_extraction) edge (candidate_classification_and_ranking);
      \path[->, thick] (candidate_classification_and_ranking) edge (keyphrase_selection);
      \path[->, thick] (keyphrase_selection) edge (keyphrases);
%      \draw[decorate, decoration={brace, mirror, amplitude=5pt}, thick] ($(candidate_classification_and_ranking.north west)+(-0.9,0.5)$) -- ($(keyphrase_selection.south west)+(-0.9,-0.5)$) node[midway, xshift=-9em] {
%        \huge
%        \begin{tabular}{c}
%          \textbf{Extraction}\\
%          \textbf{des}\\
%          \textbf{termes-clés}\\
%        \end{tabular}
%      };
    \end{tikzpicture}
    \caption{Chaîne de traitements d'un système non-supervisé d'extraction
             automatique de termes-clés.
             \label{fig:processing_steps}}
  \end{figure}

  \subsection{Préparation des données}
  \label{subsec:preparation_des_donnees}
    Les documents des collections de données utilisées subissent tous les mêmes
    prétraitements. Ils sont tout d'abord segmentés en phrases, puis en mots et
    enfin étiquetés en parties du discours. Dans ce travail, la segmentation en
    phrase est effectuée par le \textit{PunktSentenceTokenizer} disponible avec
    la librairie Python NLTK~\cite[\textit{Natural Language
    ToolKit}]{bird2009nltk}, la segmentation en mots est effectuée par l'outil
    Bonsai, du Bonsai PCFG-LA
    parser\footnote{\url{http://alpage.inria.fr/statgram/frdep/fr_stat_dep_parsing.html}}
    et l'étiquetage en parties du discours est réalisé par
    MElt~\cite{denis2009melt}. Tous ces outils sont utilisés avec leurs
    paramètres par défaut.

  \subsection{Sélection des termes-clés candidats}
  \label{subsec:extraction_de_termes_cles_candidats}
    Dans les travaux précédents, deux approches sont fréquemment utilisées. Soit
    les méthodes sélectionnent les n-grammes (filtrés) en tant que termes-clés
    candidats, soit elles sélectionnent les candidats par reconnaissance de
    forme~\cite{hulth2003keywordextraction}. Dans ce travail, nous expérimentons
    trois méthodes différentes~: deux méthodes conformes aux approches standards
    et une méthode sélectionnant les candidats termes obtenus par un extracteur
    terminologique. Aucuns travaux portant sur l'extraction automatique de
    termes-clés n'ont, à notre connaissance, utilisés une telle approche. Compte
    tenu de la nature (disciplinaire) de nos données, nous faisons l'hypothèse
    que les candidats termes, tels que définis dans le domaine de l'extraction
    terminologique, sont des termes-clés candidats pertinants. Ces trois
    méthodes de sélection fournissent des ensembles de candidats de qualités
    différentes (cf. ci-dessous), ce qui nous permet par la suite d'identifier
    les facteurs qui influent sur la difficulté de l'extraction automatique de
    termes-clés.

    La \textbf{sélection des n-grammes filtrés} consiste à extraire toutes les
    séquences ordonnées de $n$ mots, puis à les filtrer avec un
    anti-dictionnaire regroupant les mots fonctionnels de la langue
    (conjonctions, prépositions, etc.) et les mots courants (\og{}près\fg{},
    \og{}beaucoup\fg{}, etc.). Dans ce travail, nous suivons
    \newcite{witten1999kea} et sélectionnons les n-grammes de taille $n \in
    \{1..3\}$ ($\{1..3\}$-grammes) lorsque leurs mots en tête et en queue ne
    sont pas présents dans l'anti-dictionnaire fourni par l'université de
    Neuchâtel\footnote{\url{http://members.unine.ch/jacques.savoy/clef/index.html}}
    (UniNE). La sélection des n-grammes est très exhaustive, elle fournit un
    grand nombre de termes-clés candidats, ce qui permmet de maximiser la
    quantité de candidats présents dans l'ensemble des termes-clés de référence,
    mais ce qui maximise aussi la quantité de candidats erronés (bruités).
    
    \textit{Exemple de $\{1..3\}$-grammes, extraits à partir de \og{}bassin
    moyen du Don\fg{} dans la notice d'Archéologie de la
    figure~\ref{fig:exemple_notice_inist}~: \og{}bassin\fg{}, \og{}moyen\fg{},
    \og{}Don\fg{}, \og{}bassin moyen\fg{} et \og{}moyen du Don\fg{}}.

    La \textbf{reconnaissance de formes} consiste à sélectionner les unités
    textuelles qui respectent certains patrons grammaticaux. Les termes-clés
    candidats sélectionnés par reconnaissance de forme ont l'avantage d'avoir
    une nature contrôlée avec précision (p. ex. des groupes nominaux), ce qui
    les rend plus fondés linguistiquement, ainsi que de meilleur qualité que les
    n-grammes. Dans ce travail, nous utilisons le patron \texttt{/(NOM | ADJ)+/}
    afin de sélectionner les plus longues séquences de noms (noms propres
    inclus) et d'adjectifs~\cite{hassan2010conundrums}.
    
    \textit{Exemple de groupes nominaux extraits à partir de \og{}bassin moyen
    du Don\fg{} dans la notice d'Archéologie de la
    figure~\ref{fig:exemple_notice_inist}~: \og{}bassin moyen\fg{} et
    \og{}Don\fg{}.}

    La \textbf{sélection de candidats termes} consiste à sélectionner les unités
    textuelles qui sont potentiellement des termes, tels que définis dans le
    domaine de l'extraction terminologique. En terminologie, un terme est un mot
    ou une séquence de mots représentant un concept spécifique à un domaine, ou
    une discipline. Dans ce travail, nous utilisons l'extracteur terminologique
    TermSuite~\cite{rocheteau2011termsuite}, capable de détecter des candidats
    termes (simples et complexes) ainsi que leurs variantes. Contrairement à la
    méthode de sélection des plus longues séquences de noms et d'adjectifs, la
    sélection des candidats termes de TermSuite se fonde sur un travail de
    spécialisation linguistique et terminologique des termes ayant donné lieu à
    des patrons plus précis (e.g. \texttt{/NOM à NOM/}, \texttt{/NOM en NOM/},
    \texttt{/ADJ NOM à NOM ADJ/}, etc.).
    
    \textit{Exemple de candidats termes extraits à partir de \og{}bassin moyen
    du Don\fg{} dans la notice d'Archéologie de la
    figure~\ref{fig:exemple_notice_inist}~: \og{}bassin\fg{}, \og{}Don\fg{},
    \og{}bassin moyen\fg{} et \og{}bassin moyen du Don\fg{}.}

  \subsection{Ordonnancement des termes-clés candidats}
  \label{subsec:extraction_de_termes_cles}
    Un grand nombre de méthodes sont proposées dans la catégorie des méthodes
    non-supervisées. Parmi elles, les méthodes d'ordonnancement
    TF-IDF~\cite{jones1972tfidf} et TopicRank~\cite{bougouin2013topicrank}. De
    part sa simplicité et sa robustesse, la méthode TF-IDF s'impose comme la
    méthode de référence pour l'extraction non-supervisée de
    termes-clés\footnote{Notons qu'une variante de la pondération TF-IDF est
    utilisée en Recherche
    d'Information~\cite[Okapi]{robertson1999okapi,claveau2012vectorisation}.
    Bien que cette variante est jugée plus efficace en Recherche d'Information,
    celle-ci n'a, à notre connaissance, jamais été employée pour l'extraction
    automatique de termes-clés. Notre objectif n'étant pas de trouver la
    meilleure méthode d'extraction de termes-clés, nous utilisons la méthode
    originale.}, tandis que les méthodes à base de graphe, telles que TopicRank,
    suscitent un intérêt grandissant. En effet, les graphes permettent de
    représenter simplement et efficacement les unités textuelles d'un document
    et leurs relations en son sein. De plus, ils bénéficient de nombreuses
    études théoriques donnant lieu à des outils et algorithmes efficaces pour
    résoudre divers problèmes. Ces deux méthodes ont un fonctionnement très
    différent (cf. ci-dessous), ce qui nous permet par la suite d'identifier les
    facteurs qui influent sur la difficulté de l'extraction automatique de
    termes-clés.

    La méthode \textbf{TF-IDF} consiste à extraire en tant que termes-clés les
    candidats dont les mots sont importants. Un mot est considéré
    important dans un document s'il est fréquent dans le document et s'il a une
    forte spécificité, celle-ci étant déterminée à partir d'une
    collection de documents\footnote{Dans ce travail, nous utilisons la
    collection dont est extrait le document.}~: moins il y a de documents qui
    contiennent le mot, plus forte est sa spécificité. Simplement, les candidats
    sont pondérés et ordonnés selon un score d'importance calculé par la somme
    du poids TF-IDF de leurs mots.

    \textbf{TopicRank}~\cite{bougouin2013topicrank} extrait les termes-clés qui
    représentent les sujets les plus importants d'un document. Tout d'abord,
    TopicRank groupe les termes-clés candidats selon leur appartenance à un
    sujet, représente les documents sous la forme d'un graphe de sujets et
    ordonne les sujets selon leur importance dans le
    graphe~\cite{mihalcea2004textrank}. Enfin, le terme-clé candidat le plus
    représentatif d'un sujet, celui qui apparaît en premier dans le document,
    est extrait en tant que terme-clé\footnote{Ci nécessaire, les termes-clés
    extraits sont pondérés et ordonnés selon le score d'importance de leur sujet
    respectif}.
    
    TopicRank groupe les termes-clés candidats selon une mesure de similarité
    lexicale (cf. équation~\ref{equ:similarity}). Cependant, TermSuite fournit
    un groupement terminologique des termes et de leurs variantes. Lorsque les
    termes-clés candidats sont ceux extraits avec TermSuite, nous tirons profit
    de ce groupement terme/variantes à la place de celui fondé sur la similarité
    lexicale. Tenant compte du groupement (moins naïf) de TermSuite, TopicRank
    distingue alors les candidats \og{}Kostienki 11/II/\fg{} et \og{}Kostienki
    21/III/\fg{} qui représentent des faciès différents (cf.
    figure~\ref{fig:exemple_notice_inist}).
    \begin{align}
      \text{similarité}(t_1, t_2) &= \frac{\|t_1~\cap~t_2\|}{\|t_1~\cup~t_2\|} \label{equ:similarity}
    \end{align}

